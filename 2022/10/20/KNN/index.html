<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="K近邻法:KNN, java,安全,python"><meta name="description" content="一个小白成长史"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>K近邻法:KNN | FSRM</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><script src="/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="FSRM" type="application/atom+xml"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">FSRM</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">FSRM</div><div class="logo-desc">一个小白成长史</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li><li><div class="divider"></div></li><li><a href="https://github.com/ghyjn0" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/ghyjn0" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/13.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">K近邻法:KNN</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">机器学习</span></a></div></div><div class="col s5 right-align"></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-10-20</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-10-20</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.8k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 10 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="K近邻法-（KNN）"><a href="#K近邻法-（KNN）" class="headerlink" title="K近邻法 （KNN）"></a>K近邻法 （KNN）</h1><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h2><p>K近邻（K-Nearest Neighbor, KNN）是一种最经典和最简单的<em>有监督学习</em>方法之一，K-近邻算法是最简单的分类器。</p><p><strong>K近邻算法既能够用来解决分类问题，也能够用来解决回归问题</strong>。当对<strong>数据的分布只有很少</strong>或者<strong>没有任何先验知识</strong>时，<strong>K 近邻算法是一个不错的选择</strong>。</p><p>KNN做<strong>分类预测</strong>时，一般是选择<strong>多数表决法</strong>，即训练集里和预测的样本特征最近的K个样本，预测为里面有最多类别数的类别。<br>KNN做<strong>回归</strong>时，一般是<strong>选择平均法</strong>，即最近的K个样本的样本输出的平均值作为回归预测值</p><h2 id="2-算法思想"><a href="#2-算法思想" class="headerlink" title="2.算法思想"></a>2.算法思想</h2><p><strong>「人以群分，物语类聚」、「近朱者赤，近墨者黑」是 KNN 的核心思想</strong>。</p><p><strong>KNN 中的K指的是近邻个数，也就是最近的K个点，根据它距离最近的K个点是什么类别来判断属于哪个类别。根据待分类样本周围的已知类别样本来判断待分类样本的类别</strong>。</p><p>简单说 如果你周围都是猴子，那 kNN 就认为你是猴子， 如果你周围都是大学生，那 kNN 就认为你是大学生。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/74b33246feb16cbdffab526b461703e3.gif" alt="KNN 最近邻算法"></p><h2 id="3-距离度量方法"><a href="#3-距离度量方法" class="headerlink" title="3.距离度量方法"></a>3.距离度量方法</h2><h3 id="1-欧氏距离"><a href="#1-欧氏距离" class="headerlink" title="1.欧氏距离"></a>1.欧氏距离</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180858.png" alt="image-20221020180858668"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020170718.png" alt="2FDEB4F409732F92F83F48422D76A5DC"></p><blockquote><p>注意点</p></blockquote><p>当维度之间的<strong>取值范围差别太大时</strong>，<strong>欧氏距离容易被那些取值范围大的变量所主导</strong>，从而会大大降低模型的效果。</p><p>因此，在实际应用<strong>K近邻算法来解决分类</strong>等问题时，如果<strong>采用欧氏距离作为相似度度量</strong>，<strong>最好提前对数据进行标准化转换</strong></p><p>即：<code>数据归一化</code>。</p><h3 id="2-曼哈顿距离"><a href="#2-曼哈顿距离" class="headerlink" title="2.曼哈顿距离"></a>2.曼哈顿距离</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180842.png" alt="image-20221020180842136"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020170742.png" alt="896FCAFD0421B752CAF19C6C0EE76684"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020174350.jpg" alt="23"></p><p><strong>红线代表曼哈顿距离，绿色代表欧氏距离，也就是直线距离，而蓝色和黄色代表等价的曼哈顿距离</strong></p><h2 id="4-KNN-算法步骤"><a href="#4-KNN-算法步骤" class="headerlink" title="4.KNN 算法步骤"></a>4.KNN 算法步骤</h2><ol><li><strong>计算测试数据与各个样本数据之间的距离，通常为欧式距离；</strong></li><li><strong>按照距离的递增关系进行排序；</strong></li><li><strong>选取距离最小的K个点；（K值的选择往往会对最终结果造成很大影响）</strong></li><li><strong>确定前K个点所在类别的出现频率；</strong></li><li><strong>返回前K个点中出现频率最高的类别作为测试数据的预测分类（投票法规则：少数服从多数）。</strong></li></ol><p><img src="https://img-blog.csdnimg.cn/img_convert/74b33246feb16cbdffab526b461703e3.gif" alt="KNN 最近邻算法"></p><blockquote><p>注意事项</p></blockquote><p><strong><code>计算数据距离之前别忘了进行归一化处理</code></strong></p><h2 id="5-KNN-算法分析"><a href="#5-KNN-算法分析" class="headerlink" title="5.KNN 算法分析"></a>5.KNN 算法分析</h2><p><strong>近似误差</strong>：可以理解为对现有<strong>训练集的训练误差</strong>。<br><strong>估计误差</strong>：可以理解为对<strong>测试集的测试误差</strong>。</p><p><strong>近似误差关注训练集</strong>，如果<strong>近似误差小</strong>了会<strong>出现过拟合的现象</strong>，对现有的<strong>训练集</strong>能有很<strong>好的预测</strong>，但是对<strong>未知的测试样本</strong>将会出现<strong>较大偏差</strong>的预测。</p><p>模型本身不是最接近最佳模型。</p><p><strong>估计误差关注测试集</strong>，<strong>估计误差小</strong>了说明<strong>对未知数据的预测能力好</strong>。<strong>模型本身最接近最佳模型</strong></p><h3 id="1-k值的影响"><a href="#1-k值的影响" class="headerlink" title="1. k值的影响"></a>1. k值的影响</h3><blockquote><p>k值取值较小</p></blockquote><p><strong>k值较小，相当于用较小的邻域中的训练实例进行预测，只有<code>距离近的（相似的）起作用</code></strong></p><ul><li><strong>单个样本影响大</strong></li><li><strong>“学习”的近似误差(approximation error)会减小（训练误差），但估计误差(estimation error)会增大（预测误差）</strong></li><li><strong>噪声敏感（对一些噪点数据敏感）</strong></li><li><strong>整体模型变得复杂，容易发生过拟合</strong></li></ul><blockquote><p>k值取值较大</p></blockquote><p><strong>k值较大，这时<code>距离远的（不相似的）也会起作用</code></strong></p><ul><li><strong>近似误差会增大，但估计误差会减小</strong></li><li><strong>整体的模型变得简单</strong></li></ul><blockquote><p>k值的选择</p></blockquote><p><strong>交叉验证</strong>选择最好的k值</p><p>留一交叉验证是一种详尽的交叉验证技术，其中 1 个样本点用作验证集，其余 n-1 个样本用作训练集。</p><p>假设我们在数据集中有 100 个样本。然后在每次迭代中，1 个值将用作验证集，其余 99 个样本作为训练集。因此，重复该过程，直到数据集的每个样本都用作验证点。</p><p>参考链接：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/BlairGrowing/p/15668898.html">七种交叉验证及其代码 - 视界~ - 博客园 (cnblogs.com)</a></p><blockquote><p>参考链接</p></blockquote><p><strong>k值选择的影响</strong></p><p><strong>参考链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/lihao19990930/article/details/115678336?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1-115678336-blog-115061208.pc_relevant_multi_platform_whitelistv3&spm=1001.2101.3001.4242.2&utm_relevant_index=4">(19条消息) KNN(K-Nearest Neighbor)简介_弱鸡萌新的博客-CSDN博客_knn简介</a></strong></p><h3 id="2-优点和缺点"><a href="#2-优点和缺点" class="headerlink" title="2.优点和缺点"></a>2.优点和缺点</h3><p><strong>优点：原理易懂，代码容易复现，预测效果好</strong>。</p><p><strong>缺点：</strong></p><ul><li><strong>计算量太大</strong>，尤其是<strong>特征数非常多</strong>的时候。每一个待分类文本都要计算<strong>它到全体已知样本的距离</strong>，才能得到它的K个最近邻点。</li><li><strong>样本不平衡</strong>的时候，<strong>对稀有类别的预测准确率低</strong>。当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。</li></ul><h2 id="6-KNN-代码"><a href="#6-KNN-代码" class="headerlink" title="6.KNN 代码"></a>6.KNN 代码</h2><blockquote><p>1.生成训练数据集</p></blockquote><pre class="language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_blobs
<span class="token comment" spellcheck="true"># 生成数据</span>
<span class="token triple-quoted-string string">"""
代码中，生成60个训练样本，这60个样本分布在以centers参数指定中心点周围。cluster_std是标准差，用来指明生成的点分布的松散程度。
生成的训练数据集放在变量X里面，数据集的类别标记放在y里面。
make_blobs函数是为聚类产生数据集
产生一个数据集和相应的标签
n_samples:表示数据样本点个数,默认值100
n_features:表示数据的维度，默认值是2
centers:产生数据的中心点，默认值3
cluster_std：数据集的标准差，浮点数或者浮点数序列，默认值1.0
center_box：中心确定之后的数据边界，默认值(-10.0, 10.0)
shuffle ：洗乱，默认值是True
random_state:官网解释是随机生成器的种子
"""</span>
centers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_blobs<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>centers<span class="token operator">=</span>centers<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> cluster_std<span class="token operator">=</span><span class="token number">0.60</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
这些点的分布情况在坐标轴上一目了然，其中三角形的点即各个类别的中心节点。
"""</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dpi<span class="token operator">=</span><span class="token number">144</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>centers<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 画出样本</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'cool'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 画出中心点</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'^'</span><span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'orange'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'knn_centers.png'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020174807.png" alt="5"></p><blockquote><p>2.交叉验证选择k</p></blockquote><pre class="language-SS"><code class="language-SS">k_range = range(1, 30) # 设置循环次数
k_error = []
#循环，取k从1~30，查看误差效果
for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    #cv参数决定数据集划分比例，这里是按照5:1划分训练集和测试集
    scores = cross_val_score(knn, X, y, cv=6, scoring='accuracy')
    k_error.append(1 - scores.mean())

#画图，x轴为k值，y值为误差值
plt.plot(k_range, k_error)
plt.xlabel('Value of K in KNN')
plt.ylabel('Error')
plt.show()
</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180012.png" alt="image-20221020180012218"></p><blockquote><p>3.训练knn</p></blockquote><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用KNeighborsClassifier对算法进行训练，我们选择参数k=5</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier
<span class="token comment" spellcheck="true"># 模型训练</span>
k <span class="token operator">=</span> <span class="token number">10</span>
clf <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> k<span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
</code></pre><blockquote><p>4.模型测试</p></blockquote><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 对一个新样本进行预测：</span>
<span class="token comment" spellcheck="true"># 进行预测</span>
<span class="token triple-quoted-string string">"""
我们要预测的样本是[0, 2]，使用kneighbors()方法，把这个样本周围距离最*的5个点取出来。
取出来的点是训练样本X里的索引，从0开始计算。
"""</span>
X_sample <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_sample <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_sample<span class="token punctuation">)</span>
neighbors <span class="token operator">=</span> clf<span class="token punctuation">.</span>kneighbors<span class="token punctuation">(</span>X_sample<span class="token punctuation">,</span> return_distance<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre><blockquote><p>5.画出最邻近的k个点</p></blockquote><pre class="language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 把待预测的样本以及和其最*的10个样本在图上标记出来。</span>
<span class="token comment" spellcheck="true"># 画出示意图</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dpi<span class="token operator">=</span><span class="token number">144</span><span class="token punctuation">)</span>
c <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>centers<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'cool'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 出样本</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'^'</span><span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 中心点</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"x"</span><span class="token punctuation">,</span>
           s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'cool'</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># 待预测的点</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> neighbors<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">'k--'</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 预测点与距离最*的10个样本的连线</span>
plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'knn_predict.png'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180252.png" alt="最近k个"></p><p>参考链接：</p><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/BlairGrowing/p/14840623.html">机器学习——K近邻算法（KNN） - 视界~ - 博客园 (cnblogs.com)</a></p><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/BlairGrowing/p/15852786.html">chapter6——KNN实现 - 视界~ - 博客园 (cnblogs.com)</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/codedz/article/details/108862498?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-108862498-blog-115061208.pc_relevant_multi_platform_whitelistv3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-108862498-blog-115061208.pc_relevant_multi_platform_whitelistv3&utm_relevant_index=5">(19条消息) KNN算法详解及实现__dingzhen的博客-CSDN博客_knn</a></p><h2 id="7-kd树"><a href="#7-kd树" class="headerlink" title="7.kd树"></a>7.kd树</h2><blockquote><p>简介</p></blockquote><p><strong>KNN算法最简单的实现方式：计算输入实例和所有训练实例的距离，进行排序，取前k个，进行分类。当训练集特别大的时候，非常耗时。</strong></p><p><strong>kd树通过减少输入实例和训练实例的计算次数来达到优化的目的</strong>.</p><blockquote><p>为什么kd树比knn 快</p></blockquote><p><strong>二叉树在时间复杂度上是O(logN），远远优于全遍历算法。对于该树，可以在空间上理解：树的每个节点把对应父节点切成的空间再切分，从而形成各个不同的子空间。查找某点的所在位置时，就变成了查找点所在子空间</strong>。</p><h3 id="1-kd-树构建"><a href="#1-kd-树构建" class="headerlink" title="1.kd 树构建"></a>1.kd 树构建</h3><blockquote><ol><li>样本空间</li></ol></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180858.png" alt="image-20221020180916800"></p><blockquote><ol start="2"><li>步骤 一 开始</li></ol></blockquote><ol><li><strong>构造根节点：选择一个维度进行作为根节点划分==》标准：计算N个样本中每一个维度的方差，选择方差最大的 一个维度作为划分。</strong></li><li><strong>找到切分点： 假设x(1)的现在方差最大，把N个数据集的按照x(1)特征排序，从N个数据集中选择x（1）中的中位数作为切分点。</strong></li><li><strong>如何切分：切分通过切分点并垂直于x(1)坐标轴平面。</strong></li></ol><p><code>注意事项：</code></p><p><code>此时有根节点生成深度为1 的左右子节点：左子节点对应的x(1) 小于切分点，切分点小于 右子节点对应的x(1)：类似与平衡二叉树。（维度虽然很多，但是只按照x(1)特征比较）。</code></p><blockquote><ol start="3"><li>步骤二 重复</li></ol></blockquote><ol><li><strong>对深度 为m的节点，选择x(a)为切分的坐标轴，a=m( mod k)+1: 解释k为前面每一个数据的维度总数。</strong></li><li><strong>以该节点的区域中所有实例的x(a) 坐标的中位数为切分点。</strong></li><li><strong>切分通过切分点 并于坐标轴x(a) 垂直的超平面。</strong></li></ol><p><code>注意事项：</code></p><p><code>此时有根节点生成深度为m 的左右子节点：左子节点对应的x(a) 小于切分点，切分点小于 右子节点对应的x(a)：类似与平衡二叉树。（维度虽然很多，但是只按照x(a)特征比较）。</code></p><blockquote><p>例子</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020174658.png" alt="4"></p><p>参考链接：</p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/548175689">【十分钟 机器学习 系列课程】讲义（14）：k近邻法之kd树的构造和搜索 - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/526424578">如何以案例学习kd树构建和搜索过程？ - 知乎 (zhihu.com)</a></p><h3 id="2-kd树搜索"><a href="#2-kd树搜索" class="headerlink" title="2.kd树搜索"></a>2.kd树搜索</h3><blockquote><p>kd树动态可视化参考链接</p></blockquote><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1sB4y1p7Ba/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">kd树最近邻点查询运行状态可视化_哔哩哔哩_bilibili</a></p><h2 id="8-参考链接"><a href="#8-参考链接" class="headerlink" title="8.参考链接"></a>8.参考链接</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u010608296/article/details/119822650">(19条消息) KNN 最近邻算法（K近邻）_wangchuang2017的博客-CSDN博客_knn近邻算法</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_45884316/article/details/115221211">(19条消息) K-近邻算法（KNN)_的博客-CSDN博客_k近邻算法</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42765557/article/details/115061208?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-115061208-blog-119822650.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-115061208-blog-119822650.pc_relevant_default&utm_relevant_index=1">(19条消息) 深入浅出理解kNN（k近邻算法）_可惜剑是断的的博客-CSDN博客_knn</a></p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">FSRM</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://hexofox.gitee.io/2022/10/20/KNN/">https://hexofox.gitee.io/2022/10/20/KNN/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">FSRM</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">机器学习</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/libs/share/js/social-share.min.js"></script></div></div></div></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2022/10/22/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"><div class="card-image"><img src="/medias/featureimages/19.jpg" class="responsive-img" alt="滑动窗口"> <span class="card-title">滑动窗口</span></div></a><div class="card-content article-content"><div class="summary block-with-text">滑动窗口1.介绍 窗口概念 假设target是9，我们的脑海中可以快速的浮现出一个从1到9的数组。这时候不妨再想象一下，数组下方有个两个指针，一个指向1，一个指向5，两个指针形成的这个数组范围，就是所谓的窗口。如下图所示： 滑动概念</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-10-22 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/leetcode/"><span class="chip bg-color">leetcode</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/2022/10/17/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%E6%B3%95/"><div class="card-image"><img src="/medias/featureimages/18.jpg" class="responsive-img" alt="快慢指针"> <span class="card-title">快慢指针</span></div></a><div class="card-content article-content"><div class="summary block-with-text">快慢指针1.介绍 简介 双指针，指的是在遍历对象的过程中，不是普通的使用单个指针[或者称之为变量]进行访问，而是使用两个相同方向（快慢指针）或者相反方向（对撞指针）的指针进行扫描，从而达到相应的目的。 使用条件 双指针使用条件：不要使</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-10-17 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/leetcode/"><span class="chip bg-color">leetcode</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0===window.getSelection||(""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: FSRM<br />文章作者: FSRM<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200))})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{var t,n="prenext-posts";let e=$("#"+"artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#"+n).width(t)}return}})})</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">FSRM</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">65.2k</span>&nbsp;字<br><br></div><div class="col s12 m4 l4 social-link"><a href="https://github.com/GhyJn0" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0],e=(t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}()</script><script src="/libs/others/clicklove.js" async></script><script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async></script><script src="/libs/instantpage/instantpage.js" type="module"></script></body></html>