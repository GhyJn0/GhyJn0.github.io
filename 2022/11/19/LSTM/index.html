<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="LSTM, java,安全,python"><meta name="description" content="一个小白成长史"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>LSTM | FSRM</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><script src="/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="FSRM" type="application/atom+xml"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">FSRM</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">FSRM</div><div class="logo-desc">一个小白成长史</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li><li><div class="divider"></div></li><li><a href="https://github.com/ghyjn0" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/ghyjn0" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/8.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">LSTM</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">深度学习</span></a></div></div><div class="col s5 right-align"></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-11-19</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-12-01</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 1.4k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 6 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="长短期记忆网络：LSTM"><a href="#长短期记忆网络：LSTM" class="headerlink" title="长短期记忆网络：LSTM"></a>长短期记忆网络：LSTM</h1><h2 id="LSTM先验知识"><a href="#LSTM先验知识" class="headerlink" title="LSTM先验知识"></a>LSTM先验知识</h2><h3 id="1-为什么会出现LSTM"><a href="#1-为什么会出现LSTM" class="headerlink" title="1. 为什么会出现LSTM"></a>1. 为什么会出现LSTM</h3><ul><li>解决传统RNN的记忆长度的问题</li></ul><p>对于<strong>传统的<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=RNN&spm=1001.2101.3001.7020">RNN</a>网络</strong>来说，它会出现的一个问题就是：它的<strong>Memory记忆的时间序列会比较短</strong>，比如说当你去翻译一句话的时候，你可能一次只能记住3个语境相关的单词。</p><ul><li><p>解决梯度离散的问题</p><p>参考链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38147421/article/details/107692418">(20条消息) LSTM原理详解_yanglee0的博客-CSDN博客</a></p></li></ul><h2 id="LSTM-结构详解"><a href="#LSTM-结构详解" class="headerlink" title="LSTM 结构详解"></a>LSTM 结构详解</h2><h3 id="1-LSTM和RNN-结构区别"><a href="#1-LSTM和RNN-结构区别" class="headerlink" title="1.LSTM和RNN 结构区别"></a>1.LSTM和RNN 结构区别</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119102510.png" alt="image-20221119102510674"></p><h3 id="2-LSTM-3D结构到平面"><a href="#2-LSTM-3D结构到平面" class="headerlink" title="2.LSTM 3D结构到平面"></a>2.LSTM 3D结构到平面</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119102612.png" alt="image-20221119102612567"></p><h3 id="3-LSTM-结构"><a href="#3-LSTM-结构" class="headerlink" title="3. LSTM 结构"></a>3. LSTM 结构</h3><blockquote><ol><li>完整的LSTM</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119120931.png" alt="image-20221119120931508"></p><blockquote><ol start="2"><li>单个LSTM单元结构</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119121007.png" alt="image-20221119121007072"></p><blockquote><ol start="3"><li>遗忘门</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119180032.png" alt="image-20221119180032322"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205053.png" alt="image-20221201205053823"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119182527.png" alt="image-20221119182527651"></p><blockquote><ol start="4"><li>更新门</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119182652.png" alt="image-20221119182652326"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205119.png" alt="image-20221201205119907"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119182901.png" alt="image-20221119182901153"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205136.png" alt="image-20221201205136664"></p><blockquote><ol start="5"><li>输出门</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119183712.png" alt="image-20221119183712013"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205158.png" alt="image-20221201205158686"></p><h2 id="LSTM-B站视频弹幕二分类"><a href="#LSTM-B站视频弹幕二分类" class="headerlink" title="LSTM:B站视频弹幕二分类"></a>LSTM:B站视频弹幕二分类</h2><blockquote><ol><li>导入库</li></ol></blockquote><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> Word2Vec
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> sequence
<span class="token keyword">from</span> keras <span class="token keyword">import</span> utils
<span class="token keyword">from</span> keras <span class="token keyword">import</span> utils <span class="token keyword">as</span> np_utils
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> model_from_yaml
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> Embedding
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>recurrent <span class="token keyword">import</span> LSTM
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>core <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> Activation
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">import</span> jieba
<span class="token keyword">import</span> keras<span class="token punctuation">,</span>re
</code></pre><blockquote><ol start="2"><li>读取并处理训练词向量文本</li></ol></blockquote><pre class="language-python"><code class="language-python">voc_dim<span class="token operator">=</span><span class="token number">100</span><span class="token comment" spellcheck="true">#词向量100维度</span>
input_dim<span class="token operator">=</span><span class="token number">0</span><span class="token comment" spellcheck="true">#词向量长度</span>


<span class="token triple-quoted-string string">"""
读取训练词向量文本
文本格式：
格式："这 两句 想起 我 想起 我 哀婉 的 心 都 碎 了\n"
        "胡子拉碴 的 这 是 妖\n"

    处理后：[
        ['这', '两句', '想起', '我', '想起', '我', '哀婉', '的', '心', '都', '碎', '了']
        ,['胡子拉碴', '的', '这', '是', '妖']
        ]

"""</span>
<span class="token keyword">def</span> <span class="token function">load_file</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        words<span class="token operator">=</span>f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
        word_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>
            word_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> word_list
    
<span class="token comment" spellcheck="true">#words=load_file("word2vec.txt")</span>
</code></pre><blockquote><ol start="3"><li>训练词向量</li></ol></blockquote><pre class="language-python"><code class="language-python"><span class="token triple-quoted-string string">"""
训练词向量
word2vec

"""</span>

<span class="token keyword">def</span> <span class="token function">word2vec_train</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""训练词模型"""</span>
    model<span class="token operator">=</span>Word2Vec<span class="token punctuation">(</span>sentences<span class="token operator">=</span>words<span class="token punctuation">,</span><span class="token comment" spellcheck="true">#可迭代对象</span>
                   size<span class="token operator">=</span>voc_dim<span class="token punctuation">,</span><span class="token comment" spellcheck="true">#100维词向量</span>
                   min_count<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#最小出现个数</span>
                   workers<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#cpu3</span>
                   iter<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#迭代20次</span>
    model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"word2vec.model"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token string">"word2vec.model"</span>
<span class="token comment" spellcheck="true">#word2vec_train(words)</span>
</code></pre><blockquote><ol start="4"><li>加载训练词模型</li></ol></blockquote><pre class="language-python"><code class="language-python"><span class="token triple-quoted-string string">"""
加载训练词模型
返回为：词向量的长度,和模型

"""</span>
<span class="token keyword">def</span> <span class="token function">load_word2vec</span><span class="token punctuation">(</span>name_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token operator">=</span>Word2Vec<span class="token punctuation">.</span>load<span class="token punctuation">(</span>name_path<span class="token punctuation">)</span>
    word_length<span class="token operator">=</span>len<span class="token punctuation">(</span>model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> word_length<span class="token punctuation">,</span>model
</code></pre><blockquote><ol start="5"><li>对应词转化为向量维度</li></ol></blockquote><pre class="language-python"><code class="language-python">input_dim<span class="token punctuation">,</span>model<span class="token operator">=</span>load_word2vec<span class="token punctuation">(</span><span class="token string">"word2vec.model"</span><span class="token punctuation">)</span>

input_dim<span class="token operator">=</span>input_dim<span class="token operator">+</span><span class="token number">1</span>
<span class="token comment" spellcheck="true">#生成对应词向量的维度</span>
embedding_weights<span class="token operator">=</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span>voc_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#词向量对应的索引</span>
w2dic <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>
<span class="token keyword">for</span> j<span class="token punctuation">,</span>key <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    embedding_weights<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">=</span>model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>__getitem__<span class="token punctuation">(</span>key<span class="token punctuation">)</span>
    w2dic<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token operator">=</span>j<span class="token operator">+</span><span class="token number">1</span>
</code></pre><blockquote><ol start="6"><li>读取训练数据并处理</li></ol></blockquote><pre class="language-python"><code class="language-python"><span class="token triple-quoted-string string">"""
读取训练数据切分成

"""</span>
<span class="token keyword">def</span> <span class="token function">split_train_data</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'gbk'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
            r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">'[\u4e00-\u9fa5]+'</span><span class="token punctuation">)</span>
            line<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>r<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span>
            words<span class="token operator">=</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>line<span class="token punctuation">)</span>
            content<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>
                content<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
            <span class="token keyword">if</span> len<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token operator">>=</span><span class="token number">1</span><span class="token punctuation">:</span>
                <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"train"</span><span class="token operator">+</span>path<span class="token punctuation">,</span><span class="token string">'a+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>
                    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#load_train_data("pos.txt")</span>
<span class="token comment" spellcheck="true">#load_train_data("neg.txt")</span>
</code></pre><blockquote><ol start="7"><li>加载lstm训练数据</li></ol></blockquote><pre class="language-python"><code class="language-python"><span class="token triple-quoted-string string">"""
加载训练数据
积极：30000
消极：30000

"""</span>
<span class="token keyword">def</span> <span class="token function">load_train_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    pos<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    neg<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'trainpos.txt'</span><span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">30000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            pos<span class="token punctuation">.</span>append<span class="token punctuation">(</span>f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'trainneg.txt'</span><span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">30000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            neg<span class="token punctuation">.</span>append<span class="token punctuation">(</span>f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">#消极语料和积极语料拼接在一起</span>
    train_list<span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> neg<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">#y表示积极对应的标签为1，消极语料对应的标签为0</span>
    y <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>len<span class="token punctuation">(</span>pos<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int<span class="token punctuation">)</span><span class="token punctuation">,</span>
                            np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>len<span class="token punctuation">(</span>neg<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> train_list<span class="token punctuation">,</span>y


</code></pre><blockquote><ol start="8"><li>对训练集处理</li></ol></blockquote><pre class="language-python"><code class="language-python">train_list<span class="token punctuation">,</span>y<span class="token operator">=</span>load_train_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_list<span class="token punctuation">,</span>y


<span class="token comment" spellcheck="true"># In[10]:</span>


<span class="token comment" spellcheck="true">#打乱训练集</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>train_list<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
</code></pre><blockquote><ol start="9"><li>加载停用词</li></ol></blockquote><pre class="language-python"><code class="language-python"><span class="token triple-quoted-string string">"""

加载停用词

"""</span>
<span class="token keyword">def</span> <span class="token function">StopWords</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    StopWords<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'stopWords.txt'</span><span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
            StopWords<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> StopWords
stopwords<span class="token operator">=</span>StopWords<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><blockquote><ol start="10"><li>引用词向量</li></ol></blockquote><pre class="language-python"><code class="language-python"><span class="token triple-quoted-string string">"""
#训练模型转化为model词向量中索引
['好 悲伤 的 感觉', '酱 好 可怜']--->
[['好', '悲伤', '的', '感觉'], ['酱', '好', '可怜']]
[[0, 8708, 0, 69], [1008, 0, 4151]]
"""</span>
<span class="token keyword">def</span> <span class="token function">sentence_convert_word</span><span class="token punctuation">(</span>sentence_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
    textlist<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentence_list<span class="token punctuation">:</span>
        textlist<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">#将词转化为model词向量中索引</span>
    cut_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> text <span class="token keyword">in</span> textlist<span class="token punctuation">:</span>
        data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span>word <span class="token keyword">in</span>  enumerate<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> word <span class="token operator">not</span> <span class="token keyword">in</span> stopwords<span class="token punctuation">:</span>
                <span class="token keyword">try</span><span class="token punctuation">:</span>
                    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>w2dic<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>        
                    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        cut_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">return</span> cut_list

trainlists<span class="token operator">=</span>sentence_convert_word<span class="token punctuation">(</span>train_list<span class="token punctuation">)</span>

trainlists<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
</code></pre><blockquote><ol start="11"><li>计算句子平均长度</li></ol></blockquote><pre class="language-python"><code class="language-python"><span class="token triple-quoted-string string">"""
计算训练模型的平均长度

"""</span>

<span class="token keyword">def</span> <span class="token function">length_train</span><span class="token punctuation">(</span>lists<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sentence_count<span class="token operator">=</span><span class="token punctuation">[</span>len<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> lists<span class="token punctuation">]</span>
    sentence_count<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>sentence_count<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'tokens count'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'tokens length'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">#计算句子的平均长度</span>
    <span class="token comment" spellcheck="true"># 可以使用 取tokens的平均值并且加上两个tokens的标准差，来选用tokens的长度</span>
    avg_length <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>sentence_count<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>sentence_count<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"平均长度："</span><span class="token punctuation">,</span>avg_length<span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">#计算符合句子长度的概率</span>
    l<span class="token operator">=</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>sentence_count <span class="token operator">&lt;</span>avg_length<span class="token punctuation">)</span> <span class="token operator">/</span> len<span class="token punctuation">(</span>sentence_count<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"小于平均长度的概率："</span><span class="token punctuation">,</span>l<span class="token punctuation">)</span>
    
    
    <span class="token keyword">return</span> int<span class="token punctuation">(</span>avg_length<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>


avg_length<span class="token operator">=</span>length_train<span class="token punctuation">(</span>trainlists<span class="token punctuation">)</span>
avg_length<span class="token operator">=</span><span class="token number">20</span>
</code></pre><blockquote><ol start="12"><li>对训练样本进行剪切和填充</li></ol></blockquote><pre class="language-python"><code class="language-python">
<span class="token triple-quoted-string string">"""
#对训练样本进行剪切和padding
#并将样本分割为
"""</span>
<span class="token keyword">def</span> <span class="token function">train_con_padding</span><span class="token punctuation">(</span>cut_list<span class="token punctuation">,</span>avg_length<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_train_tokens_pad<span class="token operator">=</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>cut_list<span class="token punctuation">,</span>maxlen<span class="token operator">=</span>avg_length<span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">,</span>truncating<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>x_train_tokens_pad<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># 使用90%进行训练，10%进行测试</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>
        x_train_tokens_pad<span class="token punctuation">,</span>
        y<span class="token punctuation">,</span>
        test_size<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
        random_state<span class="token operator">=</span><span class="token number">12</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span>  x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test 
    
x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span>  train_con_padding<span class="token punctuation">(</span>trainlists<span class="token punctuation">,</span>avg_length<span class="token punctuation">,</span>y<span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># In[16]:</span>


y_train <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
y_test <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre><blockquote><ol start="13"><li>构建lstm 模型</li></ol></blockquote><pre class="language-python"><code class="language-python">
y_train <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
y_test <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># In[17]:</span>


<span class="token comment" spellcheck="true">#构建模型</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>
     Embedding<span class="token punctuation">(</span>
        output_dim<span class="token operator">=</span>voc_dim<span class="token punctuation">,</span>
        input_dim<span class="token operator">=</span>input_dim<span class="token punctuation">,</span>
        mask_zero<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        weights<span class="token operator">=</span><span class="token punctuation">[</span>embedding_weights<span class="token punctuation">]</span><span class="token punctuation">,</span>
        input_length<span class="token operator">=</span>avg_length<span class="token punctuation">)</span>
 <span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span>activation <span class="token operator">=</span><span class="token string">'softsign'</span><span class="token punctuation">,</span>dropout<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> recurrent_dropout<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
adam<span class="token operator">=</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.0004</span><span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9999</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">,</span> decay<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> amsgrad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>adam<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span> <span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># In[ ]:</span>


<span class="token comment" spellcheck="true"># 训练30轮，每轮都进行测试集的验证，使用1%用来测试集，每批128</span>
history <span class="token operator">=</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>validation_split<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token comment" spellcheck="true"># In[ ]:</span>


<span class="token comment" spellcheck="true">#检测训练结果</span>
score <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>
</code></pre><blockquote><ol start="14"><li>评估标准</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221122093004.png" alt="image-20221122093004388"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221122093022.png" alt="image-20221122093022605"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qian99/article/details/88628383?ops_request_misc=%7B%22request_id%22:%22165302813316781818737206%22,%22scm%22:%2220140713.130102334..%22%7D&request_id=165302813316781818737206&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-88628383-null-null.142%5Ev10%5Econtrol,157%5Ev4%5Econtrol&utm_term=lstm&spm=1018.2226.3001.4187">(20条消息) LSTM 详解_qian99的博客-CSDN博客</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_44967199/article/details/103009371">(20条消息) 循环神经网络—LSTM_流浪码工的博客-CSDN博客</a></p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Z34y1k7mc/?spm_id_from=333.880.my_history.page.click&vd_source=5e8f069711510b3788382a0a03ff38e5">【LSTM长短期记忆网络】3D模型一目了然，带你领略算法背后的逻辑_哔哩哔哩_bilibili</a></p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">FSRM</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://hexofox.gitee.io/2022/11/19/LSTM/">https://hexofox.gitee.io/2022/11/19/LSTM/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">FSRM</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">深度学习</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/libs/share/js/social-share.min.js"></script></div></div></div></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2022/11/21/%E5%85%AD%E7%BA%A7%E8%AF%8D%E6%B1%87/"><div class="card-image"><img src="/medias/featureimages/24.jpg" class="responsive-img" alt="六级词汇"> <span class="card-title">六级词汇</span></div></a><div class="card-content article-content"><div class="summary block-with-text">六级词汇1. 医疗健康 According to :根据 disease:疾病 –illness–sickness – plague瘟疫 pandemic–epidemic all over the world :全世界 kidney:</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-11-21 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/%E5%85%AD%E7%BA%A7/"><span class="chip bg-color">六级</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/2022/11/17/RNN/"><div class="card-image"><img src="/medias/featureimages/22.jpg" class="responsive-img" alt="RNN"> <span class="card-title">RNN</span></div></a><div class="card-content article-content"><div class="summary block-with-text">RNN 循环神经网络1.为什么出现RNN在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。例如，你要预测句子的下一个单词是什么，一般需要用到前</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-11-17 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">深度学习</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0===window.getSelection||(""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: FSRM<br />文章作者: FSRM<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200))})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{var t,n="prenext-posts";let e=$("#"+"artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#"+n).width(t)}return}})})</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">FSRM</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">65.2k</span>&nbsp;字<br><br></div><div class="col s12 m4 l4 social-link"><a href="https://github.com/GhyJn0" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0],e=(t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}()</script><script src="/libs/others/clicklove.js" async></script><script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async></script><script src="/libs/instantpage/instantpage.js" type="module"></script></body></html>