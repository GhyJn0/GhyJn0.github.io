<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Attributed Graph Clustering |A Deep Attentional Embedding Approach, java,安全,python"><meta name="description" content="一个小白成长史"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>Attributed Graph Clustering |A Deep Attentional Embedding Approach | FSRM</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><script src="/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="FSRM" type="application/atom+xml"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">FSRM</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">FSRM</div><div class="logo-desc">一个小白成长史</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li><li><div class="divider"></div></li><li><a href="https://github.com/ghyjn0" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/ghyjn0" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/19.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Attributed Graph Clustering |A Deep Attentional Embedding Approach</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E8%AE%BA%E6%96%87/"><span class="chip bg-color">论文</span> </a><a href="/tags/%E6%B7%B1%E5%BA%A6%E8%81%9A%E7%B1%BB/"><span class="chip bg-color">深度聚类</span> </a><a href="/tags/%E5%9B%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">图深度学习</span></a></div></div><div class="col s5 right-align"></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-03-06</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2023-03-20</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 1.4k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 5 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="论文阅读01-Attributed-Graph-Clustering-A-Deep-Attentional-Embedding-Approach"><a href="#论文阅读01-Attributed-Graph-Clustering-A-Deep-Attentional-Embedding-Approach" class="headerlink" title="论文阅读01-Attributed Graph Clustering: A Deep Attentional Embedding Approach"></a>论文阅读01-Attributed Graph Clustering: A Deep Attentional Embedding Approach</h1><h2 id="1-创新点idea"><a href="#1-创新点idea" class="headerlink" title="1. 创新点idea"></a>1. 创新点idea</h2><ol><li><strong>Two-step的图嵌入方法不是目标导向的，聚类效果不好，提出一种基于目标导向的属性图聚类框架。</strong></li></ol><p>所谓目标导向，就是说<strong>特征提取和聚类任务不是独立的</strong>，提<strong>取的特征要在一定程度上有利于聚类，</strong>那么如何实现？可以通过自训练聚类的方式，<strong>将隐藏图嵌入产生的软聚类分配与聚类联合优化</strong>。</p><ol start="2"><li><strong>提出图注意力自动编码器</strong></li></ol><h2 id="2-模型-model"><a href="#2-模型-model" class="headerlink" title="2. 模型 model"></a>2. 模型 model</h2><h3 id="1-two-step"><a href="#1-two-step" class="headerlink" title="1. two-step"></a>1. two-step</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201415139.png" alt="image-20230308094038236"></p><p><code>two-step 步骤：深度学习</code>方法来学习紧凑<code>图嵌入 embedding</code>，在此<code>基础上应用的聚类方法</code></p><p><strong>two-step之前缺点：图嵌入的生成和聚类是两个独立的部分，通常会导致性能不佳。</strong></p><p><strong>这主要是因为图嵌入不是目标导向的，即专为特定的聚类任务而设计</strong></p><p><strong>DAEGC 解决办法</strong>：<code>让模型图嵌入和聚类之间联合优化</code></p><h3 id="2-模型架构图"><a href="#2-模型架构图" class="headerlink" title="2. 模型架构图"></a>2. 模型架构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201415531.png" alt="image-20230308094148787"></p><p>​ <strong>DAEGC</strong>通过基于<strong>图注意力的自动编码器</strong>学习<strong>隐藏表示 Z</strong>，并使用<strong>自训练聚类模块对其进行操作</strong>，<code>该模块与自动编码器一起优化并在训练期间执行聚类.</code></p><p>DAEGC模型架构为两个部分：</p><ul><li><code>图注意力自动编码器部分</code></li><li><code>自训练聚类</code></li></ul><p>自然而然的，该任务的目标函数就由两部分组成，重建损失和聚类损失：L=L<em>r</em>+<em>γ</em>L<em>c</em> 。</p><h3 id="3-图注意力自动编码器"><a href="#3-图注意力自动编码器" class="headerlink" title="3. 图注意力自动编码器"></a>3. 图注意力自动编码器</h3><p>​ <strong>DAEGC</strong>这篇论文的编码器<strong>在GAT 的基础上修改 作为图编码</strong>。<strong>原GAT论文 仅考虑 1 阶相邻节点（一阶）以进行图注意力。</strong>　<code>DAEGC</code> 认为图具有复杂的结构关系，建议在<code>编码器中利用高阶邻居</code>。我们通过<code>考虑图中的 t 阶邻居节点获得邻近矩阵M： t参数可以根据实验结果，自己调节，也即是输入参数</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416881.png" alt="image-20230308094250108"></p><p><strong>接下来计算顶点之间的图注意力系数: 顶点间的图注意力是不对成的 即 aij 不等于aji</strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416969.png" alt="image-20230308100604102"></p><p>​ <strong>DAEGC 堆叠两层图注意层得到图注意力自动编码器的编码器部分:</strong></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416997.png" alt="image-20230308101653448"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416727.png" alt="image-20230308101954296"></p><p>​ 解码器采用简单的内积：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416545.png" alt="image-20230308104330299"></p><p>​ 损失函数Lr：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416043.png" alt="image-20230308104411125"></p><h3 id="4-自训练聚类模块"><a href="#4-自训练聚类模块" class="headerlink" title="4. 自训练聚类模块"></a>4. 自训练聚类模块</h3><p>​ 我们使用<strong>t-分布</strong>来衡量<strong>嵌入节点Zi</strong> 和<strong>簇中心节点Uu</strong> 之间的相似性。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416300.png" alt="image-20230308105314822"></p><p>其他论文中公式：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416770.png" alt="image-20230308105502219"></p><p><strong><em>qiu</em>表示节点i属于簇u的概率，将其看作是每个节点的软聚类分配标签，如果值越大，那么可信度越高</strong> 。通过平方运算将这种可信度放大：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416902.png" alt="image-20230308105938080"></p><p>自训练聚类模块的损失函数采用KL 散度：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416128.png" alt="image-20230308110014750"></p><p><strong>聚类损失然后迫使当前分布 Q 逼近目标分布 P ，从而将这些“置信分配”设置为软标签来监督 Q 的嵌入学习</strong></p><p>​ 因此DEAGC 模型总的损失函数L：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416277.png" alt="image-20230308111337066"></p><h3 id="5-DAEGC-算法流程图、"><a href="#5-DAEGC-算法流程图、" class="headerlink" title="5. DAEGC 算法流程图、"></a>5. DAEGC 算法流程图、</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416624.png" alt="image-20230308123920017"></p><h3 id="6-DAEGC-模型参数和评价标准"><a href="#6-DAEGC-模型参数和评价标准" class="headerlink" title="6. DAEGC 模型参数和评价标准"></a>6. DAEGC 模型参数和评价标准</h3><p><strong>DAEGC 参数设定</strong>：</p><p><strong>我们将聚类系数 γ 设置为 10。我们考虑二阶邻居并设置 M = (B +B2)/2。编码器由一个 256 个神经元隐藏层和一个 16 个神经元嵌入层构成，适用于所有数据集</strong>。</p><p><strong>DAEGC 评价指标：</strong></p><p>使用四个指标 [Xia et al., 2014] 来评估聚类结果：**准确性 (ACC)、归一化互信息 (NMI)、F 分数和调整兰德指数 (ARI)**。</p><p><strong>更好的聚类结果应该会导致所有指标的值更高。</strong></p><h3 id="7-实验结果分析"><a href="#7-实验结果分析" class="headerlink" title="7.实验结果分析"></a>7.实验结果分析</h3><blockquote><ol><li>实验对比</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416410.png" alt="image-20230310123310585"></p><ol><li><p><code>同时使用图的结构和内容信息的方法</code>通常比<code>仅使用图的一侧信息的方法表现更好</code></p></li><li><p>DAEGC模型为啥好：</p><p><code>（1）我们采用了图注意力网络，有效地整合了图的内容和结构信息；</code></p><p><code>（2） 我们的自训练聚类组件在提高聚类效率方面专业而强大</code></p></li></ol><blockquote><ol start="2"><li>嵌入层维度</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416374.png" alt="image-20230310123005772"></p><p><code>嵌入层维度分析：</code><br><strong><code>当嵌入维度从 4 个神经元增加到 16 个神经元时，聚类性能稳步上升；但是当我们进一步增加嵌入层的神经元时，性能会有所波动，尽管 ACC 和 NMI 分数总体上都保持良好</code></strong></p><blockquote><ol start="3"><li>可视化分析</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416372.png" alt="image-20230310123424500"></p><p>第一个可视化说明<code>仅使用图形注意自动编码器进行嵌入训练</code>，然后是显示后续相等时期的可视化，其中包含<code>自训练组件，直到最后一个是最终的嵌入可视化</code></p><h2 id="额外知识补充"><a href="#额外知识补充" class="headerlink" title="额外知识补充"></a>额外知识补充</h2><h3 id="student-t分布"><a href="#student-t分布" class="headerlink" title="student t分布"></a>student t分布</h3><p>对于 <code>i 样本和 j</code> 样本，我们使用 Student 的 <code>t 分布</code>作为核心来度量<code>嵌入点 hi 和聚类中心向量 μj</code> 之间的相似性，如下所示：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201416598.png" alt="image-20230306213807740"></p><p><code>qij</code>可以看作是将<code>样本i分配</code>给<code>聚类j的概率</code>，即软分配。</p><p><strong><code>注意点：</code></strong> <strong><code>t=1</code></strong></p><p>解释</p><p>我们无法在<strong>无监督环境中对验证集上的 t 进行交叉验证</strong>，并且<strong>学习它是多余的</strong>（van der Maaten，2009），我们让<strong>所有实验的 t= 1</strong>。</p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/50365577">无监督的深度嵌入式聚类分析 - 知乎 (zhihu.com)</a></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/50365577">无监督的深度嵌入式聚类分析 - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/467248262">文献+代码—AAAI’20 对话系统新意图发现( Constrained Deep Adaptive Clustering with Cluster Refinement) - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://www.marigold.website/readArticle?workId=102&author=Marigold&authorId=1000001">论文阅读02——《Attributed Graph Clustering: A Deep Attentional Embedding Approach》 (marigold.website)</a></p><h2 id="DAEGC-代码"><a href="#DAEGC-代码" class="headerlink" title="DAEGC 代码"></a>DAEGC 代码</h2><p>出现问题解决办法：</p><p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/article/1138200">在torch_geometric.datasets中使用Planetoid手动导入Core数据集及发生相关错误解决方案-阿里云开发者社区 (aliyun.com)</a></p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">FSRM</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://hexofox.gitee.io/2023/03/06/DAEGC/">https://hexofox.gitee.io/2023/03/06/DAEGC/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">FSRM</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E8%AE%BA%E6%96%87/"><span class="chip bg-color">论文</span> </a><a href="/tags/%E6%B7%B1%E5%BA%A6%E8%81%9A%E7%B1%BB/"><span class="chip bg-color">深度聚类</span> </a><a href="/tags/%E5%9B%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">图深度学习</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/libs/share/js/social-share.min.js"></script></div></div></div></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2023/03/07/GAT/"><div class="card-image"><img src="/medias/featureimages/0.jpg" class="responsive-img" alt="GAT"> <span class="card-title">GAT</span></div></a><div class="card-content article-content"><div class="summary block-with-text">GAT 图注意力1. 图数据结构两种特征1.图结构特征 2. 节点自己特征除了图的结构之外**，每个顶点还有自己的特征 ℎi（通常是一个高维向量）。**它可以使社交网络中每个用户的个体属性；可以是生物网络中，每个蛋白质的性质；还可以使交通路</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-03-07 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">图神经网络</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/2023/03/06/206-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/"><div class="card-image"><img src="/medias/featureimages/17.jpg" class="responsive-img" alt="206. 反转链表"> <span class="card-title">206. 反转链表</span></div></a><div class="card-content article-content"><div class="summary block-with-text">206. 反转链表题目示例给你单链表的头节点 head ，请你反转链表，并返回反转后的链表。 输入：head = [1,2,3,4,5] 输出：[5,4,3,2,1] 题解1. 双指针 class Solution &#123; publ</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-03-06 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/leetcode/"><span class="chip bg-color">leetcode</span> </a><a href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"><span class="chip bg-color">双指针</span> </a><a href="/tags/%E9%93%BE%E8%A1%A8/"><span class="chip bg-color">链表</span> </a><a href="/tags/%E9%80%92%E5%BD%92/"><span class="chip bg-color">递归</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0===window.getSelection||(""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: FSRM<br />文章作者: FSRM<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200))})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{var t,n="prenext-posts";let e=$("#"+"artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#"+n).width(t)}return}})})</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">FSRM</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">67k</span>&nbsp;字<br><br></div><div class="col s12 m4 l4 social-link"><a href="https://github.com/GhyJn0" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0],e=(t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}()</script><script src="/libs/others/clicklove.js" async></script><script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async></script><script src="/libs/instantpage/instantpage.js" type="module"></script></body></html>