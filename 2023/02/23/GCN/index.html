<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="GCN, java,安全,python"><meta name="description" content="一个小白成长史"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>GCN | FSRM</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><script src="/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="FSRM" type="application/atom+xml"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">FSRM</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">FSRM</div><div class="logo-desc">一个小白成长史</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li><li><div class="divider"></div></li><li><a href="https://github.com/ghyjn0" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/ghyjn0" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/4.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">GCN</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">图神经网络</span> </a><a href="/tags/%E7%A4%BE%E5%8C%BA%E5%88%92%E5%88%86/"><span class="chip bg-color">社区划分</span></a></div></div><div class="col s5 right-align"></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-02-23</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2023-03-20</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 7 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h2 id="图卷积神经网络GCN"><a href="#图卷积神经网络GCN" class="headerlink" title="图卷积神经网络GCN"></a>图卷积神经网络GCN</h2><h2 id="1-GCN来源"><a href="#1-GCN来源" class="headerlink" title="1.GCN来源"></a>1.GCN来源</h2><h3 id="1-为什么CNN无法应用图数据"><a href="#1-为什么CNN无法应用图数据" class="headerlink" title="1. 为什么CNN无法应用图数据"></a>1. 为什么CNN无法应用图数据</h3><p>​ CNN 来说，其核心在于使用了基于卷积核的卷积操作来提取图像的特征，这里的卷积操作类似于对<strong>「计算区域内的中心节点和相邻节点进行加权求和」</strong>：</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424541.png" alt="image-20230225104507350"></p><p>无论卷积核平移到图片中的哪个位置都可以保证其运算结果的一致性，这就是我们所说的<strong>「平移不变性」</strong>。</p><p>网络是<strong>不规整</strong>的<strong>关系型数据</strong>，所以其不存在平移不变性（<strong>每个节点的周围邻居数不固定</strong>），这就使得传统的 CNN 方法无法直接应用于网络中。</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424399.png" alt="image-20230225104550237"></p><h3 id="2-GCN-提出"><a href="#2-GCN-提出" class="headerlink" title="2.GCN 提出"></a>2.GCN 提出</h3><p>​ 深度学习一直都是被几大经典模型给统治着，如CNN、RNN等等，它们无论再CV还是NLP领域都取得了优异的效果，那这个GCN是怎么跑出来的？是因为我们发现了很多CNN、RNN无法解决或者效果不好的问题——图结构的数据。</p><p>​ <strong>图的结构一般来说是十分不规则的</strong>，可以认为是无限维的一种数据，所以它<strong>没有平移不变性</strong>。每一个节点的周围结构可能都是独一无二的，这种结构的数据，就让传统的CNN、RNN瞬间失效。这里涌现出了很多方法，例如GNN、DeepWalk、node2vec等等，GCN只是其中一种。</p><h2 id="2-GCN-算法"><a href="#2-GCN-算法" class="headerlink" title="2. GCN 算法"></a>2. GCN 算法</h2><h3 id="1-思想"><a href="#1-思想" class="headerlink" title="1.思想"></a>1.思想</h3><p>​ 对于每个节点，我们从其所有邻居那里获得特征信息，当然还有自身的特征。然后通过聚合操作。我们将对所有节点执行相同的操作。最后，我们将值输入神经网络。</p><h3 id="2-GCN-核心公式"><a href="#2-GCN-核心公式" class="headerlink" title="2.GCN 核心公式"></a>2.GCN 核心公式</h3><h4 id="1-层级传播公式"><a href="#1-层级传播公式" class="headerlink" title="1.层级传播公式"></a>1.层级传播公式</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201424036.png" alt="image-20230225111810015"></p><p><code>注意事项：</code></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225112843.png" alt="image-20230225112843622"></p><h4 id="2-简单GCN-模型"><a href="#2-简单GCN-模型" class="headerlink" title="2. 简单GCN 模型"></a>2. 简单GCN 模型</h4><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225112147.png" alt="image-20230225112147502"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225112051.png" alt="image-20230225112051803"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225113927.png" alt="image-20230225113927849"></p><p><strong>GCN输入一个图，通过若干层GCN每个node的特征从X变成了Z，但是，无论中间有多少层，node之间的连接关系，即邻接矩阵A，都是共享的</strong></p><h3 id="3-GCN-层数理解"><a href="#3-GCN-层数理解" class="headerlink" title="3. GCN  层数理解"></a>3. GCN 层数理解</h3><p>​ <strong>图层数是结点要素可以行进的最远距离。</strong>例如，<strong>对于 1 层 GCN</strong>，<strong>每个节点只能从其邻居那里获取信息。</strong>收集信息的过程是<strong>独立**</strong>进行的，同时**针对所有节点。</p><p>​ 当在<strong>第一层之上堆叠另一层时</strong>，我们重复收集信息的过程，但这一次，<strong>邻居已经有了关于他们自己的邻居的信息（来自上一步）</strong>。它将层数作为每个节点可以行进<strong>的最大跃点数</strong>。因此，根据我们认为节点应该从网络获取信息。</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225113254.png" alt="image-20230225113254847"></p><h2 id="3-GCN-算法步骤"><a href="#3-GCN-算法步骤" class="headerlink" title="3.GCN 算法步骤"></a>3.GCN 算法步骤</h2><h3 id="1-求图模型的邻接矩阵和度矩阵"><a href="#1-求图模型的邻接矩阵和度矩阵" class="headerlink" title="1. 求图模型的邻接矩阵和度矩阵"></a>1. 求图模型的<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E9%82%BB%E6%8E%A5%E7%9F%A9%E9%98%B5&spm=1001.2101.3001.7020">邻接矩阵</a>和度矩阵</h3><p><strong>度矩阵</strong>，这个矩阵用来表示一个节点和多少个节点相关联</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225114048.png" alt="image-20230225114048023"></p><h3 id="2-特征计算"><a href="#2-特征计算" class="headerlink" title="2. 特征计算"></a>2. 特征计算</h3><p>求得矩阵A , D , X 后，进行特征的计算，来聚合邻居节点的信息</p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225120648.png" alt="image-20230225120648038"></p><h3 id="3-注意事项"><a href="#3-注意事项" class="headerlink" title="3. 注意事项"></a>3. 注意事项</h3><blockquote><ol><li>邻接矩阵</li></ol></blockquote><p><strong>邻接矩阵 A 没有考虑自身的加权，所以<code>GCN中的邻接矩阵考虑自己</code>中的邻接矩阵实际上等于 A＋单位对角矩阵 I 。</strong></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225114553.png" alt="image-20230225114553673"></p><blockquote><ol start="2"><li>度矩阵归一化处理</li></ol></blockquote><p>​ 首先对<strong>度矩阵的行和列进行了归一化</strong>，为什么这么做呢？</p><p>​ <strong>行归一化系数代表着节点自身的一个变化程度，关联的节点越少，系数越大，越容易随波主流</strong>，<strong>更易受别人影响。</strong></p><p>​ <strong>而列归一化系数，代表关联节点对当前节点的影响程度，关系网越复杂的节点，它对其他节点的作用就越小.</strong></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225114853.png" alt="image-20230225114853206"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225115051.png" alt="image-20230225115051719"></p><h2 id="4-GCN论文理解"><a href="#4-GCN论文理解" class="headerlink" title="4.GCN论文理解"></a>4.GCN论文理解</h2><h3 id="1-renormalization-trick-规则化"><a href="#1-renormalization-trick-规则化" class="headerlink" title="1.renormalization trick 规则化"></a>1.renormalization trick 规则化</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225110541.png" alt="image-20230225110541911"></p><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225111859.png" alt="image-20230225111859026"></p><h3 id="2-GCN未经历训练和少量标注效果显著"><a href="#2-GCN未经历训练和少量标注效果显著" class="headerlink" title="2. GCN未经历训练和少量标注效果显著"></a>2. GCN未经历训练和少量标注效果显著</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225110819.png" alt="image-20230225110819119"></p><p><code>论文中GCN，即使是未经过训练的GCN 模型，凭借随机初始化的权重，也能达到更好的分类效果</code></p><p><img src="https://pic4.zhimg.com/80/v2-c1775cbb3f22cf7461f47d1a88d11a2f_720w.webp" alt="img"></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cDovLzViMDk4OGU1OTUyMjUuY2RuLnNvaHVjcy5jb20vaW1hZ2VzLzIwMTkwOTIyL2Y1MmUxOWFmN2Y2NTRhZmQ5ZGEyOGNkMzlhM2Q4ZGM3LmdpZg" alt="img"></p><p><code>作为半监督学习，GCN 可以在只标注少量样本的情况下学得出色的效果，下图为每个类别只标注一个样本的分类结果</code></p><h3 id="3-GCN-的深度思考"><a href="#3-GCN-的深度思考" class="headerlink" title="3. GCN 的深度思考"></a>3. GCN 的深度思考</h3><p><img src="https://gitee.com/hexofox/pic/raw/master/images/20230225110943.png" alt="image-20230225110943053"></p><p><code>GCN论文中表明，目前GCN只局限于浅层，实验中使用2-3层GCN效果最好，为了加深，需要使用残差连接等trick，但是即使使用了这些trick，也只能勉强保存性能不下降，并没有提高</code></p><h2 id="5-GCN优缺点"><a href="#5-GCN优缺点" class="headerlink" title="5.GCN优缺点"></a>5.GCN优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>权值共享，参数共享，从 AXW可以看出每一个节点的参数矩阵都是W，权值共享</li><li>具有局部性Local Connectivity，也就是局部连接的，因为每次聚合的只是一阶邻居</li><li>感受野正比于卷积层层数，第一层的节点只包含与直接相邻节点有关的信息，第二层以后，每个节点还包含相邻节点的相邻节点的信息，这样的话，参与运算的信息就会变多。</li></ol><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol><li><p>扩展性差：由于训练时需要需要知道关于训练节点、测试节点在内的所有节点的邻接矩阵A，因此是transductive的，不能处理大图，然而工程实践中几乎面临的都是大图问题：[(36条消息) <a target="_blank" rel="noopener" href="https://blog.csdn.net/yyl424525/article/details/100532849">论文笔记]：GraphSAGE：Inductive Representation Learning on Large Graphs 论文详解 NIPS 2017_不务正业的土豆的博客-CSDN博客</a></p></li><li><p>局限于浅层：GCN论文中表明，目前GCN只局限于浅层，实验中使用2层GCN效果最好，为了加深，需要使用残差连接等trick，但是即使使用了这些trick，也只能勉强保存性能不下降，并没有提高。</p></li><li><p>不能处理有向图：理由很简单，推导过程中用到拉普拉斯矩阵的特征分解需要满足拉普拉斯矩阵是对称矩阵的条件。</p></li></ol><h2 id="6-代码实现"><a href="#6-代码实现" class="headerlink" title="6. 代码实现"></a>6. 代码实现</h2><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>nn <span class="token keyword">import</span> GCNConv
<span class="token keyword">from</span> torch_geometric<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> Planetoid
dataset <span class="token operator">=</span> Planetoid<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'./Cora'</span><span class="token punctuation">,</span>name<span class="token operator">=</span><span class="token string">'Cora'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">class</span> <span class="token class-name">GCN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment" spellcheck="true">#二层卷积</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>num_node_features<span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> GCNConv<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span>dataset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token punctuation">,</span> edge_index <span class="token operator">=</span> data<span class="token punctuation">.</span>x<span class="token punctuation">,</span> data<span class="token punctuation">.</span>edge_index
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x<span class="token punctuation">,</span> edge_index<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token comment" spellcheck="true"># gpu加速</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> GCN<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>weight_decay<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>out<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>train_mask<span class="token punctuation">]</span><span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>
pred <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true">#print(pred)</span>
<span class="token comment" spellcheck="true">#pred1 = pred[data.test_mask].cpu().numpy()</span>
<span class="token comment" spellcheck="true"># data1 = data[data.test_mask].cpu().numpy()</span>
<span class="token comment" spellcheck="true">#print(pred1)</span>
<span class="token comment" spellcheck="true">#print(data.y[data.test_mask])</span>
correct <span class="token operator">=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span> <span class="token operator">==</span> data<span class="token punctuation">.</span>y<span class="token punctuation">[</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span>
acc <span class="token operator">=</span> int<span class="token punctuation">(</span>correct<span class="token punctuation">)</span> <span class="token operator">/</span> int<span class="token punctuation">(</span>data<span class="token punctuation">.</span>test_mask<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>acc<span class="token punctuation">)</span>
</code></pre><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/FighterLYL/GraphNeuralNetwork/blob/master/chapter5/GCN_Cora.ipynb#scrollTo=feHONSuEX4oH">GCN_Cora.ipynb - Colaboratory (google.com)</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_53961910/article/details/127856355">从0到1实现GCN——最详细的代码实现_gcn代码_早睡早起困得早的博客-CSDN博客</a></p><h2 id="7-GCN实现方式库对比"><a href="#7-GCN实现方式库对比" class="headerlink" title="7.GCN实现方式库对比"></a>7.GCN实现方式库对比</h2><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1BR4y1a7pt/?spm_id_from=pageDriver&vd_source=5e8f069711510b3788382a0a03ff38e5">cogdl实现GNN模型_哔哩哔哩_bilibili</a></p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1924y1v7Dn/?spm_id_from=333.999.0.0&vd_source=5e8f069711510b3788382a0a03ff38e5">pyg-3-pyg与dgl的对比_哔哩哔哩_bilibili</a></p><h2 id="8-参考链接代码论文视频讲解"><a href="#8-参考链接代码论文视频讲解" class="headerlink" title="8.参考链接代码论文视频讲解"></a>8.参考链接代码论文视频讲解</h2><p><strong>代码：</strong></p><p><a target="_blank" rel="noopener" href="https://colab.research.google.com/github/FighterLYL/GraphNeuralNetwork/blob/master/chapter5/GCN_Cora.ipynb#scrollTo=feHONSuEX4oH">GCN_Cora.ipynb - Colaboratory (google.com)</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38234785/article/details/107984924#_38">GCN及代码实现_不染心的博客-CSDN博客_gcn代码</a></p><p><strong>参考博客：</strong></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_50706330/article/details/127468165">GCN-图卷积神经网络算法讲解（通俗版）_gcn图卷积网络_99.99％的博客-CSDN博客</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_50595984/article/details/127365520">通俗易懂的GCN原理讲解_听弧丶的博客-CSDN博客</a></p><p><a target="_blank" rel="noopener" href="https://ai.plainenglish.io/graph-convolutional-networks-gcn-baf337d5cb6b">图卷积网络 |作者：周范 |简明英语的人工智能 (plainenglish.io)</a></p><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/54504471">如何理解 Graph Convolutional Network（GCN）？ - 知乎 (zhihu.com)</a></p><p><strong>通俗理解：</strong></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/liuweiyuxiang/article/details/98957612">图卷积神经网络(GCN)_Lavi_qq_2910138025的博客-CSDN博客</a></p><p><strong>论文：</strong></p><p>[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1609.02907">1609.02907] 使用图卷积网络的半监督分类 (arxiv.org)</a></p><p><strong>视频讲解</strong>：</p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1gg411x7fH/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">《图卷积神经网络GCN——大白话讲解升级版》这下总会了吧！！_哔哩哔哩_bilibili</a></p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1UZ4y1m7fh/?spm_id_from=333.788&vd_source=5e8f069711510b3788382a0a03ff38e5">图神经网络GCN从理论到底层实现与项目实战 3_哔哩哔哩_bilibili</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/74242097">GraphSAGE：我寻思GCN也没我牛逼 - 知乎 (zhihu.com)</a></p><p>重点推荐：</p><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/54504471/answer/332657604">如何理解 Graph Convolutional Network（GCN）？ - 知乎 (zhihu.com)</a></p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">FSRM</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://hexofox.gitee.io/2023/02/23/GCN/">https://hexofox.gitee.io/2023/02/23/GCN/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">FSRM</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">图神经网络</span> </a><a href="/tags/%E7%A4%BE%E5%8C%BA%E5%88%92%E5%88%86/"><span class="chip bg-color">社区划分</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/libs/share/js/social-share.min.js"></script></div></div></div></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2023/02/26/%E5%90%8C%E6%9E%84/"><div class="card-image"><img src="/medias/featureimages/0.jpg" class="responsive-img" alt=""> <span class="card-title"></span></div></a><div class="card-content article-content"><div class="summary block-with-text">同构判断同构 充分条件 两个图的点集与边集之间分别存在一一对应关系（相同的关系E） 必要条件 （1）.结点数相等。 （2）.边数相等。 （3）.对应节点的度相等（包括进度和出度） (4) .节点对应的关系相同（包括重边和环）</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-02-26 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/2023/01/11/Louvain/"><div class="card-image"><img src="/medias/featureimages/4.jpg" class="responsive-img" alt="Louvain算法"> <span class="card-title">Louvain算法</span></div></a><div class="card-content article-content"><div class="summary block-with-text">louvain算法1.社区1. 简介在最常见的社交网络中，每个用户相当一个点，用户之间的互相关注、点赞、私信等形成了边，用户以及相互作用关系构成了一个大的关系网络。在这样的网络中，有的用户之间的连接较为紧密，有的用户之间的连接关系较为稀疏。</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-01-11 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/%E7%A4%BE%E5%8C%BA%E5%88%92%E5%88%86/"><span class="chip bg-color">社区划分</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0===window.getSelection||(""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: FSRM<br />文章作者: FSRM<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200))})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{var t,n="prenext-posts";let e=$("#"+"artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#"+n).width(t)}return}})})</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">FSRM</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">65.2k</span>&nbsp;字<br><br></div><div class="col s12 m4 l4 social-link"><a href="https://github.com/GhyJn0" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0],e=(t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}()</script><script src="/libs/others/clicklove.js" async></script><script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async></script><script src="/libs/instantpage/instantpage.js" type="module"></script></body></html>