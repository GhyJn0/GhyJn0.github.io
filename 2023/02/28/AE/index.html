<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="AE, java,安全,python"><meta name="description" content="一个小白成长史"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>AE | FSRM</title><link rel="icon" type="image/png" href="/favicon.png"><link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/css/matery.css"><link rel="stylesheet" type="text/css" href="/css/my.css"><script src="/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 5.4.2"><link rel="alternate" href="/atom.xml" title="FSRM" type="application/atom+xml"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">FSRM</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">FSRM</div><div class="logo-desc">一个小白成长史</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li><li><div class="divider"></div></li><li><a href="https://github.com/ghyjn0" class="waves-effect waves-light" target="_blank"><i class="fab fa-github-square fa-fw"></i>Fork Me</a></li></ul></div></div><style>.nav-transparent .github-corner{display:none!important}.github-corner{position:absolute;z-index:10;top:0;right:0;border:0;transform:scale(1.1)}.github-corner svg{color:#0f9d58;fill:#fff;height:64px;width:64px}.github-corner:hover .octo-arm{animation:a .56s ease-in-out}.github-corner .octo-arm{animation:none}@keyframes a{0%,to{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}</style><a href="https://github.com/ghyjn0" class="github-corner tooltipped hide-on-med-and-down" target="_blank" data-tooltip="Fork Me" data-position="left" data-delay="50"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/medias/featureimages/4.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">AE</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">深度学习</span> </a><a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">图神经网络</span></a></div></div><div class="col s5 right-align"></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-02-28</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2023-03-20</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 1.9k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 8 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h2 id="1-自编码-AE"><a href="#1-自编码-AE" class="headerlink" title="1.自编码 AE"></a>1.自编码 AE</h2><h3 id="1-由来"><a href="#1-由来" class="headerlink" title="1. 由来"></a>1. 由来</h3><p>首先让我们回忆一下<code>深度神经网络是干什么的?</code> 它从<code>数据中学习重要的特征, 这些特征允许我们在某些数据上进行某个的任务, 比如分类, 回归, 泛化等等</code>. 通过<code>自编码器 (Autoencoder), 我们可以 &quot;压缩&quot; 输入数据以进行高效地学习</code>,</p><p>比如我们有一些文档, 我们想要 “压缩” 文档到一个低维度的向量; 又或者我们有很多张图, 我们提取图的特征到一个低维度向量.</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421055.png" alt="image-20230228220659200"></p><h3 id="2-编码器构成"><a href="#2-编码器构成" class="headerlink" title="2.编码器构成"></a>2.编码器构成</h3><p>自编码器中，有两个神经网络，分别为Encoder和Decoder，其任务分别是：</p><ul><li>Encoder：将读入的原始数据（图像、文字等）转换为一个向量</li><li>Decoder：将上述的向量还原成原始数据的形式</li></ul><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421166.png" alt="image-20230228220118720"></p><p>目标是<strong>希望还原出来的结果能够与原始数据尽可能的接近</strong>。其中的向量可称为Embeding</p><p>主要用处<strong>就是将原始数据（高维、复杂）经过Encoder后得到的向量（经过处理，低纬度）作为下游任务的输入</strong>： 降维 学习出特征。</p><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/FavoriteStar/archive/2022/12/20/16993656.html#83%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B">【机器学习】李宏毅——AE自编码器(Auto-encoder) - FavoriteStar - 博客园 (cnblogs.com)</a></p><h3 id="3-训练过程"><a href="#3-训练过程" class="headerlink" title="3.训练过程"></a>3.训练过程</h3><h4 id="1-训练流程"><a href="#1-训练流程" class="headerlink" title="1. 训练流程"></a>1. 训练流程</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421478.png" alt="image-20230302123713298"></p><h4 id="2-例子"><a href="#2-例子" class="headerlink" title="2. 例子"></a>2. 例子</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421048.png" alt="image-20230228220827282"></p><p><code>编码器的流程：</code></p><ol><li><strong>它的输入可能是一张小狗图片, 或者其他我们想要的数据形式;</strong></li><li><strong>在数据被编码之后, 则是嵌入层 (embedding), 它是我们的数据在低维度 隐空间 (latent space) 的 表征 (representation);</strong></li><li><strong>最后数据被传递给一个 解码器 (decoder) 来重新构建我们的小狗图片 (可以看出它带有一些雾化效果, 也就是噪声).</strong></li><li><strong>我们可以根据输入和数据的 相似性(similarity) 来构建 代价 (loss), 以最小化重构误差:</strong></li></ol><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421109.png" alt="image-20230228220859587"></p><h3 id="4-如何使用编码器"><a href="#4-如何使用编码器" class="headerlink" title="4. 如何使用编码器"></a>4. 如何使用编码器</h3><h4 id="1-encoder-用处"><a href="#1-encoder-用处" class="headerlink" title="1.encoder 用处"></a>1.encoder 用处</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421120.png" alt="image-20230302124106041"></p><blockquote><p>小狗使用</p></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421659.png" alt="image-20230228221124513"></p><p>假设我们有另一张小狗的输入, 且在嵌入层得到了输入的表征向量 [2,5],</p><p>那我们就可以用<code>低维的表征向量</code>去完成一些其他域/维度的任务, 比如<code>聚类</code> (clustering), 可视化 (visualization), 等等.</p><h4 id="2-decoder-用处"><a href="#2-decoder-用处" class="headerlink" title="2.decoder 用处"></a>2.decoder 用处</h4><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421472.png" alt="image-20230302124240981"></p><p>输入向量通过解码器可以生成图片。====》图像生成。</p><p>参考链接：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/485054342">https://zhuanlan.zhihu.com/p/485054342</a></p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1mY411h7Hy/?spm_id_from=333.788.recommend_more_video.4&vd_source=5e8f069711510b3788382a0a03ff38e5">动画讲CV/autoencoder自编码器原理讲解/双语字幕_哔哩哔哩_bilibili</a></p><h2 id="2-图自编码器GAE"><a href="#2-图自编码器GAE" class="headerlink" title="2.图自编码器GAE"></a>2.图自编码器GAE</h2><h3 id="1-GAE-结构图"><a href="#1-GAE-结构图" class="headerlink" title="1.GAE 结构图"></a>1.GAE 结构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421051.png" alt="image-20230301104221195"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421457.png" alt="image-20230301104418884"></p><h3 id="2-encoder"><a href="#2-encoder" class="headerlink" title="2.encoder"></a>2.encoder</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421065.png" alt="image-20230301104527660"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421644.png" alt="image-20230301104545842"></p><h3 id="3-decoder"><a href="#3-decoder" class="headerlink" title="3. decoder"></a>3. decoder</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421262.png" alt="image-20230301104634709"></p><p><code>z是N*F维，z.z^t N*f*f*N===N*N 保证了和输入的数据同纬度</code></p><h3 id="4-如何训练"><a href="#4-如何训练" class="headerlink" title="4. 如何训练"></a>4. 如何训练</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201421148.png" alt="image-20230301104829815"></p><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&mid=2247504136&idx=1&sn=ab83adb768a8378e0ee1ea2dc12a0fee&chksm=96ea0e88a19d879ecbeb647fc31fa25fa7f363921b9ddf7848d86d4083c20cb6e7a05aef8613&mpshare=1&scene=23&srcid=&sharer_sharetime=1583733589784&sharer_shareid=49ce875fba478557cba19c6b33e0002b#rd">图自编码器的起源和应用 (qq.com)</a></p><h3 id="GAE-代码"><a href="#GAE-代码" class="headerlink" title="GAE 代码"></a>GAE 代码</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/485054342">PyG应用: 教程(六) 图自编码器与变分图自编码器 - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://github.com/DaehanKim/vgae_pytorch">GitHub - DaehanKim/vgae_pytorch: This repository implements variational graph auto encoder by Thomas Kipf.</a></p><h2 id="3-变分编码器-VAE"><a href="#3-变分编码器-VAE" class="headerlink" title="3.变分编码器 VAE"></a>3.变分编码器 VAE</h2><h3 id="0-VAE原理"><a href="#0-VAE原理" class="headerlink" title="0. VAE原理"></a>0. VAE原理</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422635.png" alt="image-20230306154853469"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422344.png" alt="image-20230306155117385"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422637.png" alt="image-20230306155320675"></p><h3 id="1-生成和推理过程"><a href="#1-生成和推理过程" class="headerlink" title="1.生成和推理过程"></a>1.生成和推理过程</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422472.png" alt="image-20230302205451216"></p><h3 id="2-变分近似后验"><a href="#2-变分近似后验" class="headerlink" title="2. 变分近似后验"></a>2. 变分近似后验</h3><p><code>变分贝叶斯是把原本的统计推断问题转换成优化问题（两个分布的距离），并利用一种分析方法来近似隐变量的后验分布，从而达到原本统计推断的问题。</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422976.png" alt="image-20230302205312638"></p><h3 id="3-VAE-的架构图"><a href="#3-VAE-的架构图" class="headerlink" title="3.VAE 的架构图"></a>3.VAE 的架构图</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422338.png" alt="image-20230302210256209"></p><p>参考链接：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1mT4y1F7u8/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">基于变分自编码器(VAE)的Mnist手写体自动生成-DeepSnow_哔哩哔哩_bilibili</a></p><h3 id="4-损失函数的解释"><a href="#4-损失函数的解释" class="headerlink" title="4. 损失函数的解释"></a>4. 损失函数的解释</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422536.png" alt="image-20230302210659087"></p><p><code>注意事项：</code></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422973.png" alt="image-20230302210936706"></p><h3 id="5-VAE和AE的结构比较"><a href="#5-VAE和AE的结构比较" class="headerlink" title="5. VAE和AE的结构比较"></a>5. VAE和AE的结构比较</h3><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422875.png" alt="image-20230302124711790"></p><h3 id="6-自变分编码的公式推导"><a href="#6-自变分编码的公式推导" class="headerlink" title="6.自变分编码的公式推导"></a>6.自变分编码的公式推导</h3><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/FavoriteStar/p/16995591.html#variational-auto-encodervae">【机器学习】李宏毅——Unsupervised Learning - FavoriteStar - 博客园 (cnblogs.com)</a></p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><blockquote><ol><li>前半部分损失函数解释</li></ol></blockquote><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422646.png" alt="image-20230302211044631"></p><p><strong><code>重点理解： 损失函数第一个值：编写代码时候用 均方差或者交叉熵代替</code></strong></p><blockquote><p>3.针对上面公式的DKL散度负号的解释？<code>KL散度始终大于0</code></p></blockquote><p>注意事项：公式中的<code>带有负号</code>与原来的<code>KL散度前的负号相抵消</code>:即**<code>-Dkl&gt;0</code>**</p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422658.png" alt="image-20230302211327683"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422867.png" alt="image-20230302213201288"></p><p>参考链接<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1KN4y1j7th/?p=2&spm_id_from=pageDriver&vd_source=5e8f069711510b3788382a0a03ff38e5">02 变分自动编码器的损失函数_哔哩哔哩_bilibili</a></p><h3 id="7-代码"><a href="#7-代码" class="headerlink" title="7.代码"></a>7.代码</h3><pre class="language-python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>utils <span class="token keyword">import</span> save_image
<span class="token comment" spellcheck="true"># 这句用来设置pytorch在哪块GPU上运行</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
sample_dir <span class="token operator">=</span> <span class="token string">'samples'</span>
<span class="token keyword">if</span> <span class="token operator">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>sample_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>sample_dir<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 超参数设置</span>
<span class="token comment" spellcheck="true"># Hyper-parameters</span>
image_size <span class="token operator">=</span> <span class="token number">784</span>
h_dim <span class="token operator">=</span> <span class="token number">400</span>
z_dim <span class="token operator">=</span> <span class="token number">20</span>
num_epochs <span class="token operator">=</span> <span class="token number">15</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span>
learning_rate <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span>
dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'../../../data/minist'</span><span class="token punctuation">,</span>
                                     train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                     transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                     download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 数据加载器</span>
data_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>dataset<span class="token punctuation">,</span>
                                          batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                          shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt <span class="token comment" spellcheck="true"># plt 用于显示图片</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>image <span class="token keyword">as</span> mpimg <span class="token comment" spellcheck="true"># mpimg 用于读取图片</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">class</span> <span class="token class-name">VAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image_size<span class="token operator">=</span><span class="token number">784</span><span class="token punctuation">,</span> h_dim<span class="token operator">=</span><span class="token number">400</span><span class="token punctuation">,</span> z_dim<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        super<span class="token punctuation">(</span>VAE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>image_size<span class="token punctuation">,</span> h_dim<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 输入层</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>h_dim<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 均值 向量</span>
        self<span class="token punctuation">.</span>fc3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>h_dim<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 保准方差 向量</span>
        self<span class="token punctuation">.</span>fc4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>z_dim<span class="token punctuation">,</span> h_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>h_dim<span class="token punctuation">,</span> image_size<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 编码过程</span>
    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"1:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"2:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>h<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>fc3<span class="token punctuation">(</span>h<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 随机生成隐含向量</span>
    <span class="token keyword">def</span> <span class="token function">reparameterize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var<span class="token punctuation">)</span><span class="token punctuation">:</span>
        std <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>log_var <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span>
        eps <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>std<span class="token punctuation">)</span>
        <span class="token keyword">return</span> mu <span class="token operator">+</span> eps <span class="token operator">*</span> std<span class="token comment" spellcheck="true"># u+标准差*标准正态分布的一个采样</span>

    <span class="token comment" spellcheck="true"># 解码过程</span>
    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc4<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc5<span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 整个前向传播过程：编码-》解码</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        mu<span class="token punctuation">,</span> log_var <span class="token operator">=</span> self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"3:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>mu<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"4:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>log_var<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        z <span class="token operator">=</span> self<span class="token punctuation">.</span>reparameterize<span class="token punctuation">(</span>mu<span class="token punctuation">,</span> log_var<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"5:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>z<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x_reconst <span class="token operator">=</span> self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"6:"</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>x_reconst<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x_reconst<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var


<span class="token comment" spellcheck="true"># 实例化一个模型</span>
model <span class="token operator">=</span> VAE<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 创建优化器</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 获取样本，并前向传播</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> image_size<span class="token punctuation">)</span>
        x_reconst<span class="token punctuation">,</span> mu<span class="token punctuation">,</span> log_var <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 计算重构损失和KL散度（KL散度用于衡量两种分布的相似程度）</span>
        <span class="token comment" spellcheck="true"># KL散度的计算可以参考论文或者文章开头的链接</span>
        reconst_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>binary_cross_entropy<span class="token punctuation">(</span>x_reconst<span class="token punctuation">,</span> x<span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        kl_div <span class="token operator">=</span> <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> log_var <span class="token operator">-</span> mu<span class="token punctuation">.</span>pow<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">-</span> log_var<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 反向传播和优化</span>
        loss <span class="token operator">=</span> reconst_loss <span class="token operator">+</span> kl_div
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch[&amp;#123;&amp;#125;/&amp;#123;&amp;#125;], Step [&amp;#123;&amp;#125;/&amp;#123;&amp;#125;], Reconst Loss: &amp;#123;:.4f&amp;#125;, KL Div: &amp;#123;:.4f&amp;#125;"</span>
                  <span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> reconst_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kl_div<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># 利用训练的模型进行测试</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true"># 随机生成的图像</span>
        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> z_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        out <span class="token operator">=</span> model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
        save_image<span class="token punctuation">(</span>out<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>sample_dir<span class="token punctuation">,</span> <span class="token string">'sampled-&amp;#123;&amp;#125;.png'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># 重构的图像</span>
        out<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _ <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x_concat <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> out<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
        save_image<span class="token punctuation">(</span>x_concat<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>sample_dir<span class="token punctuation">,</span> <span class="token string">'reconst-&amp;#123;&amp;#125;.png'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
reconsPath <span class="token operator">=</span> <span class="token string">'./samples/reconst-15.png'</span>
Image <span class="token operator">=</span> mpimg<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>reconsPath<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>Image<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 显示图片</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 不显示坐标轴</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201422387.png" alt="image-20230306182916704"></p><p>参考链接：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34998569">变分自编码器VAE：原来是这么一回事 | 附开源代码 - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_46183779/article/details/127771382">(38条消息) VAE 代码实现_vae代码_supermax2020的博客-CSDN博客</a></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>博客：</p><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/FavoriteStar/archive/2022/12/20/16993656.html#83%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B">【机器学习】李宏毅——AE自编码器(Auto-encoder) - FavoriteStar - 博客园 (cnblogs.com)</a></p><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/topic/21688923/hot">图自编码器（GAE） - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzIwMDIzNDI2Ng==&mid=2247484815&idx=1&sn=1b891d454d8a43356c29a90671ac108a&source=41#wechat_redirect">【GNN】VGAE：利用变分自编码器完成图重构 (qq.com)</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/83865427">变分自编码器介绍、推导及实现 - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34998569">变分自编码器VAE：原来是这么一回事 | 附开源代码 - 知乎 (zhihu.com)</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/83865427">变分自编码器介绍、推导及实现 - 知乎 (zhihu.com)</a></p><p>视频：</p><p>VAE 损失函数公式每个变量的理解：</p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1GG4y1v7CY/?spm_id_from=autoNext&vd_source=5e8f069711510b3788382a0a03ff38e5">【技术干货】自动编码器Autoencoders|EncoderDecoder|图像生成|深度学习进阶|PyTorch深度学习_哔哩哔哩_bilibili</a></p><p>VAE encoder和decoder 理解</p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1mT4y1F7u8/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">基于变分自编码器(VAE)的Mnist手写体自动生成-DeepSnow_哔哩哔哩_bilibili</a></p><p>VAE 公式推导：</p><p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Zq4y1h7Tu/?spm_id_from=333.337.search-card.all.click&vd_source=5e8f069711510b3788382a0a03ff38e5">变分自编码器 VAE 鲁鹏_哔哩哔哩_bilibili</a></p><h2 id="待整理"><a href="#待整理" class="headerlink" title="待整理"></a>待整理</h2><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423514.png" alt="image-20230306183140171"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423600.png" alt="image-20230306183151687"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423651.png" alt="image-20230306183201681"></p><p><img src="https://raw.githubusercontent.com/GhyJn0/2023images/master/202303201423328.png" alt="image-20230306183213056"></p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">FSRM</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://hexofox.gitee.io/2023/02/28/AE/">https://hexofox.gitee.io/2023/02/28/AE/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">FSRM</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">深度学习</span> </a><a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">图神经网络</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/libs/share/js/social-share.min.js"></script></div></div></div></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/2023/03/01/%E5%8F%8D%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2/"><div class="card-image"><img src="/medias/featureimages/11.jpg" class="responsive-img" alt="344. 反转字符串"> <span class="card-title">344. 反转字符串</span></div></a><div class="card-content article-content"><div class="summary block-with-text">344. 反转字符串题目描述编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 s 的形式给出。 不要给另外的数组分配额外的空间，你必须原地修改输入数组、使用 O(1) 的额外空间解决这一问题。 来源：力扣（LeetCo</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-03-01 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"><span class="chip bg-color">字符串</span> </a><a href="/tags/leetcode/"><span class="chip bg-color">leetcode</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/2023/02/28/18-%E5%9B%9B%E6%95%B0%E4%B9%8B%E5%92%8C/"><div class="card-image"><img src="/medias/featureimages/19.jpg" class="responsive-img" alt="18.四数之和&#34;"> <span class="card-title">18.四数之和&#34;</span></div></a><div class="card-content article-content"><div class="summary block-with-text">18. 四数之和题目描述给你一个由 n 个整数组成的数组 nums ，和一个目标值 target 。请你找出并返回满足下述全部条件且不重复的四元组 [nums[a], nums[b], nums[c], nums[d]] （若两个四元组元素</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-02-28 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> FSRM</span></div></div><div class="card-action article-tags"><a href="/tags/leetcode/"><span class="chip bg-color">leetcode</span> </a><a href="/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"><span class="chip bg-color">双指针</span></a></div></div></div></div></article></div><script>$("#articleContent").on("copy",function(e){var n,t,o,i;void 0===window.getSelection||(""+(n=window.getSelection())).length<Number.parseInt("120")||(t=document.getElementsByTagName("body")[0],(o=document.createElement("div")).style.position="absolute",o.style.left="-99999px",t.appendChild(o),o.appendChild(n.getRangeAt(0).cloneContents()),"PRE"===n.getRangeAt(0).commonAncestorContainer.nodeName&&(o.innerHTML="<pre>"+o.innerHTML+"</pre>"),i=document.location.href,o.innerHTML+='<br />来源: FSRM<br />文章作者: FSRM<br />文章链接: <a href="'+i+'">'+i+"</a><br />本文章著作权归作者所有，任何形式的转载都请注明出处。",n.selectAllChildren(o),window.setTimeout(function(){t.removeChild(o)},200))})</script><script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{var t,n="prenext-posts";let e=$("#"+"artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#"+n).width(t)}return}})})</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">FSRM</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">65.2k</span>&nbsp;字<br><br></div><div class="col s12 m4 l4 social-link"><a href="https://github.com/GhyJn0" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50"><i class="fas fa-rss"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/libs/materialize/materialize.min.js"></script><script src="/libs/masonry/masonry.pkgd.min.js"></script><script src="/libs/aos/aos.js"></script><script src="/libs/scrollprogress/scrollProgress.min.js"></script><script src="/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0],e=(t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}()</script><script src="/libs/others/clicklove.js" async></script><script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async></script><script src="/libs/instantpage/instantpage.js" type="module"></script></body></html>